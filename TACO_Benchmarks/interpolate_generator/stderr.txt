Generator interpolate has base_path ./bin/interpolate_auto_schedule
User error triggered at /home/ssioutas/Halide/src/AutoSchedule.cpp:4666
Warning at ../../distrib/tools/GenGen.cpp:4:
Insufficient parallelism for f7
Creating initial loop nests...
Injecting realization of { normalize }
Inlining f20
Injecting realization of { f40 }
Injecting realization of { f21 }
Injecting realization of { f41 }
Injecting realization of { f22 }
Injecting realization of { f42 }
Injecting realization of { f23 }
Injecting realization of { f43 }
Injecting realization of { f24 }
Injecting realization of { f25 }
Injecting realization of { f45 }
Injecting realization of { f26 }
Injecting realization of { f46 }
Injecting realization of { f27 }
Injecting realization of { f47 }
Injecting realization of { f28 }
Injecting realization of { f48 }
Injecting realization of { f9 }
Inlining f19
Injecting realization of { f8 }
Inlining f18
Injecting realization of { f7 }
Inlining f17
Injecting realization of { f6 }
Inlining f16
Injecting realization of { f5 }
Inlining f15
Injecting realization of { f4 }
Inlining f14
Inlining lambda_1
Injecting realization of { f3 }
Inlining f13
Injecting realization of { f2 }
Inlining f12
Injecting realization of { f1 }
Injecting realization of { f11 }
Inlining f0
Inlining repeat_edge
Skipping injecting memoization...
Injecting tracing...
Adding checks for parameters
Computing bounds of each function's value
Adding checks for images
Performing computation bounds inference...
Removing extern loops...
Performing sliding window optimization...
Simplifying correlated differences...
Warning: expression is non-monotonic in loop variable f25.s0.y.y_o: (let t15394 = min(((f25.s0.y.y_o*10) + f25.s0.y.loop_min), (f25.s0.y.loop_max + -9)) in ((((((f25.s0.y.y_i.loop_extent + f25.s0.y.y_i.loop_min) + t15394) + 2)/4) - ((f25.s0.y.y_i.loop_min + t15394)/4)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.y.y_o: (let t15402 = min(((f25.s0.y.y_o*10) + f25.s0.y.loop_min), (f25.s0.y.loop_max + -9)) in ((((((f25.s0.y.y_i.loop_extent + f25.s0.y.y_i.loop_min) + t15402) + 2)/4) - ((f25.s0.y.y_i.loop_min + t15402)/4)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.y.y_o: (let t15408 = min(((f25.s0.y.y_o*10) + f25.s0.y.loop_min), (f25.s0.y.loop_max + -9)) in (((((f25.s0.y.y_i.loop_extent + f25.s0.y.y_i.loop_min) + t15408)/2) - ((f25.s0.y.y_i.loop_min + t15408)/2)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.y.y_o: (let t15414 = min(((f25.s0.y.y_o*10) + f25.s0.y.loop_min), (f25.s0.y.loop_max + -9)) in (((((f25.s0.y.y_i.loop_extent + f25.s0.y.y_i.loop_min) + t15414)/2) - ((f25.s0.y.y_i.loop_min + t15414)/2)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.x.x_o: (let t15422 = min(((f25.s0.x.x_o*16) + f25.s0.x.loop_min), (f25.s0.x.loop_max + -15)) in ((((((f25.s0.x.x_i.loop_extent + f25.s0.x.x_i.loop_min) + t15422) + 2)/4) - ((f25.s0.x.x_i.loop_min + t15422)/4)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.x.x_o: (let t15428 = min(((f25.s0.x.x_o*16) + f25.s0.x.loop_min), (f25.s0.x.loop_max + -15)) in (((((f25.s0.x.x_i.loop_extent + f25.s0.x.x_i.loop_min) + t15428)/2) - ((f25.s0.x.x_i.loop_min + t15428)/2)) + 1))
Warning: expression is non-monotonic in loop variable f25.s0.x.x_o: (let t15434 = min(((f25.s0.x.x_o*16) + f25.s0.x.loop_min), (f25.s0.x.loop_max + -15)) in (((((f25.s0.x.x_i.loop_extent + f25.s0.x.x_i.loop_min) + t15434)/2) - ((f25.s0.x.x_i.loop_min + t15434)/2)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.y.y_o: (let t15444 = min(((f22.s0.y.y_o*16) + f22.s0.y.loop_min), (f22.s0.y.loop_max + -15)) in ((((((f22.s0.y.y_i.loop_extent + f22.s0.y.y_i.loop_min) + t15444) + 2)/4) - ((f22.s0.y.y_i.loop_min + t15444)/4)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.y.y_o: (let t15452 = min(((f22.s0.y.y_o*16) + f22.s0.y.loop_min), (f22.s0.y.loop_max + -15)) in ((((((f22.s0.y.y_i.loop_extent + f22.s0.y.y_i.loop_min) + t15452) + 2)/4) - ((f22.s0.y.y_i.loop_min + t15452)/4)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.y.y_o: (let t15458 = min(((f22.s0.y.y_o*16) + f22.s0.y.loop_min), (f22.s0.y.loop_max + -15)) in (((((f22.s0.y.y_i.loop_extent + f22.s0.y.y_i.loop_min) + t15458)/2) - ((f22.s0.y.y_i.loop_min + t15458)/2)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.y.y_o: (let t15464 = min(((f22.s0.y.y_o*16) + f22.s0.y.loop_min), (f22.s0.y.loop_max + -15)) in (((((f22.s0.y.y_i.loop_extent + f22.s0.y.y_i.loop_min) + t15464)/2) - ((f22.s0.y.y_i.loop_min + t15464)/2)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.x.x_o: (let t15472 = min(((f22.s0.x.x_o*10) + f22.s0.x.loop_min), (f22.s0.x.loop_max + -9)) in ((((((f22.s0.x.x_i.loop_extent + f22.s0.x.x_i.loop_min) + t15472) + 2)/4) - ((f22.s0.x.x_i.loop_min + t15472)/4)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.x.x_o: (let t15478 = min(((f22.s0.x.x_o*10) + f22.s0.x.loop_min), (f22.s0.x.loop_max + -9)) in (((((f22.s0.x.x_i.loop_extent + f22.s0.x.x_i.loop_min) + t15478)/2) - ((f22.s0.x.x_i.loop_min + t15478)/2)) + 1))
Warning: expression is non-monotonic in loop variable f22.s0.x.x_o: (let t15484 = min(((f22.s0.x.x_o*10) + f22.s0.x.loop_min), (f22.s0.x.loop_max + -9)) in (((((f22.s0.x.x_i.loop_extent + f22.s0.x.x_i.loop_min) + t15484)/2) - ((f22.s0.x.x_i.loop_min + t15484)/2)) + 1))
Warning: expression is non-monotonic in loop variable normalize.s0.y.y_o: (let t15494 = min(((normalize.s0.y.y_o*10) + normalize.s0.y.loop_min), (normalize.s0.y.loop_max + -9)) in ((((((normalize.s0.y.y_i.loop_extent + normalize.s0.y.y_i.loop_min) + t15494) + 2)/4) - ((normalize.s0.y.y_i.loop_min + t15494)/4)) + 1))
Warning: expression is non-monotonic in loop variable normalize.s0.y.y_o: (let t15500 = min(((normalize.s0.y.y_o*10) + normalize.s0.y.loop_min), (normalize.s0.y.loop_max + -9)) in (((((normalize.s0.y.y_i.loop_extent + normalize.s0.y.y_i.loop_min) + t15500)/2) - ((normalize.s0.y.y_i.loop_min + t15500)/2)) + 1))
Warning: expression is non-monotonic in loop variable normalize.s0.y.y_o: (let t15506 = min(((normalize.s0.y.y_o*10) + normalize.s0.y.loop_min), (normalize.s0.y.loop_max + -9)) in (((((normalize.s0.y.y_i.loop_extent + normalize.s0.y.y_i.loop_min) + t15506)/2) - ((normalize.s0.y.y_i.loop_min + t15506)/2)) + 1))
Warning: expression is non-monotonic in loop variable normalize.s0.x.x_o: (let t15512 = min(((normalize.s0.x.x_o*16) + normalize.s0.x.loop_min), (normalize.s0.x.loop_max + -15)) in (((((normalize.s0.x.x_i.loop_extent + normalize.s0.x.x_i.loop_min) + t15512)/2) - ((normalize.s0.x.x_i.loop_min + t15512)/2)) + 1))
Warning: expression is non-monotonic in loop variable normalize.s0.x.x_o: (let t15518 = min(((normalize.s0.x.x_o*16) + normalize.s0.x.loop_min), (normalize.s0.x.loop_max + -15)) in (((((normalize.s0.x.x_i.loop_extent + normalize.s0.x.x_i.loop_min) + t15518)/2) - ((normalize.s0.x.x_i.loop_min + t15518)/2)) + 1))
Performing allocation bounds inference...
Removing code that depends on undef values...
Uniquifying variable names...
Simplifying...
Performing storage folding optimization...
Injecting debug_to_file calls...
Injecting prefetches...
Dynamically skipping stages...
Forking asynchronous producers...
Destructuring tuple-valued realizations...
Canonicalizing GPU var names...
Performing storage flattening...
Unpacking buffer arguments...
Skipping rewriting memoized allocations...
Selecting a GPU API for GPU loops...
Injecting host <-> dev buffer copies...
Selecting a GPU API for extern stages...
Simplifying...
Reduce prefetch dimension...
Simplifying correlated differences...
Unrolling...
Vectorizing...
Injecting per-block gpu synchronization...
Detecting vector interleavings...
Partitioning loops to simplify boundary conditions...
Trimming loops to the region over which they do something...
Injecting early frees...
Simplifying correlated differences...
Bounding small allocations...
Injecting warp shuffles...
Simplifying...
Lowering unsafe promises...
Lowering after final simplification:
assert((reinterpret(uint64, normalize.buffer) != (uint64)0), halide_error_buffer_argument_is_null("normalize"))
assert((reinterpret(uint64, input.buffer) != (uint64)0), halide_error_buffer_argument_is_null("input"))
let input = _halide_buffer_get_host(input.buffer)
let input.type = _halide_buffer_get_type(input.buffer)
let input.dimensions = _halide_buffer_get_dimensions(input.buffer)
let input.min.0 = _halide_buffer_get_min(input.buffer, 0)
let input.extent.0 = _halide_buffer_get_extent(input.buffer, 0)
let input.stride.0 = _halide_buffer_get_stride(input.buffer, 0)
let input.min.1 = _halide_buffer_get_min(input.buffer, 1)
let input.extent.1 = _halide_buffer_get_extent(input.buffer, 1)
let input.stride.1 = _halide_buffer_get_stride(input.buffer, 1)
let input.min.2 = _halide_buffer_get_min(input.buffer, 2)
let input.extent.2 = _halide_buffer_get_extent(input.buffer, 2)
let input.stride.2 = _halide_buffer_get_stride(input.buffer, 2)
let normalize = _halide_buffer_get_host(normalize.buffer)
let normalize.type = _halide_buffer_get_type(normalize.buffer)
let normalize.dimensions = _halide_buffer_get_dimensions(normalize.buffer)
let normalize.min.0 = _halide_buffer_get_min(normalize.buffer, 0)
let normalize.extent.0 = _halide_buffer_get_extent(normalize.buffer, 0)
let normalize.stride.0 = _halide_buffer_get_stride(normalize.buffer, 0)
let normalize.min.1 = _halide_buffer_get_min(normalize.buffer, 1)
let normalize.extent.1 = _halide_buffer_get_extent(normalize.buffer, 1)
let normalize.stride.1 = _halide_buffer_get_stride(normalize.buffer, 1)
let normalize.min.2 = _halide_buffer_get_min(normalize.buffer, 2)
let normalize.extent.2 = _halide_buffer_get_extent(normalize.buffer, 2)
let normalize.stride.2 = _halide_buffer_get_stride(normalize.buffer, 2)
let f8.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 254)/256), (((((normalize.extent.1 + normalize.min.1) + 510)/512)*2) + 1))
let f8.s0.y.min = min((normalize.min.1/256), (((normalize.min.1/512)*2) + -1))
let f8.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 254)/256), (((((normalize.extent.0 + normalize.min.0) + 510)/512)*2) + 1))
let f8.s0.x.min = min((normalize.min.0/256), (((normalize.min.0/512)*2) + -1))
let f7.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 126)/128), ((f8.s0.y.max*2) + 1))
let f7.s0.y.min = min((normalize.min.1/128), ((f8.s0.y.min*2) + -1))
let f7.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 126)/128), ((f8.s0.x.max*2) + 1))
let f7.s0.x.min = min((normalize.min.0/128), ((f8.s0.x.min*2) + -1))
let f6.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 62)/64), ((f7.s0.y.max*2) + 1))
let f6.s0.y.min = min((normalize.min.1/64), ((f7.s0.y.min*2) + -1))
let f6.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 62)/64), ((f7.s0.x.max*2) + 1))
let f6.s0.x.min = min((normalize.min.0/64), ((f7.s0.x.min*2) + -1))
let f5.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 30)/32), ((f6.s0.y.max*2) + 1))
let f5.s0.y.min = min((normalize.min.1/32), ((f6.s0.y.min*2) + -1))
let f5.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 30)/32), ((f6.s0.x.max*2) + 1))
let f5.s0.x.min = min((normalize.min.0/32), ((f6.s0.x.min*2) + -1))
let f4.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 14)/16), ((f5.s0.y.max*2) + 1))
let f4.s0.y.min = min((normalize.min.1/16), ((f5.s0.y.min*2) + -1))
let f4.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 14)/16), ((f5.s0.x.max*2) + 1))
let f4.s0.x.min = min((normalize.min.0/16), ((f5.s0.x.min*2) + -1))
let f3.s0.y.max.s = max(min((input.extent.1/16), ((f4.s0.y.max*2) + 1)), (((normalize.extent.1 + normalize.min.1) + 6)/8))
let f3.s0.y.min = min(max(min((input.extent.1/16), ((f4.s0.y.min*2) + -1)), 0), (normalize.min.1/8))
let f3.s0.x.max.s = max(min((input.extent.0/16), ((f4.s0.x.max*2) + 1)), (((normalize.extent.0 + normalize.min.0) + 6)/8))
let f3.s0.x.min = min(max(min((input.extent.0/16), ((f4.s0.x.min*2) + -1)), 0), (normalize.min.0/8))
let f2.s0.y.max = max((((normalize.extent.1 + normalize.min.1) + 2)/4), ((max(f3.s0.y.max.s, 0)*2) + 1))
let f2.s0.y.min = min((normalize.min.1/4), ((f3.s0.y.min*2) + -1))
let f2.s0.x.max = max((((normalize.extent.0 + normalize.min.0) + 2)/4), ((max(f3.s0.x.max.s, 0)*2) + 1))
let f2.s0.x.min = min((normalize.min.0/4), ((f3.s0.x.min*2) + -1))
let f1.s0.y.max = max(((normalize.extent.1 + normalize.min.1)/2), ((f2.s0.y.max*2) + 1))
let f1.s0.y.min = min((normalize.min.1/2), ((f2.s0.y.min*2) + -1))
let f1.s0.x.max = max(((normalize.extent.0 + normalize.min.0)/2), ((f2.s0.x.max*2) + 1))
let f1.s0.x.min = min((normalize.min.0/2), ((f2.s0.x.min*2) + -1))
let input.extent.0.required.s = (max(max(min((f1.s0.x.max*2), ((input.extent.0 + input.min.0) + -1)), (min(max(((f1.s0.x.max*2) + 2), (normalize.extent.0 + normalize.min.0)), (input.extent.0 + input.min.0)) + -1)), input.min.0) - max(min(min(min(min((f1.s0.x.min*2), (min((f1.s0.x.min*2), (input.extent.0 + input.min.0)) + -1)), ((normalize.extent.0 + normalize.min.0) + -16)), normalize.min.0), ((input.extent.0 + input.min.0) + -1)), input.min.0))
let input.min.0.required = max(min(min(min(min((f1.s0.x.min*2), (min((f1.s0.x.min*2), (input.extent.0 + input.min.0)) + -1)), ((normalize.extent.0 + normalize.min.0) + -16)), normalize.min.0), ((input.extent.0 + input.min.0) + -1)), input.min.0)
let input.extent.1.required = (max(min(max((normalize.extent.1 + normalize.min.1), ((f1.s0.y.max*2) + 2)), (input.extent.1 + input.min.1)), (input.min.1 + 1)) - max((min((min((f1.s0.y.min*2), (input.extent.1 + input.min.1)) + 9), (min(normalize.extent.1, 10) + normalize.min.1)) + -10), input.min.1))
let input.min.1.required = max((min((min((f1.s0.y.min*2), (input.extent.1 + input.min.1)) + 9), (min(normalize.extent.1, 10) + normalize.min.1)) + -10), input.min.1)
let input.extent.2.required = (max(min((input.extent.2 + input.min.2), 4), (input.min.2 + 1)) - max((min((input.extent.2 + input.min.2), 1) + -1), input.min.2))
let input.min.2.required = max((min((input.extent.2 + input.min.2), 1) + -1), input.min.2)
let normalize.extent.0.required.s = (min((((normalize.extent.0 + -1)/16)*16), (normalize.extent.0 + -16)) - min(normalize.extent.0, 16))
let normalize.extent.1.required.s = (min((((normalize.extent.1 + -1)/10)*10), (normalize.extent.1 + -10)) - min(normalize.extent.1, 10))
let normalize.stride.2.required = ((normalize.extent.0.required.s + 32)*(normalize.extent.1.required.s + 20))
assert((!_halide_buffer_is_bounds_query(input.buffer) || ((0 <= input.min.2.required) && ((input.extent.2.required + input.min.2.required) <= 4))), halide_error_constraints_make_required_region_smaller("Input buffer input", 2, 0, 3, input.min.2.required, ((input.extent.2.required + input.min.2.required) + -1)))
if (_halide_buffer_is_bounds_query(input.buffer)) {
  _halide_buffer_init(input.buffer, _halide_buffer_get_shape(input.buffer), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), input.min.0.required, (input.extent.0.required.s + 1), 1, 0, input.min.1.required, input.extent.1.required, (input.extent.0.required.s + 1), 0, 0, 4, ((input.extent.0.required.s + 1)*input.extent.1.required), 0), (uint64)0)
}
if (_halide_buffer_is_bounds_query(normalize.buffer)) {
  _halide_buffer_init(normalize.buffer, _halide_buffer_get_shape(normalize.buffer), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), ((min(normalize.extent.0, 16) + normalize.min.0) + -16), (normalize.extent.0.required.s + 32), 1, 0, ((min(normalize.extent.1, 10) + normalize.min.1) + -10), (normalize.extent.1.required.s + 20), (normalize.extent.0.required.s + 32), 0, 0, 3, normalize.stride.2.required, 0), (uint64)0)
}
if (!(_halide_buffer_is_bounds_query(input.buffer) || _halide_buffer_is_bounds_query(normalize.buffer))) {
  assert((input.type == (uint32)73730), halide_error_bad_type("Input buffer input", input.type, (uint32)73730))
  assert((input.dimensions == 3), halide_error_bad_dimensions("Input buffer input", input.dimensions, 3))
  assert((normalize.type == (uint32)73730), halide_error_bad_type("Output buffer normalize", normalize.type, (uint32)73730))
  assert((normalize.dimensions == 3), halide_error_bad_dimensions("Output buffer normalize", normalize.dimensions, 3))
  assert(((input.min.0 <= input.min.0.required) && (((input.extent.0.required.s + input.min.0.required) + 1) <= (input.extent.0 + input.min.0))), halide_error_access_out_of_bounds("Input buffer input", 0, input.min.0.required, (input.extent.0.required.s + input.min.0.required), input.min.0, ((input.extent.0 + input.min.0) + -1)))
  assert((0 <= input.extent.0), halide_error_buffer_extents_negative("Input buffer input", 0, input.extent.0))
  assert(((input.min.1 <= input.min.1.required) && ((input.extent.1.required + input.min.1.required) <= (input.extent.1 + input.min.1))), halide_error_access_out_of_bounds("Input buffer input", 1, input.min.1.required, ((input.extent.1.required + input.min.1.required) + -1), input.min.1, ((input.extent.1 + input.min.1) + -1)))
  assert((0 <= input.extent.1), halide_error_buffer_extents_negative("Input buffer input", 1, input.extent.1))
  assert(((input.min.2 <= input.min.2.required) && ((input.extent.2.required + input.min.2.required) <= (input.extent.2 + input.min.2))), halide_error_access_out_of_bounds("Input buffer input", 2, input.min.2.required, ((input.extent.2.required + input.min.2.required) + -1), input.min.2, ((input.extent.2 + input.min.2) + -1)))
  assert((0 <= input.extent.2), halide_error_buffer_extents_negative("Input buffer input", 2, input.extent.2))
  assert(((16 <= normalize.extent.0) && ((((min(normalize.extent.0, 16) + normalize.min.0) + normalize.extent.0.required.s) + 16) <= (normalize.extent.0 + normalize.min.0))), halide_error_access_out_of_bounds("Output buffer normalize", 0, ((min(normalize.extent.0, 16) + normalize.min.0) + -16), (((min(normalize.extent.0, 16) + normalize.min.0) + normalize.extent.0.required.s) + 15), normalize.min.0, ((normalize.extent.0 + normalize.min.0) + -1)))
  assert(((10 <= normalize.extent.1) && ((((min(normalize.extent.1, 10) + normalize.min.1) + normalize.extent.1.required.s) + 10) <= (normalize.extent.1 + normalize.min.1))), halide_error_access_out_of_bounds("Output buffer normalize", 1, ((min(normalize.extent.1, 10) + normalize.min.1) + -10), (((min(normalize.extent.1, 10) + normalize.min.1) + normalize.extent.1.required.s) + 9), normalize.min.1, ((normalize.extent.1 + normalize.min.1) + -1)))
  assert(((normalize.min.2 <= 0) && (3 <= (normalize.extent.2 + normalize.min.2))), halide_error_access_out_of_bounds("Output buffer normalize", 2, 0, 2, normalize.min.2, ((normalize.extent.2 + normalize.min.2) + -1)))
  assert((0 <= normalize.extent.2), halide_error_buffer_extents_negative("Output buffer normalize", 2, normalize.extent.2))
  assert((input.stride.0 == 1), halide_error_constraint_violated("input.stride.0", input.stride.0, "1", 1))
  assert((input.min.2 == 0), halide_error_constraint_violated("input.min.2", input.min.2, "0", 0))
  assert((input.extent.2 == 4), halide_error_constraint_violated("input.extent.2", input.extent.2, "4", 4))
  assert((normalize.stride.0 == 1), halide_error_constraint_violated("normalize.stride.0", normalize.stride.0, "1", 1))
  let input.total_extent.1 = (int64(input.extent.1)*int64(input.extent.0))
  let normalize.total_extent.1 = (int64(normalize.extent.1)*int64(normalize.extent.0))
  let normalize.total_extent.2 = (normalize.total_extent.1*int64(normalize.extent.2))
  assert((abs(int64(input.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("input", abs(int64(input.extent.0)), (uint64)2147483647))
  assert((abs((int64(input.extent.1)*int64(input.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("input", abs((int64(input.extent.1)*int64(input.stride.1))), (uint64)2147483647))
  assert((input.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("input", input.total_extent.1, (int64)2147483647))
  assert((abs((int64(input.stride.2)*(int64)4)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("input", abs((int64(input.stride.2)*(int64)4)), (uint64)2147483647))
  assert((input.total_extent.1 <= (int64)536870911), halide_error_buffer_extents_too_large("input", (input.total_extent.1*(int64)4), (int64)2147483647))
  assert((abs(int64(normalize.extent.0)) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("normalize", abs(int64(normalize.extent.0)), (uint64)2147483647))
  assert((abs((int64(normalize.extent.1)*int64(normalize.stride.1))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("normalize", abs((int64(normalize.extent.1)*int64(normalize.stride.1))), (uint64)2147483647))
  assert((normalize.total_extent.1 <= (int64)2147483647), halide_error_buffer_extents_too_large("normalize", normalize.total_extent.1, (int64)2147483647))
  assert((abs((int64(normalize.extent.2)*int64(normalize.stride.2))) <= (uint64)2147483647), halide_error_buffer_allocation_too_large("normalize", abs((int64(normalize.extent.2)*int64(normalize.stride.2))), (uint64)2147483647))
  assert((normalize.total_extent.2 <= (int64)2147483647), halide_error_buffer_extents_too_large("normalize", normalize.total_extent.2, (int64)2147483647))
  let f1.y.min_realized = min(min(min((normalize.min.1/2), ((min((f2.s0.y.max + -7), f2.s0.y.min)*2) + -1)), (f1.s0.y.max + -7)), f1.s0.y.min)
  let f1.y.extent_realized.s.s = max(max(((normalize.extent.1 + normalize.min.1)/2), ((min((((((f2.s0.y.max - f2.s0.y.min)/8)*8) + f2.s0.y.min) + 7), f2.s0.y.max)*2) + 1)), min((((((f1.s0.y.max - f1.s0.y.min)/8)*8) + f1.s0.y.min) + 7), f1.s0.y.max))
  let f1.x.min_realized = min(min(min((normalize.min.0/2), ((min((f2.s0.x.max + -7), f2.s0.x.min)*2) + -1)), (f1.s0.x.max + -7)), f1.s0.x.min)
  let f1.x.extent_realized.s.s = max(max(((normalize.extent.0 + normalize.min.0)/2), ((min((((((f2.s0.x.max - f2.s0.x.min)/8)*8) + f2.s0.x.min) + 7), f2.s0.x.max)*2) + 1)), min((((((f1.s0.x.max - f1.s0.x.min)/8)*8) + f1.s0.x.min) + 7), f1.s0.x.max))
  let f1.stride.2 = (((f1.x.extent_realized.s.s - f1.x.min_realized) + 1)*((f1.y.extent_realized.s.s - f1.y.min_realized) + 1))
  allocate f1[float32 * ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1) * ((f1.y.extent_realized.s.s - f1.y.min_realized) + 1) * 4] if (uint1)0
  let f1.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f1.x.min_realized, ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1), 1, 0, f1.y.min_realized, ((f1.y.extent_realized.s.s - f1.y.min_realized) + 1), ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1), 0, 0, 4, f1.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f1.x.min_realized, ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1), 1, 0, f1.y.min_realized, ((f1.y.extent_realized.s.s - f1.y.min_realized) + 1), ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1), 0, 0, 4, f1.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f1.buffer)
  produce f1 {
    let halide_device_malloc_result$13 = halide_device_malloc(f1.buffer, halide_cuda_device_interface())
    assert((halide_device_malloc_result$13 == 0), halide_device_malloc_result$13)
    let halide_copy_to_device_result = halide_copy_to_device(input.buffer, halide_cuda_device_interface())
    assert((halide_copy_to_device_result == 0), halide_copy_to_device_result)
    let t15929.s = ((input.stride.2*3) - (input.min.1*input.stride.1))
    let t16601 = (input.min.1*input.stride.1)
    let t16596 = ((input.stride.2*3) - t16601)
    let t16599 = (t15929.s - input.min.0)
    let t16591 = (((f1.s0.y.max - f1.s0.y.min)/8) + 1)
    let t16592 = (((f1.s0.x.max - f1.s0.x.min)/8) + 1)
    let t16598 = (input.min.0 + t16601)
    let t16600 = ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1)
    let t16595 = (input.extent.1 + input.min.1)
    let t16597 = (input.extent.0 + input.min.0)
    let t16593 = (f1.s0.y.max + -7)
    let t16594 = (f1.s0.x.max + -7)
    gpu_block<CUDA> (f1.s0.y.y_o.__block_id_y, 0, t16591) {
      gpu_block<CUDA> (f1.s0.x.x_o.__block_id_x, 0, t16592) {
        allocate __shared[uint8 * 2176] in GPUShared
        gpu_thread<CUDA> (.__thread_id_y, 0, 17) {
          gpu_thread<CUDA> (.__thread_id_x, 0, 8) {
            let f1.s0.y.y_i.base = min(((f1.s0.y.y_o.__block_id_y*8) + f1.s0.y.min), t16593)
            let f1.s0.x.x_i.base = min(((f1.s0.x.x_o.__block_id_x*8) + f1.s0.x.min), t16594)
            produce f11 {
              let t15934.s = max((min(((f1.s0.y.y_i.base*2) + .__thread_id_y), t16595) + -1), input.min.1)
              let t16604 = (input.stride.1*t15934.s)
              let t16605 = (t16596 - input.min.0)
              let t16606 = ((.__thread_id_y*8) + .__thread_id_x)
              let t16602 = (.__thread_id_x + f1.s0.x.x_i.base)
              for (f11.s0.c, 0, 3) {
                __shared[((f11.s0.c*136) + t16606)] = (let t16437 = max((min((t16602*2), t16597) + -1), input.min.0) in (let t16438 = max(min((t16602*2), (t16597 + -1)), input.min.0) in (let t16439 = max((min(((t16602*2) + 2), t16597) + -1), input.min.0) in ((((input[((f11.s0.c*input.stride.2) + ((t16604 - t16598) + t16438))]*input[((t16604 + t16605) + t16438)])*2.000000f) + ((input[((f11.s0.c*input.stride.2) + ((t16604 - t16598) + t16439))]*input[((t16604 + t16605) + t16439)]) + (input[((f11.s0.c*input.stride.2) + ((t16604 - t16598) + t16437))]*input[((t16604 + t16605) + t16437)])))*0.250000f))))
              }
              __shared[(((.__thread_id_y*8) + .__thread_id_x) + 408)] = (let t16444.s = max((min(((f1.s0.y.y_i.base*2) + .__thread_id_y), t16595) + -1), input.min.1) in (((input[(max(min(((.__thread_id_x + f1.s0.x.x_i.base)*2), (t16597 + -1)), input.min.0) + ((input.stride.1*t16444.s) + t16599))]*2.000000f) + (input[(max((min(((.__thread_id_x + f1.s0.x.x_i.base)*2), t16597) + -1), input.min.0) + ((input.stride.1*t16444.s) + t16599))] + input[(max((min((((.__thread_id_x + f1.s0.x.x_i.base)*2) + 2), t16597) + -1), input.min.0) + ((input.stride.1*t16444.s) + t16599))]))*0.250000f))
            }
            gpu_thread_barrier()
            consume f11 {
              if ((.__thread_id_y < 8)) {
                let t15942.s = ((((f1.s0.y.y_i.base - f1.y.min_realized) + .__thread_id_y)*t16600) + (f1.s0.x.x_i.base - f1.x.min_realized))
                let t16607 = ((.__thread_id_y*16) + .__thread_id_x)
                let t16608 = (.__thread_id_x + t15942.s)
                for (f1.s0.c, 0, 4) {
                  f1[((f1.s0.c*f1.stride.2) + t16608)] = ((__shared[(((f1.s0.c*136) + t16607) + 16)] + (__shared[((f1.s0.c*136) + t16607)] + (__shared[(((f1.s0.c*136) + t16607) + 8)]*2.000000f)))*0.250000f)
                }
              }
            }
          }
        }
        free __shared
      }
    }
    _halide_buffer_set_device_dirty(f1.buffer, (uint1)1)
  }
  let f2.y.min_realized = min(min(min((((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4), ((min((max(f3.s0.y.max.s, 0) + -7), f3.s0.y.min)*2) + -1)), (f2.s0.y.max + -7)), f2.s0.y.min)
  let f2.y.extent_realized.s.s = max(max(min((((normalize.extent.1 + normalize.min.1) + 2)/4), (((normalize.min.1/4) + ((((((normalize.extent.1 + normalize.min.1) + 2)/4) - (normalize.min.1/4))/16)*16)) + 15)), ((min(max(f3.s0.y.max.s, 0), (((((max(f3.s0.y.max.s, 0) - f3.s0.y.min)/8)*8) + f3.s0.y.min) + 7))*2) + 1)), min((((((f2.s0.y.max - f2.s0.y.min)/8)*8) + f2.s0.y.min) + 7), f2.s0.y.max))
  let f2.x.min_realized = min(min(min((((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4), ((min((max(f3.s0.x.max.s, 0) + -7), f3.s0.x.min)*2) + -1)), (f2.s0.x.max + -7)), f2.s0.x.min)
  let f2.x.extent_realized.s.s = max(max(min((((normalize.extent.0 + normalize.min.0) + 2)/4), (((normalize.min.0/4) + ((((((normalize.extent.0 + normalize.min.0) + 2)/4) - (normalize.min.0/4))/10)*10)) + 9)), ((min(max(f3.s0.x.max.s, 0), (((((max(f3.s0.x.max.s, 0) - f3.s0.x.min)/8)*8) + f3.s0.x.min) + 7))*2) + 1)), min((((((f2.s0.x.max - f2.s0.x.min)/8)*8) + f2.s0.x.min) + 7), f2.s0.x.max))
  let f2.stride.2 = (((f2.x.extent_realized.s.s - f2.x.min_realized) + 1)*((f2.y.extent_realized.s.s - f2.y.min_realized) + 1))
  allocate f2[float32 * ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1) * ((f2.y.extent_realized.s.s - f2.y.min_realized) + 1) * 4] if (uint1)0
  let f2.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f2.x.min_realized, ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1), 1, 0, f2.y.min_realized, ((f2.y.extent_realized.s.s - f2.y.min_realized) + 1), ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1), 0, 0, 4, f2.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f2.x.min_realized, ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1), 1, 0, f2.y.min_realized, ((f2.y.extent_realized.s.s - f2.y.min_realized) + 1), ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1), 0, 0, 4, f2.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f2.buffer)
  produce f2 {
    consume f1 {
      let halide_device_malloc_result$12 = halide_device_malloc(f2.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$12 == 0), halide_device_malloc_result$12)
      let t16616 = (f1.x.extent_realized.s.s - f1.x.min_realized)
      let t16615 = (t16616 - f1.x.min_realized)
      let t16609 = (((f2.s0.y.max - f2.s0.y.min)/8) + 1)
      let t16610 = (((f2.s0.x.max - f2.s0.x.min)/8) + 1)
      let t16614 = ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1)
      let t16613 = (t16616 + 1)
      let t16611 = (f2.s0.y.max + -7)
      let t16612 = (f2.s0.x.max + -7)
      gpu_block<CUDA> (f2.s0.y.y_o.__block_id_y, 0, t16609) {
        gpu_block<CUDA> (f2.s0.x.x_o.__block_id_x, 0, t16610) {
          gpu_thread<CUDA> (.__thread_id_y, 0, 8) {
            gpu_thread<CUDA> (.__thread_id_x, 0, 8) {
              let f2.s0.y.y_i.base = min(((f2.s0.y.y_o.__block_id_y*8) + f2.s0.y.min), t16611)
              let f2.s0.x.x_i.base = min(((f2.s0.x.x_o.__block_id_x*8) + f2.s0.x.min), t16612)
              let t15953 = ((((.__thread_id_y + f2.s0.y.y_i.base)*2) - f1.y.min_realized)*t16613)
              let t15960.s = ((((f2.s0.y.y_i.base - f2.y.min_realized) + .__thread_id_y)*t16614) + (f2.s0.x.x_i.base - f2.x.min_realized))
              let t16618 = (t15953 - f1.x.min_realized)
              let t16619 = (t15953 - f1.x.extent_realized.s.s)
              let t16620 = (t15953 + t16615)
              let t16621 = (.__thread_id_x + t15960.s)
              let t16617 = (.__thread_id_x + f2.s0.x.x_i.base)
              for (f2.s0.c, 0, 4) {
                f2[((f2.s0.c*f2.stride.2) + t16621)] = (let t16456 = ((f1.stride.2*f2.s0.c) + ((t16617*2) + t16618)) in (let t16457 = ((f1.stride.2*f2.s0.c) + ((t16617*2) + t16619)) in (let t16458 = ((f1.stride.2*f2.s0.c) + ((t16617*2) + t16620)) in (((((f1[(t16456 + 1)] + (f1[(t16456 + -1)] + (f1[t16456]*2.000000f)))*2.000000f) + (f1[t16457] + (f1[(t16457 + -2)] + (f1[(t16457 + -1)]*2.000000f)))) + (f1[(t16458 + 2)] + (f1[t16458] + (f1[(t16458 + 1)]*2.000000f))))*0.062500f))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f2.buffer, (uint1)1)
    }
  }
  let f3.y.min_realized = min(min(min(max(min((input.extent.1/16), ((min((f4.s0.y.max + -31), f4.s0.y.min)*2) + -1)), 0), (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/8)), (max(f3.s0.y.max.s, 0) + -7)), f3.s0.y.min)
  let f3.y.extent_realized.s.s = max(max(min((input.extent.1/16), ((min((((((f4.s0.y.max - f4.s0.y.min)/32)*32) + f4.s0.y.min) + 31), f4.s0.y.max)*2) + 1)), ((min((((normalize.extent.1 + normalize.min.1) + 2)/4), (((normalize.min.1/4) + ((((((normalize.extent.1 + normalize.min.1) + 2)/4) - (normalize.min.1/4))/16)*16)) + 15)) + 1)/2)), min(max(f3.s0.y.max.s, 0), (((((max(f3.s0.y.max.s, 0) - f3.s0.y.min)/8)*8) + f3.s0.y.min) + 7)))
  let f3.x.min_realized = min(min(min(max(min((input.extent.0/16), ((min((f4.s0.x.max + -31), f4.s0.x.min)*2) + -1)), 0), (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/8)), (max(f3.s0.x.max.s, 0) + -7)), f3.s0.x.min)
  let f3.x.extent_realized.s.s = max(max(min((input.extent.0/16), ((min((((((f4.s0.x.max - f4.s0.x.min)/32)*32) + f4.s0.x.min) + 31), f4.s0.x.max)*2) + 1)), ((min((((normalize.extent.0 + normalize.min.0) + 2)/4), (((normalize.min.0/4) + ((((((normalize.extent.0 + normalize.min.0) + 2)/4) - (normalize.min.0/4))/10)*10)) + 9)) + 1)/2)), min(max(f3.s0.x.max.s, 0), (((((max(f3.s0.x.max.s, 0) - f3.s0.x.min)/8)*8) + f3.s0.x.min) + 7)))
  let f3.stride.2 = (((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1)*((max(f3.y.extent_realized.s.s, 0) - f3.y.min_realized) + 1))
  allocate f3[float32 * ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1) * ((max(f3.y.extent_realized.s.s, 0) - f3.y.min_realized) + 1) * 4] if (uint1)0
  let f3.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f3.x.min_realized, ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1), 1, 0, f3.y.min_realized, ((max(f3.y.extent_realized.s.s, 0) - f3.y.min_realized) + 1), ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1), 0, 0, 4, f3.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f3.x.min_realized, ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1), 1, 0, f3.y.min_realized, ((max(f3.y.extent_realized.s.s, 0) - f3.y.min_realized) + 1), ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1), 0, 0, 4, f3.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f3.buffer)
  produce f3 {
    consume f2 {
      let halide_device_malloc_result$11 = halide_device_malloc(f3.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$11 == 0), halide_device_malloc_result$11)
      let t16629 = (f2.x.extent_realized.s.s - f2.x.min_realized)
      let t16630 = max(f3.s0.x.max.s, 0)
      let t16631 = max(f3.s0.y.max.s, 0)
      let t16628 = (t16629 - f2.x.min_realized)
      let t16624 = (t16631 + -7)
      let t16625 = (t16630 + -7)
      let t16622 = (((t16631 - f3.s0.y.min)/8) + 1)
      let t16623 = (((t16630 - f3.s0.x.min)/8) + 1)
      let t16627 = ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1)
      let t16626 = (t16629 + 1)
      gpu_block<CUDA> (f3.s0.y.y_o.__block_id_y, 0, t16622) {
        gpu_block<CUDA> (f3.s0.x.x_o.__block_id_x, 0, t16623) {
          gpu_thread<CUDA> (.__thread_id_y, 0, 8) {
            gpu_thread<CUDA> (.__thread_id_x, 0, 8) {
              let f3.s0.y.y_i.base = min(((f3.s0.y.y_o.__block_id_y*8) + f3.s0.y.min), t16624)
              let f3.s0.x.x_i.base = min(((f3.s0.x.x_o.__block_id_x*8) + f3.s0.x.min), t16625)
              let t15972 = ((((.__thread_id_y + f3.s0.y.y_i.base)*2) - f2.y.min_realized)*t16626)
              let t15979.s = ((((f3.s0.y.y_i.base - f3.y.min_realized) + .__thread_id_y)*t16627) + (f3.s0.x.x_i.base - f3.x.min_realized))
              let t16633 = (t15972 - f2.x.min_realized)
              let t16634 = (t15972 - f2.x.extent_realized.s.s)
              let t16635 = (t15972 + t16628)
              let t16636 = (.__thread_id_x + t15979.s)
              let t16632 = (.__thread_id_x + f3.s0.x.x_i.base)
              for (f3.s0.c, 0, 4) {
                f3[((f3.s0.c*f3.stride.2) + t16636)] = (let t16467 = ((f2.stride.2*f3.s0.c) + ((t16632*2) + t16633)) in (let t16468 = ((f2.stride.2*f3.s0.c) + ((t16632*2) + t16634)) in (let t16469 = ((f2.stride.2*f3.s0.c) + ((t16632*2) + t16635)) in (((((f2[(t16467 + 1)] + (f2[(t16467 + -1)] + (f2[t16467]*2.000000f)))*2.000000f) + (f2[t16468] + (f2[(t16468 + -2)] + (f2[(t16468 + -1)]*2.000000f)))) + (f2[(t16469 + 2)] + (f2[t16469] + (f2[(t16469 + 1)]*2.000000f))))*0.062500f))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f3.buffer, (uint1)1)
    }
  }
  let f4.y.min_realized = min(min(min((((min(normalize.extent.1, 58) + normalize.min.1) + -58)/16), ((min((f5.s0.y.max + -15), f5.s0.y.min)*2) + -1)), (f4.s0.y.max + -31)), f4.s0.y.min)
  let f4.y.extent_realized.s.s = max(max(((min((((normalize.extent.1 + normalize.min.1) + 2)/4), (((normalize.min.1/4) + ((((((normalize.extent.1 + normalize.min.1) + 2)/4) - (normalize.min.1/4))/16)*16)) + 15)) + 3)/4), ((min((((((f5.s0.y.max - f5.s0.y.min)/16)*16) + f5.s0.y.min) + 15), f5.s0.y.max)*2) + 1)), min((((((f4.s0.y.max - f4.s0.y.min)/32)*32) + f4.s0.y.min) + 31), f4.s0.y.max))
  let f4.x.min_realized = min(min(min((((min(normalize.extent.0, 34) + normalize.min.0) + -34)/16), ((min((f5.s0.x.max + -15), f5.s0.x.min)*2) + -1)), (f4.s0.x.max + -31)), f4.s0.x.min)
  let f4.x.extent_realized.s.s = max(max(((min((((normalize.extent.0 + normalize.min.0) + 2)/4), (((normalize.min.0/4) + ((((((normalize.extent.0 + normalize.min.0) + 2)/4) - (normalize.min.0/4))/10)*10)) + 9)) + 3)/4), ((min((((((f5.s0.x.max - f5.s0.x.min)/16)*16) + f5.s0.x.min) + 15), f5.s0.x.max)*2) + 1)), min((((((f4.s0.x.max - f4.s0.x.min)/32)*32) + f4.s0.x.min) + 31), f4.s0.x.max))
  let f4.stride.2 = (((f4.x.extent_realized.s.s - f4.x.min_realized) + 1)*((f4.y.extent_realized.s.s - f4.y.min_realized) + 1))
  allocate f4[float32 * ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1) * ((f4.y.extent_realized.s.s - f4.y.min_realized) + 1) * 4] if (uint1)0
  let f4.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f4.x.min_realized, ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1), 1, 0, f4.y.min_realized, ((f4.y.extent_realized.s.s - f4.y.min_realized) + 1), ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1), 0, 0, 4, f4.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f4.x.min_realized, ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1), 1, 0, f4.y.min_realized, ((f4.y.extent_realized.s.s - f4.y.min_realized) + 1), ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1), 0, 0, 4, f4.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f4.buffer)
  produce f4 {
    consume f3 {
      let halide_device_malloc_result$10 = halide_device_malloc(f4.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$10 == 0), halide_device_malloc_result$10)
      let t16643 = (input.extent.1/16)
      let t16644 = (input.extent.0/16)
      let t16642 = (max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized)
      let t16637 = (((f4.s0.y.max - f4.s0.y.min)/32) + 1)
      let t16638 = (((f4.s0.x.max - f4.s0.x.min)/32) + 1)
      let t16641 = ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1)
      let t16639 = (f4.s0.y.max + -31)
      let t16640 = (f4.s0.x.max + -31)
      gpu_block<CUDA> (f4.s0.y.y_o.__block_id_y, 0, t16637) {
        gpu_block<CUDA> (f4.s0.x.x_o.__block_id_x, 0, t16638) {
          gpu_thread<CUDA> (.__thread_id_y, 0, 32) {
            gpu_thread<CUDA> (.__thread_id_x, 0, 32) {
              let f4.s0.y.y_i.base = min(((f4.s0.y.y_o.__block_id_y*32) + f4.s0.y.min), t16639)
              let f4.s0.x.x_i.base = min(((f4.s0.x.x_o.__block_id_x*32) + f4.s0.x.min), t16640)
              let t15991.s = ((((f4.s0.y.y_i.base - f4.y.min_realized) + .__thread_id_y)*t16641) + (f4.s0.x.x_i.base - f4.x.min_realized))
              let t16647 = (t16642 + 1)
              let t16646 = (.__thread_id_y + f4.s0.y.y_i.base)
              let t16648 = (.__thread_id_x + t15991.s)
              let t16645 = (.__thread_id_x + f4.s0.x.x_i.base)
              for (f4.s0.c, 0, 4) {
                f4[((f4.s0.c*f4.stride.2) + t16648)] = (let t16477.s = min((t16646*2), t16643) in (let t16478.s = min(((t16645*2) + 1), t16644) in (let t16480.s = min(((t16645*2) + -1), t16644) in (let t16481.s = min((t16645*2), t16644) in (let t16482.s = min(((t16646*2) + -1), t16643) in (let t16483.s = min(((t16646*2) + 1), t16643) in (((((f3[((f3.stride.2*f4.s0.c) + (max(t16478.s, 0) + (((max(t16477.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16480.s, 0) + (((max(t16477.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16481.s, 0) + (((max(t16477.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))]*2.000000f)))*2.000000f) + (f3[((f3.stride.2*f4.s0.c) + (max(t16478.s, 0) + (((max(t16482.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16480.s, 0) + (((max(t16482.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16481.s, 0) + (((max(t16482.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))]*2.000000f)))) + (f3[((f3.stride.2*f4.s0.c) + (max(t16478.s, 0) + (((max(t16483.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16480.s, 0) + (((max(t16483.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))] + (f3[((f3.stride.2*f4.s0.c) + (max(t16481.s, 0) + (((max(t16483.s, 0) - f3.y.min_realized)*t16647) - f3.x.min_realized)))]*2.000000f))))*0.062500f)))))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f4.buffer, (uint1)1)
    }
  }
  let f5.y.min_realized = min(min(min((((min(normalize.extent.1, 258) + normalize.min.1) + -258)/32), ((min((f6.s0.y.max + -7), f6.s0.y.min)*2) + -1)), (f5.s0.y.max + -15)), f5.s0.y.min)
  let f5.y.extent_realized.s.s = max(max(min((((normalize.extent.1 + normalize.min.1) + 30)/32), (((normalize.min.1/32) + ((((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))/10)*10)) + 9)), ((min((((((f6.s0.y.max - f6.s0.y.min)/8)*8) + f6.s0.y.min) + 7), f6.s0.y.max)*2) + 1)), min((((((f5.s0.y.max - f5.s0.y.min)/16)*16) + f5.s0.y.min) + 15), f5.s0.y.max))
  let f5.x.min_realized = min(min(min((((min(normalize.extent.0, 450) + normalize.min.0) + -450)/32), ((min((f6.s0.x.max + -7), f6.s0.x.min)*2) + -1)), (f5.s0.x.max + -15)), f5.s0.x.min)
  let f5.x.extent_realized.s.s = max(max(min((((normalize.extent.0 + normalize.min.0) + 30)/32), (((normalize.min.0/32) + ((((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))/16)*16)) + 15)), ((min((((((f6.s0.x.max - f6.s0.x.min)/8)*8) + f6.s0.x.min) + 7), f6.s0.x.max)*2) + 1)), min((((((f5.s0.x.max - f5.s0.x.min)/16)*16) + f5.s0.x.min) + 15), f5.s0.x.max))
  let f5.stride.2 = (((f5.x.extent_realized.s.s - f5.x.min_realized) + 1)*((f5.y.extent_realized.s.s - f5.y.min_realized) + 1))
  allocate f5[float32 * ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1) * ((f5.y.extent_realized.s.s - f5.y.min_realized) + 1) * 4] if (uint1)0
  let f5.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f5.x.min_realized, ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1), 1, 0, f5.y.min_realized, ((f5.y.extent_realized.s.s - f5.y.min_realized) + 1), ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1), 0, 0, 4, f5.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f5.x.min_realized, ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1), 1, 0, f5.y.min_realized, ((f5.y.extent_realized.s.s - f5.y.min_realized) + 1), ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1), 0, 0, 4, f5.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f5.buffer)
  produce f5 {
    consume f4 {
      let halide_device_malloc_result$9 = halide_device_malloc(f5.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$9 == 0), halide_device_malloc_result$9)
      let t16656 = (f4.x.extent_realized.s.s - f4.x.min_realized)
      let t16655 = (t16656 - f4.x.min_realized)
      let t16649 = (((f5.s0.y.max - f5.s0.y.min)/16) + 1)
      let t16650 = (((f5.s0.x.max - f5.s0.x.min)/16) + 1)
      let t16654 = ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1)
      let t16653 = (t16656 + 1)
      let t16651 = (f5.s0.y.max + -15)
      let t16652 = (f5.s0.x.max + -15)
      gpu_block<CUDA> (f5.s0.y.y_o.__block_id_y, 0, t16649) {
        gpu_block<CUDA> (f5.s0.x.x_o.__block_id_x, 0, t16650) {
          gpu_thread<CUDA> (.__thread_id_y, 0, 16) {
            gpu_thread<CUDA> (.__thread_id_x, 0, 16) {
              let f5.s0.y.y_i.base = min(((f5.s0.y.y_o.__block_id_y*16) + f5.s0.y.min), t16651)
              let f5.s0.x.x_i.base = min(((f5.s0.x.x_o.__block_id_x*16) + f5.s0.x.min), t16652)
              let t16001 = ((((.__thread_id_y + f5.s0.y.y_i.base)*2) - f4.y.min_realized)*t16653)
              let t16008.s = ((((f5.s0.y.y_i.base - f5.y.min_realized) + .__thread_id_y)*t16654) + (f5.s0.x.x_i.base - f5.x.min_realized))
              let t16658 = (t16001 - f4.x.min_realized)
              let t16659 = (t16001 - f4.x.extent_realized.s.s)
              let t16660 = (t16001 + t16655)
              let t16661 = (.__thread_id_x + t16008.s)
              let t16657 = (.__thread_id_x + f5.s0.x.x_i.base)
              for (f5.s0.c, 0, 4) {
                f5[((f5.s0.c*f5.stride.2) + t16661)] = (let t16490 = ((f4.stride.2*f5.s0.c) + ((t16657*2) + t16658)) in (let t16491 = ((f4.stride.2*f5.s0.c) + ((t16657*2) + t16659)) in (let t16492 = ((f4.stride.2*f5.s0.c) + ((t16657*2) + t16660)) in (((((f4[(t16490 + 1)] + (f4[(t16490 + -1)] + (f4[t16490]*2.000000f)))*2.000000f) + (f4[t16491] + (f4[(t16491 + -2)] + (f4[(t16491 + -1)]*2.000000f)))) + (f4[(t16492 + 2)] + (f4[t16492] + (f4[(t16492 + 1)]*2.000000f))))*0.062500f))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f5.buffer, (uint1)1)
    }
  }
  let f6.y.min_realized = min(min(min((((min(normalize.extent.1, 258) + normalize.min.1) + -258)/64), ((f7.s0.y.min*2) + -1)), (f6.s0.y.max + -7)), f6.s0.y.min)
  let f6.y.extent_realized.s.s = max(max(((min((((normalize.extent.1 + normalize.min.1) + 30)/32), (((normalize.min.1/32) + ((((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))/10)*10)) + 9)) + 1)/2), ((f7.s0.y.max*2) + 1)), min((((((f6.s0.y.max - f6.s0.y.min)/8)*8) + f6.s0.y.min) + 7), f6.s0.y.max))
  let f6.x.min_realized = min(min(min((((min(normalize.extent.0, 450) + normalize.min.0) + -450)/64), ((f7.s0.x.min*2) + -1)), (f6.s0.x.max + -7)), f6.s0.x.min)
  let f6.x.extent_realized.s.s = max(max(((min((((normalize.extent.0 + normalize.min.0) + 30)/32), (((normalize.min.0/32) + ((((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))/16)*16)) + 15)) + 1)/2), ((f7.s0.x.max*2) + 1)), min((((((f6.s0.x.max - f6.s0.x.min)/8)*8) + f6.s0.x.min) + 7), f6.s0.x.max))
  let f6.stride.2 = (((f6.x.extent_realized.s.s - f6.x.min_realized) + 1)*((f6.y.extent_realized.s.s - f6.y.min_realized) + 1))
  allocate f6[float32 * ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1) * ((f6.y.extent_realized.s.s - f6.y.min_realized) + 1) * 4] if (uint1)0
  let f6.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f6.x.min_realized, ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1), 1, 0, f6.y.min_realized, ((f6.y.extent_realized.s.s - f6.y.min_realized) + 1), ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1), 0, 0, 4, f6.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f6.x.min_realized, ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1), 1, 0, f6.y.min_realized, ((f6.y.extent_realized.s.s - f6.y.min_realized) + 1), ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1), 0, 0, 4, f6.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f6.buffer)
  produce f6 {
    consume f5 {
      let halide_device_malloc_result$8 = halide_device_malloc(f6.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$8 == 0), halide_device_malloc_result$8)
      let t16669 = (f5.x.extent_realized.s.s - f5.x.min_realized)
      let t16668 = (t16669 - f5.x.min_realized)
      let t16662 = (((f6.s0.y.max - f6.s0.y.min)/8) + 1)
      let t16663 = (((f6.s0.x.max - f6.s0.x.min)/8) + 1)
      let t16667 = ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1)
      let t16666 = (t16669 + 1)
      let t16664 = (f6.s0.y.max + -7)
      let t16665 = (f6.s0.x.max + -7)
      gpu_block<CUDA> (f6.s0.y.y_o.__block_id_y, 0, t16662) {
        gpu_block<CUDA> (f6.s0.x.x_o.__block_id_x, 0, t16663) {
          gpu_thread<CUDA> (.__thread_id_y, 0, 8) {
            gpu_thread<CUDA> (.__thread_id_x, 0, 8) {
              let f6.s0.y.y_i.base = min(((f6.s0.y.y_o.__block_id_y*8) + f6.s0.y.min), t16664)
              let f6.s0.x.x_i.base = min(((f6.s0.x.x_o.__block_id_x*8) + f6.s0.x.min), t16665)
              let t16018 = ((((.__thread_id_y + f6.s0.y.y_i.base)*2) - f5.y.min_realized)*t16666)
              let t16025.s = ((((f6.s0.y.y_i.base - f6.y.min_realized) + .__thread_id_y)*t16667) + (f6.s0.x.x_i.base - f6.x.min_realized))
              let t16671 = (t16018 - f5.x.min_realized)
              let t16672 = (t16018 - f5.x.extent_realized.s.s)
              let t16673 = (t16018 + t16668)
              let t16674 = (.__thread_id_x + t16025.s)
              let t16670 = (.__thread_id_x + f6.s0.x.x_i.base)
              for (f6.s0.c, 0, 4) {
                f6[((f6.s0.c*f6.stride.2) + t16674)] = (let t16499 = ((f5.stride.2*f6.s0.c) + ((t16670*2) + t16671)) in (let t16500 = ((f5.stride.2*f6.s0.c) + ((t16670*2) + t16672)) in (let t16501 = ((f5.stride.2*f6.s0.c) + ((t16670*2) + t16673)) in (((((f5[(t16499 + 1)] + (f5[(t16499 + -1)] + (f5[t16499]*2.000000f)))*2.000000f) + (f5[t16500] + (f5[(t16500 + -2)] + (f5[(t16500 + -1)]*2.000000f)))) + (f5[(t16501 + 2)] + (f5[t16501] + (f5[(t16501 + 1)]*2.000000f))))*0.062500f))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f6.buffer, (uint1)1)
    }
  }
  let f7.y.min_realized = min(min((((min(normalize.extent.1, 258) + normalize.min.1) + -258)/128), ((f8.s0.y.min*2) + -1)), f7.s0.y.min)
  let f7.y.extent_realized.s.s = max(max(((min((((normalize.extent.1 + normalize.min.1) + 30)/32), (((normalize.min.1/32) + ((((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))/10)*10)) + 9)) + 3)/4), ((f8.s0.y.max*2) + 1)), f7.s0.y.max)
  let f7.x.min_realized = min(min((((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128), ((f8.s0.x.min*2) + -1)), f7.s0.x.min)
  let f7.x.extent_realized.s.s = max(max(((min((((normalize.extent.0 + normalize.min.0) + 30)/32), (((normalize.min.0/32) + ((((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))/16)*16)) + 15)) + 3)/4), ((f8.s0.x.max*2) + 1)), f7.s0.x.max)
  let f7.stride.2 = (((f7.x.extent_realized.s.s - f7.x.min_realized) + 1)*((f7.y.extent_realized.s.s - f7.y.min_realized) + 1))
  allocate f7[float32 * ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1) * ((f7.y.extent_realized.s.s - f7.y.min_realized) + 1) * 4] if (uint1)0
  let f7.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f7.x.min_realized, ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1), 1, 0, f7.y.min_realized, ((f7.y.extent_realized.s.s - f7.y.min_realized) + 1), ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1), 0, 0, 4, f7.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f7.x.min_realized, ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1), 1, 0, f7.y.min_realized, ((f7.y.extent_realized.s.s - f7.y.min_realized) + 1), ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1), 0, 0, 4, f7.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f7.buffer)
  produce f7 {
    consume f6 {
      let halide_device_malloc_result$7 = halide_device_malloc(f7.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$7 == 0), halide_device_malloc_result$7)
      let t16680 = (f6.x.extent_realized.s.s - f6.x.min_realized)
      let t16679 = (t16680 - f6.x.min_realized)
      let t16677 = ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1)
      let t16675 = ((f7.s0.y.max - f7.s0.y.min) + 1)
      let t16678 = ((f7.s0.x.max - f7.s0.x.min) + 1)
      let t16676 = (t16680 + 1)
      gpu_block<CUDA> (f7.s0.__outermost.v243.__block_id_x, 0, 1) {
        gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
          for (f7.s0.y, f7.s0.y.min, t16675) {
            let t16039 = (((f7.s0.y*2) - f6.y.min_realized)*t16676)
            let t16046.s = ((f7.s0.y - f7.y.min_realized)*t16677)
            let t16684 = (t16046.s - f7.x.min_realized)
            let t16683 = (t16039 - f6.x.min_realized)
            let t16681 = (t16039 - f6.x.extent_realized.s.s)
            let t16682 = (t16039 + t16679)
            for (f7.s0.x, f7.s0.x.min, t16678) {
              let t16058 = ((f7.s0.x*2) + t16681)
              let t16059 = ((f7.s0.x*2) + t16682)
              let t16060 = ((f7.s0.x*2) + t16683)
              let t16691 = (f7.s0.x + t16684)
              for (f7.s0.c, 0, 4) {
                f7[((f7.s0.c*f7.stride.2) + t16691)] = (((((f6[(((f6.stride.2*f7.s0.c) + t16060) + 1)] + (f6[(((f6.stride.2*f7.s0.c) + t16060) + -1)] + (f6[((f6.stride.2*f7.s0.c) + t16060)]*2.000000f)))*2.000000f) + (f6[((f6.stride.2*f7.s0.c) + t16058)] + (f6[(((f6.stride.2*f7.s0.c) + t16058) + -2)] + (f6[(((f6.stride.2*f7.s0.c) + t16058) + -1)]*2.000000f)))) + (f6[(((f6.stride.2*f7.s0.c) + t16059) + 2)] + (f6[((f6.stride.2*f7.s0.c) + t16059)] + (f6[(((f6.stride.2*f7.s0.c) + t16059) + 1)]*2.000000f))))*0.062500f)
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f7.buffer, (uint1)1)
    }
  }
  let f8.stride.2 = (((f8.s0.x.max - f8.s0.x.min) + 1)*((f8.s0.y.max - f8.s0.y.min) + 1))
  allocate f8[float32 * ((f8.s0.x.max - f8.s0.x.min) + 1) * ((f8.s0.y.max - f8.s0.y.min) + 1) * 4] if (uint1)0
  let f8.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), f8.s0.x.min, ((f8.s0.x.max - f8.s0.x.min) + 1), 1, 0, f8.s0.y.min, ((f8.s0.y.max - f8.s0.y.min) + 1), ((f8.s0.x.max - f8.s0.x.min) + 1), 0, 0, 4, f8.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), f8.s0.x.min, ((f8.s0.x.max - f8.s0.x.min) + 1), 1, 0, f8.s0.y.min, ((f8.s0.y.max - f8.s0.y.min) + 1), ((f8.s0.x.max - f8.s0.x.min) + 1), 0, 0, 4, f8.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f8.buffer)
  produce f8 {
    consume f7 {
      let halide_device_malloc_result$6 = halide_device_malloc(f8.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$6 == 0), halide_device_malloc_result$6)
      let t16692 = ((f8.s0.y.max - f8.s0.y.min) + 1)
      let t16693 = ((f8.s0.x.max - f8.s0.x.min) + 1)
      gpu_block<CUDA> (f8.s0.__outermost.v247.__block_id_w, 0, 1) {
        gpu_block<CUDA> (f8.s0.c.__block_id_z, 0, 4) {
          gpu_block<CUDA> (f8.s0.y.__block_id_y, 0, t16692) {
            gpu_block<CUDA> (f8.s0.x.__block_id_x, 0, t16693) {
              gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
                f8[(((f8.s0.c.__block_id_z*f8.stride.2) + (f8.s0.y.__block_id_y*t16693)) + f8.s0.x.__block_id_x)] = (let t16510 = ((((f8.s0.y.__block_id_y + f8.s0.y.min)*2) - f7.y.min_realized)*((f7.x.extent_realized.s.s - f7.x.min_realized) + 1)) in (let t16513 = (((f8.s0.x.__block_id_x + f8.s0.x.min)*2) + (((f7.stride.2*f8.s0.c.__block_id_z) - f7.x.min_realized) + t16510)) in (let t16514 = (((f8.s0.x.__block_id_x + f8.s0.x.min)*2) + (((f7.stride.2*f8.s0.c.__block_id_z) - f7.x.extent_realized.s.s) + t16510)) in (let t16515 = (((f8.s0.x.__block_id_x + f8.s0.x.min)*2) + (((f7.stride.2*f8.s0.c.__block_id_z) + ((f7.x.extent_realized.s.s - f7.x.min_realized) - f7.x.min_realized)) + t16510)) in (((((f7[(t16513 + 1)] + (f7[(t16513 + -1)] + (f7[t16513]*2.000000f)))*2.000000f) + (f7[t16514] + (f7[(t16514 + -2)] + (f7[(t16514 + -1)]*2.000000f)))) + (f7[(t16515 + 2)] + (f7[t16515] + (f7[(t16515 + 1)]*2.000000f))))*0.062500f)))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f8.buffer, (uint1)1)
    }
  }
  let f9.y.extent_realized.s = ((((normalize.extent.1 + normalize.min.1) + 510)/512) - (normalize.min.1/512))
  let f9.x.extent_realized.s = ((((normalize.extent.0 + normalize.min.0) + 510)/512) - (normalize.min.0/512))
  let f9.stride.2 = ((f9.x.extent_realized.s + 1)*(f9.y.extent_realized.s + 1))
  allocate f9[float32 * (f9.x.extent_realized.s + 1) * (f9.y.extent_realized.s + 1) * 4] if (uint1)0
  let f9.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (normalize.min.0/512), (f9.x.extent_realized.s + 1), 1, 0, (normalize.min.1/512), (f9.y.extent_realized.s + 1), (f9.x.extent_realized.s + 1), 0, 0, 4, f9.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (normalize.min.0/512), (f9.x.extent_realized.s + 1), 1, 0, (normalize.min.1/512), (f9.y.extent_realized.s + 1), (f9.x.extent_realized.s + 1), 0, 0, 4, f9.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f9.buffer)
  let f9.s0.y.__block_id_y.loop_extent = ((((normalize.extent.1 + normalize.min.1) + 1022)/512) - (normalize.min.1/512))
  let f9.s0.x.__block_id_x.loop_extent = ((((normalize.extent.0 + normalize.min.0) + 1022)/512) - (normalize.min.0/512))
  produce f9 {
    consume f8 {
      let halide_device_malloc_result$5 = halide_device_malloc(f9.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$5 == 0), halide_device_malloc_result$5)
      let t16696 = (normalize.min.1/512)
      let t16697 = (normalize.min.0/512)
      let t16698 = (f9.x.extent_realized.s + 1)
      gpu_block<CUDA> (f9.s0.__outermost.v251.__block_id_w, 0, 1) {
        gpu_block<CUDA> (f9.s0.c.__block_id_z, 0, 4) {
          gpu_block<CUDA> (f9.s0.y.__block_id_y, 0, f9.s0.y.__block_id_y.loop_extent) {
            gpu_block<CUDA> (f9.s0.x.__block_id_x, 0, f9.s0.x.__block_id_x.loop_extent) {
              gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
                f9[(((f9.s0.c.__block_id_z*f9.stride.2) + (f9.s0.y.__block_id_y*t16698)) + f9.s0.x.__block_id_x)] = (let t16517 = ((((f9.s0.y.__block_id_y + t16696)*2) - f8.s0.y.min)*((f8.s0.x.max - f8.s0.x.min) + 1)) in (let t16520 = (((f9.s0.x.__block_id_x + t16697)*2) + (((f8.stride.2*f9.s0.c.__block_id_z) - f8.s0.x.min) + t16517)) in (let t16521 = (((f9.s0.x.__block_id_x + t16697)*2) + (((f8.stride.2*f9.s0.c.__block_id_z) - f8.s0.x.max) + t16517)) in (let t16522 = (((f9.s0.x.__block_id_x + t16697)*2) + (((f8.stride.2*f9.s0.c.__block_id_z) + ((f8.s0.x.max - f8.s0.x.min) - f8.s0.x.min)) + t16517)) in (((((f8[(t16520 + 1)] + (f8[(t16520 + -1)] + (f8[t16520]*2.000000f)))*2.000000f) + (f8[t16521] + (f8[(t16521 + -2)] + (f8[(t16521 + -1)]*2.000000f)))) + (f8[(t16522 + 2)] + (f8[t16522] + (f8[(t16522 + 1)]*2.000000f))))*0.062500f)))))
              }
            }
          }
        }
      }
      _halide_buffer_set_device_dirty(f9.buffer, (uint1)1)
    }
  }
  let f48.x.extent_realized.s = ((((normalize.extent.0 + normalize.min.0) + 254)/256) - (normalize.min.0/256))
  let f48.stride.2 = ((f48.x.extent_realized.s + 1)*(f9.y.extent_realized.s + 1))
  allocate f48[float32 * (f48.x.extent_realized.s + 1) * (f9.y.extent_realized.s + 1) * 4] if (uint1)0
  let f48.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (normalize.min.0/256), (f48.x.extent_realized.s + 1), 1, 0, (normalize.min.1/512), (f9.y.extent_realized.s + 1), (f48.x.extent_realized.s + 1), 0, 0, 4, f48.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (normalize.min.0/256), (f48.x.extent_realized.s + 1), 1, 0, (normalize.min.1/512), (f9.y.extent_realized.s + 1), (f48.x.extent_realized.s + 1), 0, 0, 4, f48.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f48.buffer)
  let f48.s0.y.__block_id_y.loop_extent = ((((normalize.extent.1 + normalize.min.1) + 1022)/512) - (normalize.min.1/512))
  let f48.s0.x.__block_id_x.loop_extent = ((((normalize.extent.0 + normalize.min.0) + 510)/256) - (normalize.min.0/256))
  produce f48 {
    consume f9 {
      let halide_device_malloc_result$4 = halide_device_malloc(f48.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$4 == 0), halide_device_malloc_result$4)
      let t16704 = (normalize.min.0/256)
      let t16699 = (normalize.min.0/512)
      let t16700 = (f9.x.extent_realized.s + 1)
      let t16703 = (f48.x.extent_realized.s + 1)
      gpu_block<CUDA> (f48.s0.__outermost.v233.__block_id_w, 0, 1) {
        gpu_block<CUDA> (f48.s0.c.__block_id_z, 0, 4) {
          gpu_block<CUDA> (f48.s0.y.__block_id_y, 0, f48.s0.y.__block_id_y.loop_extent) {
            gpu_block<CUDA> (f48.s0.x.__block_id_x, 0, f48.s0.x.__block_id_x.loop_extent) {
              gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
                f48[(((f48.s0.c.__block_id_z*f48.stride.2) + (f48.s0.y.__block_id_y*t16703)) + f48.s0.x.__block_id_x)] = (let t16523 = ((f48.s0.y.__block_id_y*t16700) + ((f48.s0.c.__block_id_z*f9.stride.2) - t16699)) in ((f9[(((f48.s0.x.__block_id_x + t16704)/2) + t16523)] + f9[((((f48.s0.x.__block_id_x + t16704) + 1)/2) + t16523)])*0.500000f))
              }
            }
          }
        }
      }
      let halide_device_free_result$5 = halide_device_free(f9.buffer)
      assert((halide_device_free_result$5 == 0), halide_device_free_result$5)
      free f9
      _halide_buffer_set_device_dirty(f48.buffer, (uint1)1)
    }
  }
  let f28.y.extent_realized.s = ((((normalize.extent.1 + normalize.min.1) + 254)/256) - (normalize.min.1/256))
  let f28.stride.2 = ((f48.x.extent_realized.s + 1)*(f28.y.extent_realized.s + 1))
  allocate f28[float32 * (f48.x.extent_realized.s + 1) * (f28.y.extent_realized.s + 1) * 4] if (uint1)0
  let f28.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (normalize.min.0/256), (f48.x.extent_realized.s + 1), 1, 0, (normalize.min.1/256), (f28.y.extent_realized.s + 1), (f48.x.extent_realized.s + 1), 0, 0, 4, f28.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (normalize.min.0/256), (f48.x.extent_realized.s + 1), 1, 0, (normalize.min.1/256), (f28.y.extent_realized.s + 1), (f48.x.extent_realized.s + 1), 0, 0, 4, f28.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f28.buffer)
  let f28.s0.y.__block_id_y.loop_extent = ((((normalize.extent.1 + normalize.min.1) + 510)/256) - (normalize.min.1/256))
  let f28.s0.x.__block_id_x.loop_extent = ((((normalize.extent.0 + normalize.min.0) + 510)/256) - (normalize.min.0/256))
  produce f28 {
    consume f48 {
      consume f8 {
        let halide_device_malloc_result$3 = halide_device_malloc(f28.buffer, halide_cuda_device_interface())
        assert((halide_device_malloc_result$3 == 0), halide_device_malloc_result$3)
        let t16083.s = ((normalize.min.0/256) + (f8.stride.2*3))
        let t16713 = (normalize.min.1/256)
        let t16710 = (normalize.min.1/512)
        let t16705 = (t16713 - f8.s0.y.min)
        let t16707 = ((normalize.min.0/256) - f8.s0.x.min)
        let t16708 = (t16083.s - f8.s0.x.min)
        let t16706 = ((f8.s0.x.max - f8.s0.x.min) + 1)
        let t16711 = (f48.x.extent_realized.s + 1)
        gpu_block<CUDA> (f28.s0.__outermost.v219.__block_id_w, 0, 1) {
          gpu_block<CUDA> (f28.s0.c.__block_id_z, 0, 4) {
            gpu_block<CUDA> (f28.s0.y.__block_id_y, 0, f28.s0.y.__block_id_y.loop_extent) {
              gpu_block<CUDA> (f28.s0.x.__block_id_x, 0, f28.s0.x.__block_id_x.loop_extent) {
                gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
                  f28[(((f28.s0.c.__block_id_z*f28.stride.2) + (f28.s0.y.__block_id_y*t16711)) + f28.s0.x.__block_id_x)] = (f8[((((f28.s0.y.__block_id_y + t16705)*t16706) + ((f28.s0.c.__block_id_z*f8.stride.2) + t16707)) + f28.s0.x.__block_id_x)] + (((1.000000f - f8[((((f28.s0.y.__block_id_y + t16705)*t16706) + t16708) + f28.s0.x.__block_id_x)])*(f48[(((f28.s0.c.__block_id_z*f48.stride.2) + ((((f28.s0.y.__block_id_y + t16713)/2) - t16710)*t16711)) + f28.s0.x.__block_id_x)] + f48[(((f28.s0.c.__block_id_z*f48.stride.2) + (((((f28.s0.y.__block_id_y + t16713) + 1)/2) - t16710)*t16711)) + f28.s0.x.__block_id_x)]))*0.500000f))
                }
              }
            }
          }
        }
        let halide_device_free_result$6 = halide_device_free(f8.buffer)
        assert((halide_device_free_result$6 == 0), halide_device_free_result$6)
        free f8
        let halide_device_free_result$4 = halide_device_free(f48.buffer)
        assert((halide_device_free_result$4 == 0), halide_device_free_result$4)
        free f48
        _halide_buffer_set_device_dirty(f28.buffer, (uint1)1)
      }
    }
  }
  let f47.y.extent_realized.s = (max(((min((((normalize.extent.1 + normalize.min.1) + 30)/32), (((normalize.min.1/32) + ((((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))/10)*10)) + 9)) + 7)/8), (((normalize.extent.1 + normalize.min.1) + 254)/256)) - (((min(normalize.extent.1, 258) + normalize.min.1) + -258)/256))
  let f47.x.extent_realized.s = (max(((min((((normalize.extent.0 + normalize.min.0) + 30)/32), (((normalize.min.0/32) + ((((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))/16)*16)) + 15)) + 3)/4), (((normalize.extent.0 + normalize.min.0) + 126)/128)) - (((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128))
  let f47.stride.2 = ((f47.x.extent_realized.s + 1)*(f47.y.extent_realized.s + 1))
  allocate f47[float32 * (f47.x.extent_realized.s + 1) * (f47.y.extent_realized.s + 1) * 4] if (uint1)0
  let f47.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128), (f47.x.extent_realized.s + 1), 1, 0, (((min(normalize.extent.1, 258) + normalize.min.1) + -258)/256), (f47.y.extent_realized.s + 1), (f47.x.extent_realized.s + 1), 0, 0, 4, f47.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128), (f47.x.extent_realized.s + 1), 1, 0, (((min(normalize.extent.1, 258) + normalize.min.1) + -258)/256), (f47.y.extent_realized.s + 1), (f47.x.extent_realized.s + 1), 0, 0, 4, f47.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f47.buffer)
  let f47.s0.y.__block_id_y.loop_extent = ((((normalize.extent.1 + normalize.min.1) + 510)/256) - (normalize.min.1/256))
  let f47.s0.x.__block_id_x.loop_extent = ((((normalize.extent.0 + normalize.min.0) + 254)/128) - (normalize.min.0/128))
  produce f47 {
    consume f28 {
      let halide_device_malloc_result$2 = halide_device_malloc(f47.buffer, halide_cuda_device_interface())
      assert((halide_device_malloc_result$2 == 0), halide_device_malloc_result$2)
      let t16095 = ((normalize.min.1/256) - (((min(normalize.extent.1, 258) + normalize.min.1) + -258)/256))
      let t16094 = ((normalize.min.0/128) - (((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128))
      let t16719 = (normalize.min.0/128)
      let t16714 = (normalize.min.0/256)
      let t16715 = (f48.x.extent_realized.s + 1)
      let t16718 = (f47.x.extent_realized.s + 1)
      gpu_block<CUDA> (f47.s0.__outermost.v229.__block_id_w, 0, 1) {
        gpu_block<CUDA> (f47.s0.c.__block_id_z, 0, 4) {
          gpu_block<CUDA> (f47.s0.y.__block_id_y, 0, f47.s0.y.__block_id_y.loop_extent) {
            gpu_block<CUDA> (f47.s0.x.__block_id_x, 0, f47.s0.x.__block_id_x.loop_extent) {
              gpu_thread<CUDA> (.__thread_id_x, 0, 1) {
                f47[((((f47.s0.y.__block_id_y + t16095)*t16718) + ((f47.s0.c.__block_id_z*f47.stride.2) + t16094)) + f47.s0.x.__block_id_x)] = (let t16530 = ((f47.s0.y.__block_id_y*t16715) + ((f28.stride.2*f47.s0.c.__block_id_z) - t16714)) in ((f28[(((f47.s0.x.__block_id_x + t16719)/2) + t16530)] + f28[((((f47.s0.x.__block_id_x + t16719) + 1)/2) + t16530)])*0.500000f))
              }
            }
          }
        }
      }
      let halide_device_free_result$3 = halide_device_free(f28.buffer)
      assert((halide_device_free_result$3 == 0), halide_device_free_result$3)
      free f28
      _halide_buffer_set_device_dirty(f47.buffer, (uint1)1)
    }
  }
  let f25.y.min_realized.s = min((min(normalize.extent.1, 58) + 200), normalize.extent.1)
  let f25.y.extent_realized.s = (max(min((((normalize.extent.1 + normalize.min.1) + 30)/32), (((normalize.min.1/32) + ((((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))/10)*10)) + 9)), ((min((((normalize.extent.1 + normalize.min.1) + 2)/4), (((normalize.min.1/4) + ((((((normalize.extent.1 + normalize.min.1) + 2)/4) - (normalize.min.1/4))/16)*16)) + 15)) + 7)/8)) - (((f25.y.min_realized.s + normalize.min.1) + -258)/32))
  let f25.x.min_realized.s = min((min(normalize.extent.0, 34) + 416), normalize.extent.0)
  let f25.x.extent_realized.s = (max(min((((normalize.extent.0 + normalize.min.0) + 30)/32), (((normalize.min.0/32) + ((((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))/16)*16)) + 15)), ((min((((normalize.extent.0 + normalize.min.0) + 2)/4), (((normalize.min.0/4) + ((((((normalize.extent.0 + normalize.min.0) + 2)/4) - (normalize.min.0/4))/10)*10)) + 9)) + 7)/8)) - (((f25.x.min_realized.s + normalize.min.0) + -450)/32))
  let f25.stride.2 = ((f25.x.extent_realized.s + 1)*(f25.y.extent_realized.s + 1))
  allocate f25[float32 * (f25.x.extent_realized.s + 1) * (f25.y.extent_realized.s + 1) * 4] if (uint1)0
  let f25.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (((f25.x.min_realized.s + normalize.min.0) + -450)/32), (f25.x.extent_realized.s + 1), 1, 0, (((f25.y.min_realized.s + normalize.min.1) + -258)/32), (f25.y.extent_realized.s + 1), (f25.x.extent_realized.s + 1), 0, 0, 4, f25.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (((f25.x.min_realized.s + normalize.min.0) + -450)/32), (f25.x.extent_realized.s + 1), 1, 0, (((f25.y.min_realized.s + normalize.min.1) + -258)/32), (f25.y.extent_realized.s + 1), (f25.x.extent_realized.s + 1), 0, 0, 4, f25.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f25.buffer)
  let f25.s0.x.x_o.loop_extent.s = ((((normalize.extent.0 + normalize.min.0) + 30)/32) - (normalize.min.0/32))
  let f25.s0.y.y_o.loop_extent.s = ((((normalize.extent.1 + normalize.min.1) + 30)/32) - (normalize.min.1/32))
  produce f25 {
    consume f47 {
      consume f7 {
        consume f6 {
          consume f5 {
            let halide_device_malloc_result$1 = halide_device_malloc(f25.buffer, halide_cuda_device_interface())
            assert((halide_device_malloc_result$1 == 0), halide_device_malloc_result$1)
            let t16726 = (((min(normalize.extent.1, 258) + normalize.min.1) + -258)/256)
            let t16729 = (((min(normalize.extent.0, 450) + normalize.min.0) + -450)/128)
            let t16722 = (((normalize.extent.1 + normalize.min.1) + -258)/32)
            let t16724 = (((normalize.extent.0 + normalize.min.0) + -450)/32)
            let t16735 = (((f25.y.min_realized.s + normalize.min.1) + -258)/32)
            let t16734 = (((f25.x.min_realized.s + normalize.min.0) + -450)/32)
            let t16723 = (normalize.min.1/32)
            let t16725 = (normalize.min.0/32)
            let t16730 = ((f7.stride.2*3) - f7.x.min_realized)
            let t16732 = ((f6.stride.2*3) - f6.x.min_realized)
            let t16737 = ((f5.stride.2*3) - f5.x.min_realized)
            let t16720 = ((f25.s0.y.y_o.loop_extent.s/10) + 1)
            let t16721 = ((f25.s0.x.x_o.loop_extent.s/16) + 1)
            let t16728 = ((f7.x.extent_realized.s.s - f7.x.min_realized) + 1)
            let t16731 = ((f6.x.extent_realized.s.s - f6.x.min_realized) + 1)
            let t16733 = ((f5.x.extent_realized.s.s - f5.x.min_realized) + 1)
            let t16727 = (f47.x.extent_realized.s + 1)
            let t16736 = (f25.x.extent_realized.s + 1)
            gpu_block<CUDA> (f25.s0.y.y_o.__block_id_y, 0, t16720) {
              gpu_block<CUDA> (f25.s0.x.x_o.__block_id_x, 0, t16721) {
                allocate __shared[uint8 * 2400] in GPUShared
                gpu_thread<CUDA> (.__thread_id_y, 0, 10) {
                  gpu_thread<CUDA> (.__thread_id_x, 0, 16) {
                    let f25.s0.y.y_i.base = min(((f25.s0.y.y_o.__block_id_y*10) + t16723), t16722)
                    let f25.s0.x.x_i.base = min(((f25.s0.x.x_o.__block_id_x*16) + t16725), t16724)
                    let f27.s0.x.__thread_id_x.loop_extent.s = min(((f25.s0.x.x_o.__block_id_x*16) + t16725), t16724)
                    produce f27 {
                      if ((.__thread_id_y < 4)) {
                        if ((.__thread_id_x < (((f27.s0.x.__thread_id_x.loop_extent.s % 4) + 22)/4))) {
                          let t16120 = (((((f25.s0.y.y_i.base/4) + .__thread_id_y)/2) - t16726)*t16727)
                          let t16121 = ((((((f25.s0.y.y_i.base/4) + .__thread_id_y) + 1)/2) - t16726)*t16727)
                          let t16116 = ((((f25.s0.y.y_i.base/4) - f7.y.min_realized) + .__thread_id_y)*t16728)
                          let t16117 = ((f25.s0.x.x_i.base/4) - t16729)
                          let t16119 = ((f25.s0.x.x_i.base/4) + t16730)
                          let t16742 = (f25.s0.x.x_i.base % 4)
                          let t16738 = ((((f25.s0.x.x_i.base/4) - f7.x.min_realized) + t16116) + .__thread_id_x)
                          let t16741 = ((t16117 + t16121) + .__thread_id_x)
                          let t16740 = ((t16117 + t16120) + .__thread_id_x)
                          let t16739 = ((t16116 + t16119) + .__thread_id_x)
                          for (f27.s0.c, 0, 4) {
                            __shared[(((((t16742 + 22)/4)*f27.s0.c)*4) + ((((t16742 + 22)/4)*.__thread_id_y) + .__thread_id_x))] = (f7[((f27.s0.c*f7.stride.2) + t16738)] + (((1.000000f - f7[t16739])*(f47[((f27.s0.c*f47.stride.2) + t16740)] + f47[((f27.s0.c*f47.stride.2) + t16741)]))*0.500000f))
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    produce f46 {
                      consume f27 {
                        if ((.__thread_id_y < 4)) {
                          if ((.__thread_id_x < 9)) {
                            let t16748 = ((f25.s0.x.x_i.base/2) + .__thread_id_x)
                            let t16745 = (t16748/2)
                            let t16746 = ((t16748 + 1)/2)
                            let t16744 = (f25.s0.x.x_i.base/4)
                            let t16743 = (f25.s0.x.x_i.base % 4)
                            let t16747 = (((.__thread_id_y*9) + .__thread_id_x) + 216)
                            for (f46.s0.c, 0, 4) {
                              __shared[((f46.s0.c*36) + t16747)] = ((__shared[(((((t16743 + 22)/4)*f46.s0.c)*4) + (((((t16743 + 22)/4)*.__thread_id_y) - t16744) + t16745))] + __shared[(((((t16743 + 22)/4)*f46.s0.c)*4) + (((((t16743 + 22)/4)*.__thread_id_y) - t16744) + t16746))])*0.500000f)
                            }
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    produce f26 {
                      consume f46 {
                        if ((.__thread_id_y < 6)) {
                          if ((.__thread_id_x < 9)) {
                            let t16133 = ((((f25.s0.y.y_i.base/2) - f6.y.min_realized) + .__thread_id_y)*t16731)
                            let t16135 = ((f25.s0.x.x_i.base/2) + t16732)
                            let t16136.s = ((((f25.s0.y.y_i.base/2) + .__thread_id_y)/2) - (f25.s0.y.y_i.base/4))
                            let t16137.s = (((((f25.s0.y.y_i.base/2) + .__thread_id_y) + 1)/2) - (f25.s0.y.y_i.base/4))
                            let t16753 = ((.__thread_id_y*9) + .__thread_id_x)
                            let t16752 = (((t16137.s*9) + .__thread_id_x) + 216)
                            let t16751 = (((t16136.s*9) + .__thread_id_x) + 216)
                            let t16749 = ((((f25.s0.x.x_i.base/2) - f6.x.min_realized) + t16133) + .__thread_id_x)
                            let t16750 = ((t16133 + t16135) + .__thread_id_x)
                            for (f26.s0.c, 0, 4) {
                              __shared[((f26.s0.c*54) + t16753)] = (f6[((f26.s0.c*f6.stride.2) + t16749)] + (((1.000000f - f6[t16750])*(__shared[((f26.s0.c*36) + t16751)] + __shared[((f26.s0.c*36) + t16752)]))*0.500000f))
                            }
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    produce f45 {
                      consume f26 {
                        if ((.__thread_id_y < 6)) {
                          let t16143 = ((((f25.s0.x.x_i.base % 2) + .__thread_id_x)/2) + (.__thread_id_y*9))
                          let t16144 = ((((.__thread_id_x + f25.s0.x.x_i.base) + 1)/2) + ((.__thread_id_y*9) - (f25.s0.x.x_i.base/2)))
                          let t16754 = (((.__thread_id_y*16) + .__thread_id_x) + 216)
                          for (f45.s0.c, 0, 4) {
                            __shared[((f45.s0.c*96) + t16754)] = ((__shared[((f45.s0.c*54) + t16143)] + __shared[((f45.s0.c*54) + t16144)])*0.500000f)
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    consume f45 {
                      let t16147 = (((f25.s0.y.y_i.base - f5.y.min_realized) + .__thread_id_y)*t16733)
                      let t16151.s = ((((.__thread_id_y + f25.s0.y.y_i.base) + 1)/2) - (f25.s0.y.y_i.base/2))
                      let t16150.s = (((.__thread_id_y + f25.s0.y.y_i.base)/2) - (f25.s0.y.y_i.base/2))
                      let t16152.s = ((((f25.s0.y.y_i.base - t16735) + .__thread_id_y)*t16736) + (f25.s0.x.x_i.base - t16734))
                      let t16758 = (((t16151.s*16) + .__thread_id_x) + 216)
                      let t16757 = (((t16150.s*16) + .__thread_id_x) + 216)
                      let t16755 = (((f25.s0.x.x_i.base - f5.x.min_realized) + t16147) + .__thread_id_x)
                      let t16756 = (((f25.s0.x.x_i.base + t16737) + t16147) + .__thread_id_x)
                      let t16759 = (.__thread_id_x + t16152.s)
                      for (f25.s0.c, 0, 4) {
                        f25[((f25.s0.c*f25.stride.2) + t16759)] = (f5[((f25.s0.c*f5.stride.2) + t16755)] + (((1.000000f - f5[t16756])*(__shared[((f25.s0.c*96) + t16757)] + __shared[((f25.s0.c*96) + t16758)]))*0.500000f))
                      }
                    }
                  }
                }
                free __shared
              }
            }
            let halide_device_free_result$9 = halide_device_free(f5.buffer)
            assert((halide_device_free_result$9 == 0), halide_device_free_result$9)
            free f5
            let halide_device_free_result$8 = halide_device_free(f6.buffer)
            assert((halide_device_free_result$8 == 0), halide_device_free_result$8)
            free f6
            let halide_device_free_result$7 = halide_device_free(f7.buffer)
            assert((halide_device_free_result$7 == 0), halide_device_free_result$7)
            free f7
            let halide_device_free_result$2 = halide_device_free(f47.buffer)
            assert((halide_device_free_result$2 == 0), halide_device_free_result$2)
            free f47
            _halide_buffer_set_device_dirty(f25.buffer, (uint1)1)
          }
        }
      }
    }
  }
  let f22.y.extent_realized.s = ((((normalize.extent.1 + normalize.min.1) + 2)/4) - (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4))
  let f22.x.extent_realized.s = ((((normalize.extent.0 + normalize.min.0) + 2)/4) - (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4))
  let f22.stride.2 = ((f22.x.extent_realized.s + 1)*(f22.y.extent_realized.s + 1))
  allocate f22[float32 * (f22.x.extent_realized.s + 1) * (f22.y.extent_realized.s + 1) * 4] if (uint1)0
  let f22.buffer = _halide_buffer_init(alloca(size_of_halide_buffer_t()), make_struct((halide_dimension_t *), (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4), (f22.x.extent_realized.s + 1), 1, 0, (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4), (f22.y.extent_realized.s + 1), (f22.x.extent_realized.s + 1), 0, 0, 4, f22.stride.2, 0), reinterpret((void *), (uint64)0), (uint64)0, reinterpret((halide_device_interface_t *), (uint64)0), 2, 32, 3, make_struct((halide_dimension_t *), (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4), (f22.x.extent_realized.s + 1), 1, 0, (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4), (f22.y.extent_realized.s + 1), (f22.x.extent_realized.s + 1), 0, 0, 4, f22.stride.2, 0), (uint64)0)
  register_destructor("halide_device_free_as_destructor", f22.buffer)
  let f22.s0.x.x_o.loop_extent.s = ((((normalize.extent.0 + normalize.min.0) + 2)/4) - (normalize.min.0/4))
  let f22.s0.y.y_o.loop_extent.s = ((((normalize.extent.1 + normalize.min.1) + 2)/4) - (normalize.min.1/4))
  produce f22 {
    consume f25 {
      consume f4 {
        consume f3 {
          consume f2 {
            let halide_device_malloc_result = halide_device_malloc(f22.buffer, halide_cuda_device_interface())
            assert((halide_device_malloc_result == 0), halide_device_malloc_result)
            let t16775 = (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4)
            let t16774 = (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4)
            let t16762 = (((normalize.extent.1 + normalize.min.1) + -58)/4)
            let t16764 = (((normalize.extent.0 + normalize.min.0) + -34)/4)
            let t16767 = (((f25.y.min_realized.s + normalize.min.1) + -258)/32)
            let t16769 = (((f25.x.min_realized.s + normalize.min.0) + -450)/32)
            let t16763 = (normalize.min.1/4)
            let t16765 = (normalize.min.0/4)
            let t16770 = ((f4.stride.2*3) - f4.x.min_realized)
            let t16772 = ((f3.stride.2*3) - f3.x.min_realized)
            let t16777 = ((f2.stride.2*3) - f2.x.min_realized)
            let t16760 = ((f22.s0.y.y_o.loop_extent.s/16) + 1)
            let t16761 = ((f22.s0.x.x_o.loop_extent.s/10) + 1)
            let t16771 = ((max(f3.x.extent_realized.s.s, 0) - f3.x.min_realized) + 1)
            let t16766 = ((f4.x.extent_realized.s.s - f4.x.min_realized) + 1)
            let t16773 = ((f2.x.extent_realized.s.s - f2.x.min_realized) + 1)
            let t16768 = (f25.x.extent_realized.s + 1)
            let t16776 = (f22.x.extent_realized.s + 1)
            gpu_block<CUDA> (f22.s0.y.y_o.__block_id_y, 0, t16760) {
              gpu_block<CUDA> (f22.s0.x.x_o.__block_id_x, 0, t16761) {
                allocate __shared[uint8 * 2304] in GPUShared
                gpu_thread<CUDA> (.__thread_id_y, 0, 16) {
                  gpu_thread<CUDA> (.__thread_id_x, 0, 10) {
                    let f22.s0.y.y_i.base = min(((f22.s0.y.y_o.__block_id_y*16) + t16763), t16762)
                    let f22.s0.x.x_i.base = min(((f22.s0.x.x_o.__block_id_x*10) + t16765), t16764)
                    let f24.s0.y.__thread_id_y.loop_extent.s = min(((f22.s0.y.y_o.__block_id_y*16) + t16763), t16762)
                    produce f24 {
                      if ((.__thread_id_y < (((f24.s0.y.__thread_id_y.loop_extent.s % 4) + 22)/4))) {
                        if ((.__thread_id_x < 4)) {
                          let t16173 = ((((f22.s0.y.y_i.base/4) - f4.y.min_realized) + .__thread_id_y)*t16766)
                          let t16174 = ((((((f22.s0.y.y_i.base/4) + .__thread_id_y)/2) - t16767)*t16768) - t16769)
                          let t16177 = (((((((f22.s0.y.y_i.base/4) + .__thread_id_y) + 1)/2) - t16767)*t16768) - t16769)
                          let t16179 = ((f22.s0.x.x_i.base/4) + t16770)
                          let t16784 = (f22.s0.x.x_i.base/4)
                          let t16785 = (.__thread_id_x + t16784)
                          let t16783 = (((f22.s0.y.y_i.base % 4) + 22)/4)
                          let t16782 = ((.__thread_id_y*4) + .__thread_id_x)
                          let t16780 = (((t16784 - f4.x.min_realized) + t16173) + .__thread_id_x)
                          let t16781 = ((t16173 + t16179) + .__thread_id_x)
                          for (f24.s0.c, 0, 4) {
                            __shared[(((f24.s0.c*t16783)*4) + t16782)] = (f4[((f24.s0.c*f4.stride.2) + t16780)] + (((1.000000f - f4[t16781])*((f25[((f24.s0.c*f25.stride.2) + ((t16785/2) + t16174))] + f25[((f24.s0.c*f25.stride.2) + (((t16785 + 1)/2) + t16174))]) + (f25[((f24.s0.c*f25.stride.2) + ((t16785/2) + t16177))] + f25[((f24.s0.c*f25.stride.2) + (((t16785 + 1)/2) + t16177))])))*0.250000f))
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    let f43.s0.y.__thread_id_y.loop_extent.s = min(((f22.s0.y.y_o.__block_id_y*16) + t16763), t16762)
                    produce f43 {
                      consume f24 {
                        if ((.__thread_id_y < (((f43.s0.y.__thread_id_y.loop_extent.s % 4) + 22)/4))) {
                          if ((.__thread_id_x < 6)) {
                            let t16188 = ((.__thread_id_y*4) - (f22.s0.x.x_i.base/4))
                            let t16790 = ((f22.s0.x.x_i.base/2) + .__thread_id_x)
                            let t16786 = (((f22.s0.y.y_i.base % 4) + 22)/4)
                            let t16787 = ((t16790/2) + t16188)
                            let t16788 = (((t16790 + 1)/2) + t16188)
                            let t16789 = (((.__thread_id_y*6) + .__thread_id_x) + 216)
                            for (f43.s0.c, 0, 4) {
                              __shared[(((f43.s0.c*t16786)*6) + t16789)] = ((__shared[(((f43.s0.c*t16786)*4) + t16787)] + __shared[(((f43.s0.c*t16786)*4) + t16788)])*0.500000f)
                            }
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    produce f23 {
                      consume f43 {
                        if ((.__thread_id_y < 9)) {
                          if ((.__thread_id_x < 6)) {
                            let t16194 = ((((f22.s0.y.y_i.base/2) - f3.y.min_realized) + .__thread_id_y)*t16771)
                            let t16197 = ((f22.s0.x.x_i.base/2) + t16772)
                            let t16198.s = ((((f22.s0.y.y_i.base/2) + .__thread_id_y)/2) - (f22.s0.y.y_i.base/4))
                            let t16199.s = (((((f22.s0.y.y_i.base/2) + .__thread_id_y) + 1)/2) - (f22.s0.y.y_i.base/4))
                            let t16791 = (((f22.s0.y.y_i.base % 4) + 22)/4)
                            let t16796 = ((.__thread_id_y*6) + .__thread_id_x)
                            let t16795 = (((t16199.s*6) + .__thread_id_x) + 216)
                            let t16794 = (((t16198.s*6) + .__thread_id_x) + 216)
                            let t16792 = ((((f22.s0.x.x_i.base/2) - f3.x.min_realized) + t16194) + .__thread_id_x)
                            let t16793 = ((t16194 + t16197) + .__thread_id_x)
                            for (f23.s0.c, 0, 4) {
                              __shared[((f23.s0.c*54) + t16796)] = (f3[((f23.s0.c*f3.stride.2) + t16792)] + (((1.000000f - f3[t16793])*(__shared[(((f23.s0.c*t16791)*6) + t16794)] + __shared[(((f23.s0.c*t16791)*6) + t16795)]))*0.500000f))
                            }
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    produce f42 {
                      consume f23 {
                        if ((.__thread_id_y < 9)) {
                          let t16205 = ((((f22.s0.x.x_i.base % 2) + .__thread_id_x)/2) + (.__thread_id_y*6))
                          let t16206 = ((((.__thread_id_x + f22.s0.x.x_i.base) + 1)/2) + ((.__thread_id_y*6) - (f22.s0.x.x_i.base/2)))
                          let t16797 = (((.__thread_id_y*10) + .__thread_id_x) + 216)
                          for (f42.s0.c, 0, 4) {
                            __shared[((f42.s0.c*90) + t16797)] = ((__shared[((f42.s0.c*54) + t16205)] + __shared[((f42.s0.c*54) + t16206)])*0.500000f)
                          }
                        }
                      }
                    }
                    gpu_thread_barrier()
                    consume f42 {
                      let t16209 = (((f22.s0.y.y_i.base - f2.y.min_realized) + .__thread_id_y)*t16773)
                      let t16213.s = ((((.__thread_id_y + f22.s0.y.y_i.base) + 1)/2) - (f22.s0.y.y_i.base/2))
                      let t16212.s = (((.__thread_id_y + f22.s0.y.y_i.base)/2) - (f22.s0.y.y_i.base/2))
                      let t16214.s = ((((f22.s0.y.y_i.base - t16775) + .__thread_id_y)*t16776) + (f22.s0.x.x_i.base - t16774))
                      let t16801 = (((t16213.s*10) + .__thread_id_x) + 216)
                      let t16800 = (((t16212.s*10) + .__thread_id_x) + 216)
                      let t16798 = (((f22.s0.x.x_i.base - f2.x.min_realized) + t16209) + .__thread_id_x)
                      let t16799 = (((f22.s0.x.x_i.base + t16777) + t16209) + .__thread_id_x)
                      let t16802 = (.__thread_id_x + t16214.s)
                      for (f22.s0.c, 0, 4) {
                        f22[((f22.s0.c*f22.stride.2) + t16802)] = (f2[((f2.stride.2*f22.s0.c) + t16798)] + (((1.000000f - f2[t16799])*(__shared[((f22.s0.c*90) + t16800)] + __shared[((f22.s0.c*90) + t16801)]))*0.500000f))
                      }
                    }
                  }
                }
                free __shared
              }
            }
            let halide_device_free_result$12 = halide_device_free(f2.buffer)
            assert((halide_device_free_result$12 == 0), halide_device_free_result$12)
            free f2
            let halide_device_free_result$11 = halide_device_free(f3.buffer)
            assert((halide_device_free_result$11 == 0), halide_device_free_result$11)
            free f3
            let halide_device_free_result$10 = halide_device_free(f4.buffer)
            assert((halide_device_free_result$10 == 0), halide_device_free_result$10)
            free f4
            let halide_device_free_result$1 = halide_device_free(f25.buffer)
            assert((halide_device_free_result$1 == 0), halide_device_free_result$1)
            free f25
            _halide_buffer_set_device_dirty(f22.buffer, (uint1)1)
          }
        }
      }
    }
  }
  assert(((0 <= normalize.min.2) && ((normalize.extent.2 + normalize.min.2) <= 3)), halide_error_explicit_bounds_too_small("c", "normalize", 0, 2, normalize.min.2, ((normalize.extent.2 + normalize.min.2) + -1)))
  produce normalize {
    consume f22 {
      consume f1 {
        let halide_copy_to_device_result$1 = halide_copy_to_device(normalize.buffer, halide_cuda_device_interface())
        assert((halide_copy_to_device_result$1 == 0), halide_copy_to_device_result$1)
        let t16226 = ((f22.stride.2*3) - (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4))
        let t16225 = ((f22.stride.2*2) - (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4))
        let t16240.s = (((normalize.stride.2*2) + normalize.min.0) - (normalize.min.1*normalize.stride.1))
        let t16238.s = ((normalize.min.0 + normalize.stride.2) - (normalize.min.1*normalize.stride.1))
        let t16224 = (f22.stride.2 - (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4))
        let t16237 = (0 - (normalize.min.1*normalize.stride.1))
        let t16807 = (((min(normalize.extent.1, 58) + normalize.min.1) + -58)/4)
        let t16809 = (((min(normalize.extent.0, 34) + normalize.min.0) + -34)/4)
        let t16803 = ((normalize.extent.1 + 9)/10)
        let t16804 = ((normalize.extent.0 + 15)/16)
        let t16811 = ((f1.stride.2*3) - f1.x.min_realized)
        let t16813 = ((f1.stride.2*2) - f1.x.min_realized)
        let t16825 = (t16240.s - normalize.min.0)
        let t16823 = (t16238.s - normalize.min.0)
        let t16812 = (f1.stride.2 - f1.x.min_realized)
        let t16810 = ((f1.x.extent_realized.s.s - f1.x.min_realized) + 1)
        let t16820 = ((input.extent.1 + input.min.1) + -1)
        let t16818 = ((input.extent.0 + input.min.0) + -1)
        let t16805 = (normalize.extent.1 + -10)
        let t16806 = (normalize.extent.0 + -16)
        let t16808 = (f22.x.extent_realized.s + 1)
        gpu_block<CUDA> (normalize.s0.y.y_o.__block_id_y, 0, t16803) {
          gpu_block<CUDA> (normalize.s0.x.x_o.__block_id_x, 0, t16804) {
            allocate __shared[uint8 * 2400] in GPUShared
            gpu_thread<CUDA> (.__thread_id_y, 0, 10) {
              gpu_thread<CUDA> (.__thread_id_x, 0, 16) {
                let normalize.s0.y.y_i.base.s = min((normalize.s0.y.y_o.__block_id_y*10), t16805)
                let normalize.s0.x.x_i.base.s = min((normalize.s0.x.x_o.__block_id_x*16), t16806)
                produce f41 {
                  if ((.__thread_id_y < 4)) {
                    if ((.__thread_id_x < 9)) {
                      __shared[((.__thread_id_y*9) + .__thread_id_x)] = ((f22[(((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) - t16809))] + f22[((((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x) + 1)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) - t16809))])*0.500000f)
                      __shared[(((.__thread_id_y*9) + .__thread_id_x) + 36)] = ((f22[(((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16224))] + f22[((((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x) + 1)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16224))])*0.500000f)
                      __shared[(((.__thread_id_y*9) + .__thread_id_x) + 72)] = ((f22[(((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16225))] + f22[((((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x) + 1)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16225))])*0.500000f)
                      __shared[(((.__thread_id_y*9) + .__thread_id_x) + 108)] = ((f22[(((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16226))] + f22[((((((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + .__thread_id_x) + 1)/2) + ((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/4) - t16807) + .__thread_id_y)*t16808) + t16226))])*0.500000f)
                    }
                  }
                }
                gpu_thread_barrier()
                produce f21 {
                  consume f41 {
                    if ((.__thread_id_y < 6)) {
                      if ((.__thread_id_x < 9)) {
                        __shared[(((.__thread_id_y*9) + .__thread_id_x) + 384)] = (f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) - f1.x.min_realized)) + .__thread_id_x)] + (((1.000000f - f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16811)) + .__thread_id_x)])*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x)] + __shared[((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x)]))*0.500000f))
                        __shared[(((.__thread_id_y*9) + .__thread_id_x) + 438)] = (f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16812)) + .__thread_id_x)] + (((1.000000f - f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16811)) + .__thread_id_x)])*(__shared[((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 36)] + __shared[(((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 36)]))*0.500000f))
                        __shared[(((.__thread_id_y*9) + .__thread_id_x) + 492)] = (f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16813)) + .__thread_id_x)] + (((1.000000f - f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16811)) + .__thread_id_x)])*(__shared[((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 72)] + __shared[(((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 72)]))*0.500000f))
                        __shared[(((.__thread_id_y*9) + .__thread_id_x) + 546)] = (let t16565 = f1[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) - f1.y.min_realized) + .__thread_id_y)*t16810) + (((normalize.min.0 + normalize.s0.x.x_i.base.s)/2) + t16811)) + .__thread_id_x)] in ((((1.000000f - t16565)*(__shared[((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 108)] + __shared[(((((((((normalize.min.1 + normalize.s0.y.y_i.base.s)/2) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/4))*9) + .__thread_id_x) + 108)]))*0.500000f) + t16565))
                      }
                    }
                  }
                }
                gpu_thread_barrier()
                produce f40 {
                  consume f21 {
                    if ((.__thread_id_y < 6)) {
                      __shared[((.__thread_id_y*16) + .__thread_id_x)] = ((__shared[((((((normalize.min.0 + normalize.s0.x.x_i.base.s) % 2) + .__thread_id_x)/2) + (.__thread_id_y*9)) + 384)] + __shared[(((((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x) + 769)/2) + ((.__thread_id_y*9) - ((normalize.min.0 + normalize.s0.x.x_i.base.s)/2)))])*0.500000f)
                      __shared[(((.__thread_id_y*16) + .__thread_id_x) + 96)] = ((__shared[((((((normalize.min.0 + normalize.s0.x.x_i.base.s) % 2) + .__thread_id_x)/2) + (.__thread_id_y*9)) + 438)] + __shared[(((((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x) + 877)/2) + ((.__thread_id_y*9) - ((normalize.min.0 + normalize.s0.x.x_i.base.s)/2)))])*0.500000f)
                      __shared[(((.__thread_id_y*16) + .__thread_id_x) + 192)] = ((__shared[((((((normalize.min.0 + normalize.s0.x.x_i.base.s) % 2) + .__thread_id_x)/2) + (.__thread_id_y*9)) + 492)] + __shared[(((((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x) + 985)/2) + ((.__thread_id_y*9) - ((normalize.min.0 + normalize.s0.x.x_i.base.s)/2)))])*0.500000f)
                      __shared[(((.__thread_id_y*16) + .__thread_id_x) + 288)] = ((__shared[((((((normalize.min.0 + normalize.s0.x.x_i.base.s) % 2) + .__thread_id_x)/2) + (.__thread_id_y*9)) + 546)] + __shared[(((((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x) + 1093)/2) + ((.__thread_id_y*9) - ((normalize.min.0 + normalize.s0.x.x_i.base.s)/2)))])*0.500000f)
                    }
                  }
                }
                gpu_thread_barrier()
                consume f40 {
                  normalize[(((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y)*normalize.stride.1) + (normalize.s0.x.x_i.base.s + t16237)) + .__thread_id_x)] = (let t16570 = max(min(((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x), t16818), input.min.0) in (let t16573.s = max(min(((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y), t16820), input.min.1) in (let t16574 = input[(((input.stride.1*t16573.s) + (((input.stride.2*3) - (input.min.1*input.stride.1)) - input.min.0)) + t16570)] in (let t16575 = (((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/2)) in (((input[(((input.stride.1*t16573.s) - ((input.min.1*input.stride.1) + input.min.0)) + t16570)]*t16574) + (((1.000000f - t16574)*(__shared[((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x)] + __shared[((t16575*16) + .__thread_id_x)]))*0.500000f))/((((1.000000f - t16574)*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x) + 288)] + __shared[(((t16575*16) + .__thread_id_x) + 288)]))*0.500000f) + t16574))))))
                  normalize[(((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y)*normalize.stride.1) + (normalize.s0.x.x_i.base.s + t16823)) + .__thread_id_x)] = (let t16577 = max(min(((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x), t16818), input.min.0) in (let t16580.s = max(min(((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y), t16820), input.min.1) in (let t16581 = input[(((input.stride.1*t16580.s) + (((input.stride.2*3) - (input.min.1*input.stride.1)) - input.min.0)) + t16577)] in (let t16582 = (((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/2)) in (((input[(((input.stride.1*t16580.s) + ((input.stride.2 - (input.min.1*input.stride.1)) - input.min.0)) + t16577)]*t16581) + (((1.000000f - t16581)*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x) + 96)] + __shared[(((t16582*16) + .__thread_id_x) + 96)]))*0.500000f))/((((1.000000f - t16581)*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x) + 288)] + __shared[(((t16582*16) + .__thread_id_x) + 288)]))*0.500000f) + t16581))))))
                  normalize[(((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y)*normalize.stride.1) + (normalize.s0.x.x_i.base.s + t16825)) + .__thread_id_x)] = (let t16584 = max(min(((normalize.min.0 + normalize.s0.x.x_i.base.s) + .__thread_id_x), t16818), input.min.0) in (let t16587.s = max(min(((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y), t16820), input.min.1) in (let t16588 = input[(((input.stride.1*t16587.s) + (((input.stride.2*3) - (input.min.1*input.stride.1)) - input.min.0)) + t16584)] in (let t16589 = (((((normalize.min.1 + normalize.s0.y.y_i.base.s) + .__thread_id_y) + 1)/2) - ((normalize.min.1 + normalize.s0.y.y_i.base.s)/2)) in (((input[(((input.stride.1*t16587.s) + (((input.stride.2*2) - (input.min.1*input.stride.1)) - input.min.0)) + t16584)]*t16588) + (((1.000000f - t16588)*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x) + 192)] + __shared[(((t16589*16) + .__thread_id_x) + 192)]))*0.500000f))/((((1.000000f - t16588)*(__shared[(((((((normalize.min.1 + normalize.s0.y.y_i.base.s) % 2) + .__thread_id_y)/2)*16) + .__thread_id_x) + 288)] + __shared[(((t16589*16) + .__thread_id_x) + 288)]))*0.500000f) + t16588))))))
                }
              }
            }
            free __shared
          }
        }
        _halide_buffer_set_device_dirty(normalize.buffer, (uint1)1)
        let halide_device_free_result$13 = halide_device_free(f1.buffer)
        assert((halide_device_free_result$13 == 0), halide_device_free_result$13)
        free f1
        let halide_device_free_result = halide_device_free(f22.buffer)
        assert((halide_device_free_result == 0), halide_device_free_result)
        free f22
      }
    }
  }
}


Skipping Hexagon offload...
Constructing CUDA device codegen
Target triple of initial module: x86_64--linux-gnu
Generating llvm bitcode...
Generating llvm bitcode prolog for function interpolate_auto_schedule...
Generating llvm bitcode for function interpolate_auto_schedule...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
Generating llvm bitcode for kernel...
PTX kernel:
//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_61
.address_size 64

	// .globl	kernel_f1_s0_y_y_o___block_id_y // -- Begin function kernel_f1_s0_y_y_o___block_id_y
                                        // @kernel_f1_s0_y_y_o___block_id_y
.visible .entry kernel_f1_s0_y_y_o___block_id_y(
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_13,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_14,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_15,
	.param .u32 kernel_f1_s0_y_y_o___block_id_y_param_16,
	.param .u64 kernel_f1_s0_y_y_o___block_id_y_param_17,
	.param .u64 kernel_f1_s0_y_y_o___block_id_y_param_18
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<79>;
	.reg .b64 	%rd<45>;

// %bb.0:                               // %entry
	ld.param.u32 	%r9, [kernel_f1_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd2, [kernel_f1_s0_y_y_o___block_id_y_param_18];
	cvta.to.global.u64 	%rd3, %rd2;
	ld.param.u32 	%r10, [kernel_f1_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r11, [kernel_f1_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r12, %ctaid.y;
	ld.param.u32 	%r13, [kernel_f1_s0_y_y_o___block_id_y_param_4];
	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r1, %tid.y;
	ld.param.u32 	%r15, [kernel_f1_s0_y_y_o___block_id_y_param_5];
	mov.u32 	%r2, %tid.x;
	ld.param.u32 	%r16, [kernel_f1_s0_y_y_o___block_id_y_param_6];
	shl.b32 	%r17, %r12, 3;
	ld.param.u32 	%r18, [kernel_f1_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r19, %r17, %r9;
	ld.param.u32 	%r20, [kernel_f1_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r21, [kernel_f1_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r3, %r19, %r20;
	ld.param.u32 	%r22, [kernel_f1_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r23, %r14, 3;
	ld.param.u32 	%r24, [kernel_f1_s0_y_y_o___block_id_y_param_11];
	ld.param.u32 	%r25, [kernel_f1_s0_y_y_o___block_id_y_param_16];
	add.s32 	%r26, %r23, %r25;
	ld.param.u32 	%r27, [kernel_f1_s0_y_y_o___block_id_y_param_12];
	min.s32 	%r4, %r26, %r18;
	shl.b32 	%r28, %r3, 1;
	add.s32 	%r29, %r28, %r1;
	min.s32 	%r30, %r29, %r16;
	add.s32 	%r31, %r30, -1;
	max.s32 	%r32, %r31, %r24;
	mul.lo.s32 	%r33, %r32, %r22;
	sub.s32 	%r34, %r15, %r27;
	shl.b32 	%r35, %r1, 3;
	add.s32 	%r36, %r35, %r2;
	add.s32 	%r37, %r4, %r2;
	shl.b32 	%r38, %r37, 1;
	min.s32 	%r39, %r38, %r13;
	add.s32 	%r40, %r39, -1;
	max.s32 	%r41, %r40, %r27;
	add.s32 	%r42, %r13, -1;
	min.s32 	%r43, %r38, %r42;
	max.s32 	%r44, %r43, %r27;
	add.s32 	%r45, %r38, 2;
	min.s32 	%r46, %r45, %r13;
	add.s32 	%r47, %r46, -1;
	max.s32 	%r48, %r47, %r27;
	sub.s32 	%r49, %r33, %r11;
	add.s32 	%r50, %r33, %r34;
	add.s32 	%r51, %r50, %r44;
	mul.wide.s32 	%rd5, %r51, 4;
	add.s64 	%rd6, %rd3, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	add.s32 	%r52, %r50, %r48;
	mul.wide.s32 	%rd7, %r52, 4;
	add.s64 	%rd8, %rd3, %rd7;
	ld.global.nc.f32 	%f2, [%rd8];
	add.s32 	%r53, %r50, %r41;
	mul.wide.s32 	%rd9, %r53, 4;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.nc.f32 	%f3, [%rd10];
	add.s32 	%r54, %r49, %r44;
	mul.wide.s32 	%rd11, %r54, 4;
	add.s64 	%rd12, %rd3, %rd11;
	ld.global.nc.f32 	%f4, [%rd12];
	mul.ftz.f32 	%f5, %f4, %f1;
	add.s32 	%r55, %r49, %r48;
	mul.wide.s32 	%rd13, %r55, 4;
	add.s64 	%rd14, %rd3, %rd13;
	ld.global.nc.f32 	%f6, [%rd14];
	add.s32 	%r56, %r49, %r41;
	mul.wide.s32 	%rd15, %r56, 4;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.nc.f32 	%f7, [%rd16];
	mul.ftz.f32 	%f8, %f7, %f3;
	fma.rn.ftz.f32 	%f9, %f6, %f2, %f8;
	fma.rn.ftz.f32 	%f10, %f5, 0f40000000, %f9;
	mul.ftz.f32 	%f11, %f10, 0f3E800000;
	mul.wide.u32 	%rd17, %r36, 4;
	st.shared.f32 	[%rd17], %f11;
	add.s32 	%r57, %r49, %r21;
	add.s32 	%r58, %r57, %r44;
	mul.wide.s32 	%rd18, %r58, 4;
	add.s64 	%rd19, %rd3, %rd18;
	ld.global.nc.f32 	%f12, [%rd19];
	mul.ftz.f32 	%f13, %f12, %f1;
	add.s32 	%r59, %r57, %r48;
	mul.wide.s32 	%rd20, %r59, 4;
	add.s64 	%rd21, %rd3, %rd20;
	ld.global.nc.f32 	%f14, [%rd21];
	add.s32 	%r60, %r57, %r41;
	mul.wide.s32 	%rd22, %r60, 4;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.nc.f32 	%f15, [%rd23];
	mul.ftz.f32 	%f16, %f15, %f3;
	fma.rn.ftz.f32 	%f17, %f14, %f2, %f16;
	fma.rn.ftz.f32 	%f18, %f13, 0f40000000, %f17;
	mul.ftz.f32 	%f19, %f18, 0f3E800000;
	st.shared.f32 	[%rd17+544], %f19;
	add.s32 	%r61, %r57, %r21;
	add.s32 	%r62, %r61, %r44;
	mul.wide.s32 	%rd24, %r62, 4;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.nc.f32 	%f20, [%rd25];
	mul.ftz.f32 	%f21, %f20, %f1;
	add.s32 	%r63, %r61, %r48;
	mul.wide.s32 	%rd26, %r63, 4;
	add.s64 	%rd27, %rd3, %rd26;
	ld.global.nc.f32 	%f22, [%rd27];
	add.s32 	%r64, %r61, %r41;
	mul.wide.s32 	%rd28, %r64, 4;
	add.s64 	%rd29, %rd3, %rd28;
	ld.global.nc.f32 	%f23, [%rd29];
	mul.ftz.f32 	%f24, %f23, %f3;
	fma.rn.ftz.f32 	%f25, %f22, %f2, %f24;
	fma.rn.ftz.f32 	%f26, %f21, 0f40000000, %f25;
	mul.ftz.f32 	%f27, %f26, 0f3E800000;
	st.shared.f32 	[%rd17+1088], %f27;
	add.s32 	%r65, %r33, %r10;
	add.s32 	%r66, %r65, %r44;
	mul.wide.s32 	%rd30, %r66, 4;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.nc.f32 	%f28, [%rd31];
	add.s32 	%r67, %r65, %r41;
	mul.wide.s32 	%rd32, %r67, 4;
	add.s64 	%rd33, %rd3, %rd32;
	ld.global.nc.f32 	%f29, [%rd33];
	add.s32 	%r68, %r48, %r65;
	mul.wide.s32 	%rd34, %r68, 4;
	add.s64 	%rd35, %rd3, %rd34;
	ld.global.nc.f32 	%f30, [%rd35];
	add.ftz.f32 	%f31, %f29, %f30;
	fma.rn.ftz.f32 	%f32, %f28, 0f40000000, %f31;
	mul.ftz.f32 	%f33, %f32, 0f3E800000;
	st.shared.f32 	[%rd17+1632], %f33;
	bar.sync 	0;
	setp.gt.u32 	%p1, %r1, 7;
	@%p1 bra 	LBB0_2;
// %bb.1:                               // %true_bb
	ld.param.u32 	%r8, [kernel_f1_s0_y_y_o___block_id_y_param_15];
	ld.param.u32 	%r7, [kernel_f1_s0_y_y_o___block_id_y_param_14];
	ld.param.u32 	%r6, [kernel_f1_s0_y_y_o___block_id_y_param_13];
	ld.param.u32 	%r5, [kernel_f1_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd4, [kernel_f1_s0_y_y_o___block_id_y_param_17];
	cvta.to.global.u64 	%rd1, %rd4;
	sub.s32 	%r69, %r1, %r6;
	add.s32 	%r70, %r69, %r3;
	shl.b32 	%r71, %r1, 4;
	add.s32 	%r72, %r71, %r2;
	sub.s32 	%r73, %r2, %r7;
	add.s32 	%r74, %r73, %r4;
	mad.lo.s32 	%r75, %r70, %r5, %r74;
	mul.wide.u32 	%rd36, %r72, 4;
	ld.shared.f32 	%f34, [%rd36+64];
	ld.shared.f32 	%f35, [%rd36];
	ld.shared.f32 	%f36, [%rd36+32];
	fma.rn.ftz.f32 	%f37, %f36, 0f40000000, %f35;
	add.ftz.f32 	%f38, %f34, %f37;
	mul.ftz.f32 	%f39, %f38, 0f3E800000;
	mul.wide.s32 	%rd37, %r75, 4;
	add.s64 	%rd38, %rd1, %rd37;
	st.global.f32 	[%rd38], %f39;
	ld.shared.f32 	%f40, [%rd36+608];
	ld.shared.f32 	%f41, [%rd36+544];
	ld.shared.f32 	%f42, [%rd36+576];
	fma.rn.ftz.f32 	%f43, %f42, 0f40000000, %f41;
	add.ftz.f32 	%f44, %f40, %f43;
	mul.ftz.f32 	%f45, %f44, 0f3E800000;
	add.s32 	%r76, %r75, %r8;
	mul.wide.s32 	%rd39, %r76, 4;
	add.s64 	%rd40, %rd1, %rd39;
	st.global.f32 	[%rd40], %f45;
	ld.shared.f32 	%f46, [%rd36+1152];
	ld.shared.f32 	%f47, [%rd36+1088];
	ld.shared.f32 	%f48, [%rd36+1120];
	fma.rn.ftz.f32 	%f49, %f48, 0f40000000, %f47;
	add.ftz.f32 	%f50, %f46, %f49;
	mul.ftz.f32 	%f51, %f50, 0f3E800000;
	add.s32 	%r77, %r76, %r8;
	mul.wide.s32 	%rd41, %r77, 4;
	add.s64 	%rd42, %rd1, %rd41;
	st.global.f32 	[%rd42], %f51;
	ld.shared.f32 	%f52, [%rd36+1696];
	ld.shared.f32 	%f53, [%rd36+1632];
	ld.shared.f32 	%f54, [%rd36+1664];
	fma.rn.ftz.f32 	%f55, %f54, 0f40000000, %f53;
	add.ftz.f32 	%f56, %f52, %f55;
	mul.ftz.f32 	%f57, %f56, 0f3E800000;
	add.s32 	%r78, %r77, %r8;
	mul.wide.s32 	%rd43, %r78, 4;
	add.s64 	%rd44, %rd1, %rd43;
	st.global.f32 	[%rd44], %f57;
LBB0_2:                                 // %after_bb
	ret;
}
                                        // -- End function
	// .globl	kernel_f2_s0_y_y_o___block_id_y // -- Begin function kernel_f2_s0_y_y_o___block_id_y
.visible .entry kernel_f2_s0_y_y_o___block_id_y(
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f2_s0_y_y_o___block_id_y_param_13,
	.param .u64 kernel_f2_s0_y_y_o___block_id_y_param_14,
	.param .u64 kernel_f2_s0_y_y_o___block_id_y_param_15
)                                       // @kernel_f2_s0_y_y_o___block_id_y
{
	.reg .f32 	%f<73>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<37>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f2_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd1, [kernel_f2_s0_y_y_o___block_id_y_param_15];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f2_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd3, [kernel_f2_s0_y_y_o___block_id_y_param_14];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f2_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r4, [kernel_f2_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r5, %ctaid.y;
	ld.param.u32 	%r6, [kernel_f2_s0_y_y_o___block_id_y_param_4];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.y;
	ld.param.u32 	%r9, [kernel_f2_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r10, [kernel_f2_s0_y_y_o___block_id_y_param_6];
	mov.u32 	%r11, %tid.x;
	shl.b32 	%r12, %r5, 3;
	ld.param.u32 	%r13, [kernel_f2_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r14, %r12, %r9;
	ld.param.u32 	%r15, [kernel_f2_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r16, [kernel_f2_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r17, %r14, %r16;
	ld.param.u32 	%r18, [kernel_f2_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r19, %r7, 3;
	ld.param.u32 	%r20, [kernel_f2_s0_y_y_o___block_id_y_param_11];
	add.s32 	%r21, %r19, %r6;
	ld.param.u32 	%r22, [kernel_f2_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f2_s0_y_y_o___block_id_y_param_13];
	min.s32 	%r24, %r21, %r18;
	add.s32 	%r25, %r17, %r8;
	shl.b32 	%r26, %r25, 1;
	sub.s32 	%r27, %r26, %r4;
	mul.lo.s32 	%r28, %r27, %r20;
	sub.s32 	%r29, %r8, %r15;
	add.s32 	%r30, %r29, %r17;
	add.s32 	%r31, %r24, %r11;
	shl.b32 	%r32, %r31, 1;
	sub.s32 	%r33, %r11, %r13;
	add.s32 	%r34, %r33, %r24;
	mad.lo.s32 	%r35, %r30, %r22, %r34;
	sub.s32 	%r36, %r32, %r3;
	add.s32 	%r37, %r36, %r28;
	sub.s32 	%r38, %r32, %r2;
	add.s32 	%r39, %r38, %r28;
	add.s32 	%r40, %r32, %r23;
	add.s32 	%r41, %r40, %r28;
	mul.wide.s32 	%rd5, %r37, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r39, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r41, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.wide.s32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	add.s32 	%r42, %r32, %r1;
	sub.s32 	%r43, %r42, %r3;
	add.s32 	%r44, %r43, %r28;
	sub.s32 	%r45, %r42, %r2;
	add.s32 	%r46, %r45, %r28;
	add.s32 	%r47, %r42, %r23;
	add.s32 	%r48, %r47, %r28;
	mul.wide.s32 	%rd13, %r44, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f19, [%rd14+4];
	ld.global.nc.f32 	%f20, [%rd14+-4];
	ld.global.nc.f32 	%f21, [%rd14];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	mul.wide.s32 	%rd15, %r46, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f24, [%rd16];
	ld.global.nc.f32 	%f25, [%rd16+-8];
	ld.global.nc.f32 	%f26, [%rd16+-4];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	mul.wide.s32 	%rd17, %r48, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f30, [%rd18+8];
	ld.global.nc.f32 	%f31, [%rd18];
	ld.global.nc.f32 	%f32, [%rd18+4];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s32 	%r49, %r35, %r10;
	mul.wide.s32 	%rd19, %r49, 4;
	add.s64 	%rd20, %rd2, %rd19;
	st.global.f32 	[%rd20], %f36;
	add.s32 	%r50, %r42, %r1;
	sub.s32 	%r51, %r50, %r3;
	add.s32 	%r52, %r51, %r28;
	sub.s32 	%r53, %r50, %r2;
	add.s32 	%r54, %r53, %r28;
	add.s32 	%r55, %r50, %r23;
	add.s32 	%r56, %r55, %r28;
	mul.wide.s32 	%rd21, %r52, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f37, [%rd22+4];
	ld.global.nc.f32 	%f38, [%rd22+-4];
	ld.global.nc.f32 	%f39, [%rd22];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	mul.wide.s32 	%rd23, %r54, 4;
	add.s64 	%rd24, %rd4, %rd23;
	ld.global.nc.f32 	%f42, [%rd24];
	ld.global.nc.f32 	%f43, [%rd24+-8];
	ld.global.nc.f32 	%f44, [%rd24+-4];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	mul.wide.s32 	%rd25, %r56, 4;
	add.s64 	%rd26, %rd4, %rd25;
	ld.global.nc.f32 	%f48, [%rd26+8];
	ld.global.nc.f32 	%f49, [%rd26];
	ld.global.nc.f32 	%f50, [%rd26+4];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	add.s32 	%r57, %r49, %r10;
	mul.wide.s32 	%rd27, %r57, 4;
	add.s64 	%rd28, %rd2, %rd27;
	st.global.f32 	[%rd28], %f54;
	add.s32 	%r58, %r50, %r1;
	sub.s32 	%r59, %r58, %r3;
	add.s32 	%r60, %r59, %r28;
	sub.s32 	%r61, %r58, %r2;
	add.s32 	%r62, %r61, %r28;
	add.s32 	%r63, %r58, %r23;
	add.s32 	%r64, %r63, %r28;
	mul.wide.s32 	%rd29, %r60, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.nc.f32 	%f55, [%rd30+4];
	ld.global.nc.f32 	%f56, [%rd30+-4];
	ld.global.nc.f32 	%f57, [%rd30];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	mul.wide.s32 	%rd31, %r62, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.nc.f32 	%f60, [%rd32];
	ld.global.nc.f32 	%f61, [%rd32+-8];
	ld.global.nc.f32 	%f62, [%rd32+-4];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	mul.wide.s32 	%rd33, %r64, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f66, [%rd34+8];
	ld.global.nc.f32 	%f67, [%rd34];
	ld.global.nc.f32 	%f68, [%rd34+4];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	add.s32 	%r65, %r57, %r10;
	mul.wide.s32 	%rd35, %r65, 4;
	add.s64 	%rd36, %rd2, %rd35;
	st.global.f32 	[%rd36], %f72;
	ret;
}
                                        // -- End function
	// .globl	kernel_f3_s0_y_y_o___block_id_y // -- Begin function kernel_f3_s0_y_y_o___block_id_y
.visible .entry kernel_f3_s0_y_y_o___block_id_y(
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f3_s0_y_y_o___block_id_y_param_13,
	.param .u64 kernel_f3_s0_y_y_o___block_id_y_param_14,
	.param .u64 kernel_f3_s0_y_y_o___block_id_y_param_15
)                                       // @kernel_f3_s0_y_y_o___block_id_y
{
	.reg .f32 	%f<73>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<37>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f3_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd1, [kernel_f3_s0_y_y_o___block_id_y_param_15];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f3_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd3, [kernel_f3_s0_y_y_o___block_id_y_param_14];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f3_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r4, [kernel_f3_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r5, %ctaid.y;
	ld.param.u32 	%r6, [kernel_f3_s0_y_y_o___block_id_y_param_4];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.y;
	ld.param.u32 	%r9, [kernel_f3_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r10, [kernel_f3_s0_y_y_o___block_id_y_param_6];
	mov.u32 	%r11, %tid.x;
	shl.b32 	%r12, %r5, 3;
	ld.param.u32 	%r13, [kernel_f3_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r14, %r12, %r9;
	ld.param.u32 	%r15, [kernel_f3_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r16, [kernel_f3_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r17, %r14, %r16;
	ld.param.u32 	%r18, [kernel_f3_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r19, %r7, 3;
	ld.param.u32 	%r20, [kernel_f3_s0_y_y_o___block_id_y_param_11];
	add.s32 	%r21, %r19, %r6;
	ld.param.u32 	%r22, [kernel_f3_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f3_s0_y_y_o___block_id_y_param_13];
	min.s32 	%r24, %r21, %r18;
	add.s32 	%r25, %r17, %r8;
	shl.b32 	%r26, %r25, 1;
	sub.s32 	%r27, %r26, %r4;
	mul.lo.s32 	%r28, %r27, %r20;
	sub.s32 	%r29, %r8, %r15;
	add.s32 	%r30, %r29, %r17;
	add.s32 	%r31, %r24, %r11;
	shl.b32 	%r32, %r31, 1;
	sub.s32 	%r33, %r11, %r13;
	add.s32 	%r34, %r33, %r24;
	mad.lo.s32 	%r35, %r30, %r22, %r34;
	sub.s32 	%r36, %r32, %r3;
	add.s32 	%r37, %r36, %r28;
	sub.s32 	%r38, %r32, %r2;
	add.s32 	%r39, %r38, %r28;
	add.s32 	%r40, %r32, %r23;
	add.s32 	%r41, %r40, %r28;
	mul.wide.s32 	%rd5, %r37, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r39, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r41, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.wide.s32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	add.s32 	%r42, %r32, %r1;
	sub.s32 	%r43, %r42, %r3;
	add.s32 	%r44, %r43, %r28;
	sub.s32 	%r45, %r42, %r2;
	add.s32 	%r46, %r45, %r28;
	add.s32 	%r47, %r42, %r23;
	add.s32 	%r48, %r47, %r28;
	mul.wide.s32 	%rd13, %r44, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f19, [%rd14+4];
	ld.global.nc.f32 	%f20, [%rd14+-4];
	ld.global.nc.f32 	%f21, [%rd14];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	mul.wide.s32 	%rd15, %r46, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f24, [%rd16];
	ld.global.nc.f32 	%f25, [%rd16+-8];
	ld.global.nc.f32 	%f26, [%rd16+-4];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	mul.wide.s32 	%rd17, %r48, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f30, [%rd18+8];
	ld.global.nc.f32 	%f31, [%rd18];
	ld.global.nc.f32 	%f32, [%rd18+4];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s32 	%r49, %r35, %r10;
	mul.wide.s32 	%rd19, %r49, 4;
	add.s64 	%rd20, %rd2, %rd19;
	st.global.f32 	[%rd20], %f36;
	add.s32 	%r50, %r42, %r1;
	sub.s32 	%r51, %r50, %r3;
	add.s32 	%r52, %r51, %r28;
	sub.s32 	%r53, %r50, %r2;
	add.s32 	%r54, %r53, %r28;
	add.s32 	%r55, %r50, %r23;
	add.s32 	%r56, %r55, %r28;
	mul.wide.s32 	%rd21, %r52, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f37, [%rd22+4];
	ld.global.nc.f32 	%f38, [%rd22+-4];
	ld.global.nc.f32 	%f39, [%rd22];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	mul.wide.s32 	%rd23, %r54, 4;
	add.s64 	%rd24, %rd4, %rd23;
	ld.global.nc.f32 	%f42, [%rd24];
	ld.global.nc.f32 	%f43, [%rd24+-8];
	ld.global.nc.f32 	%f44, [%rd24+-4];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	mul.wide.s32 	%rd25, %r56, 4;
	add.s64 	%rd26, %rd4, %rd25;
	ld.global.nc.f32 	%f48, [%rd26+8];
	ld.global.nc.f32 	%f49, [%rd26];
	ld.global.nc.f32 	%f50, [%rd26+4];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	add.s32 	%r57, %r49, %r10;
	mul.wide.s32 	%rd27, %r57, 4;
	add.s64 	%rd28, %rd2, %rd27;
	st.global.f32 	[%rd28], %f54;
	add.s32 	%r58, %r50, %r1;
	sub.s32 	%r59, %r58, %r3;
	add.s32 	%r60, %r59, %r28;
	sub.s32 	%r61, %r58, %r2;
	add.s32 	%r62, %r61, %r28;
	add.s32 	%r63, %r58, %r23;
	add.s32 	%r64, %r63, %r28;
	mul.wide.s32 	%rd29, %r60, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.nc.f32 	%f55, [%rd30+4];
	ld.global.nc.f32 	%f56, [%rd30+-4];
	ld.global.nc.f32 	%f57, [%rd30];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	mul.wide.s32 	%rd31, %r62, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.nc.f32 	%f60, [%rd32];
	ld.global.nc.f32 	%f61, [%rd32+-8];
	ld.global.nc.f32 	%f62, [%rd32+-4];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	mul.wide.s32 	%rd33, %r64, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f66, [%rd34+8];
	ld.global.nc.f32 	%f67, [%rd34];
	ld.global.nc.f32 	%f68, [%rd34+4];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	add.s32 	%r65, %r57, %r10;
	mul.wide.s32 	%rd35, %r65, 4;
	add.s64 	%rd36, %rd2, %rd35;
	st.global.f32 	[%rd36], %f72;
	ret;
}
                                        // -- End function
	// .globl	kernel_f4_s0_y_y_o___block_id_y // -- Begin function kernel_f4_s0_y_y_o___block_id_y
.visible .entry kernel_f4_s0_y_y_o___block_id_y(
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f4_s0_y_y_o___block_id_y_param_13,
	.param .u64 kernel_f4_s0_y_y_o___block_id_y_param_14,
	.param .u64 kernel_f4_s0_y_y_o___block_id_y_param_15
)                                       // @kernel_f4_s0_y_y_o___block_id_y
{
	.reg .f32 	%f<73>;
	.reg .b32 	%r<108>;
	.reg .b64 	%rd<85>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f4_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd1, [kernel_f4_s0_y_y_o___block_id_y_param_15];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f4_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd3, [kernel_f4_s0_y_y_o___block_id_y_param_14];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f4_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r4, [kernel_f4_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r5, %ctaid.y;
	mov.u32 	%r6, %ctaid.x;
	ld.param.u32 	%r7, [kernel_f4_s0_y_y_o___block_id_y_param_4];
	ld.param.u32 	%r8, [kernel_f4_s0_y_y_o___block_id_y_param_5];
	mov.u32 	%r9, %tid.y;
	ld.param.u32 	%r10, [kernel_f4_s0_y_y_o___block_id_y_param_6];
	mov.u32 	%r11, %tid.x;
	shl.b32 	%r12, %r5, 5;
	ld.param.u32 	%r13, [kernel_f4_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r14, %r12, %r7;
	ld.param.u32 	%r15, [kernel_f4_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r16, [kernel_f4_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r17, %r14, %r15;
	ld.param.u32 	%r18, [kernel_f4_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r19, %r6, 5;
	ld.param.u32 	%r20, [kernel_f4_s0_y_y_o___block_id_y_param_11];
	add.s32 	%r21, %r19, %r4;
	ld.param.u32 	%r22, [kernel_f4_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f4_s0_y_y_o___block_id_y_param_13];
	min.s32 	%r24, %r21, %r16;
	sub.s32 	%r25, %r9, %r13;
	add.s32 	%r26, %r25, %r17;
	add.s32 	%r27, %r20, 1;
	add.s32 	%r28, %r17, %r9;
	add.s32 	%r29, %r24, %r11;
	shl.b32 	%r30, %r28, 1;
	min.s32 	%r31, %r30, %r22;
	shl.b32 	%r32, %r29, 1;
	or.b32  	%r33, %r32, 1;
	min.s32 	%r34, %r33, %r23;
	add.s32 	%r35, %r32, -1;
	min.s32 	%r36, %r35, %r23;
	min.s32 	%r37, %r32, %r23;
	add.s32 	%r38, %r30, -1;
	min.s32 	%r39, %r38, %r22;
	or.b32  	%r40, %r30, 1;
	min.s32 	%r41, %r40, %r22;
	max.s32 	%r42, %r34, 0;
	max.s32 	%r43, %r31, 0;
	sub.s32 	%r44, %r43, %r3;
	mul.lo.s32 	%r45, %r44, %r27;
	sub.s32 	%r46, %r45, %r2;
	max.s32 	%r47, %r36, 0;
	max.s32 	%r48, %r37, 0;
	max.s32 	%r49, %r39, 0;
	sub.s32 	%r50, %r49, %r3;
	mul.lo.s32 	%r51, %r50, %r27;
	sub.s32 	%r52, %r51, %r2;
	max.s32 	%r53, %r41, 0;
	sub.s32 	%r54, %r53, %r3;
	mul.lo.s32 	%r55, %r54, %r27;
	sub.s32 	%r56, %r55, %r2;
	sub.s32 	%r57, %r11, %r10;
	add.s32 	%r58, %r57, %r24;
	mad.lo.s32 	%r59, %r26, %r18, %r58;
	add.s32 	%r60, %r46, %r42;
	mul.wide.s32 	%rd5, %r60, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	add.s32 	%r61, %r46, %r47;
	mul.wide.s32 	%rd7, %r61, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f2, [%rd8];
	add.s32 	%r62, %r46, %r48;
	mul.wide.s32 	%rd9, %r62, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f3, [%rd10];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	add.s32 	%r63, %r52, %r42;
	mul.wide.s32 	%rd11, %r63, 4;
	add.s64 	%rd12, %rd4, %rd11;
	ld.global.nc.f32 	%f6, [%rd12];
	add.s32 	%r64, %r52, %r47;
	mul.wide.s32 	%rd13, %r64, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f7, [%rd14];
	add.s32 	%r65, %r52, %r48;
	mul.wide.s32 	%rd15, %r65, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f8, [%rd16];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	add.s32 	%r66, %r56, %r42;
	mul.wide.s32 	%rd17, %r66, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f12, [%rd18];
	add.s32 	%r67, %r56, %r47;
	mul.wide.s32 	%rd19, %r67, 4;
	add.s64 	%rd20, %rd4, %rd19;
	ld.global.nc.f32 	%f13, [%rd20];
	add.s32 	%r68, %r56, %r48;
	mul.wide.s32 	%rd21, %r68, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f14, [%rd22];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.wide.s32 	%rd23, %r59, 4;
	add.s64 	%rd24, %rd2, %rd23;
	st.global.f32 	[%rd24], %f18;
	add.s32 	%r69, %r46, %r1;
	add.s32 	%r70, %r69, %r42;
	mul.wide.s32 	%rd25, %r70, 4;
	add.s64 	%rd26, %rd4, %rd25;
	ld.global.nc.f32 	%f19, [%rd26];
	add.s32 	%r71, %r69, %r47;
	mul.wide.s32 	%rd27, %r71, 4;
	add.s64 	%rd28, %rd4, %rd27;
	ld.global.nc.f32 	%f20, [%rd28];
	add.s32 	%r72, %r69, %r48;
	mul.wide.s32 	%rd29, %r72, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.nc.f32 	%f21, [%rd30];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	add.s32 	%r73, %r52, %r1;
	add.s32 	%r74, %r73, %r42;
	mul.wide.s32 	%rd31, %r74, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.nc.f32 	%f24, [%rd32];
	add.s32 	%r75, %r73, %r47;
	mul.wide.s32 	%rd33, %r75, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f25, [%rd34];
	add.s32 	%r76, %r73, %r48;
	mul.wide.s32 	%rd35, %r76, 4;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.nc.f32 	%f26, [%rd36];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	add.s32 	%r77, %r56, %r1;
	add.s32 	%r78, %r77, %r42;
	mul.wide.s32 	%rd37, %r78, 4;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.nc.f32 	%f30, [%rd38];
	add.s32 	%r79, %r77, %r47;
	mul.wide.s32 	%rd39, %r79, 4;
	add.s64 	%rd40, %rd4, %rd39;
	ld.global.nc.f32 	%f31, [%rd40];
	add.s32 	%r80, %r77, %r48;
	mul.wide.s32 	%rd41, %r80, 4;
	add.s64 	%rd42, %rd4, %rd41;
	ld.global.nc.f32 	%f32, [%rd42];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s32 	%r81, %r59, %r8;
	mul.wide.s32 	%rd43, %r81, 4;
	add.s64 	%rd44, %rd2, %rd43;
	st.global.f32 	[%rd44], %f36;
	add.s32 	%r82, %r69, %r1;
	add.s32 	%r83, %r82, %r42;
	mul.wide.s32 	%rd45, %r83, 4;
	add.s64 	%rd46, %rd4, %rd45;
	ld.global.nc.f32 	%f37, [%rd46];
	add.s32 	%r84, %r82, %r47;
	mul.wide.s32 	%rd47, %r84, 4;
	add.s64 	%rd48, %rd4, %rd47;
	ld.global.nc.f32 	%f38, [%rd48];
	add.s32 	%r85, %r82, %r48;
	mul.wide.s32 	%rd49, %r85, 4;
	add.s64 	%rd50, %rd4, %rd49;
	ld.global.nc.f32 	%f39, [%rd50];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	add.s32 	%r86, %r73, %r1;
	add.s32 	%r87, %r86, %r42;
	mul.wide.s32 	%rd51, %r87, 4;
	add.s64 	%rd52, %rd4, %rd51;
	ld.global.nc.f32 	%f42, [%rd52];
	add.s32 	%r88, %r86, %r47;
	mul.wide.s32 	%rd53, %r88, 4;
	add.s64 	%rd54, %rd4, %rd53;
	ld.global.nc.f32 	%f43, [%rd54];
	add.s32 	%r89, %r86, %r48;
	mul.wide.s32 	%rd55, %r89, 4;
	add.s64 	%rd56, %rd4, %rd55;
	ld.global.nc.f32 	%f44, [%rd56];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	add.s32 	%r90, %r77, %r1;
	add.s32 	%r91, %r90, %r42;
	mul.wide.s32 	%rd57, %r91, 4;
	add.s64 	%rd58, %rd4, %rd57;
	ld.global.nc.f32 	%f48, [%rd58];
	add.s32 	%r92, %r90, %r47;
	mul.wide.s32 	%rd59, %r92, 4;
	add.s64 	%rd60, %rd4, %rd59;
	ld.global.nc.f32 	%f49, [%rd60];
	add.s32 	%r93, %r90, %r48;
	mul.wide.s32 	%rd61, %r93, 4;
	add.s64 	%rd62, %rd4, %rd61;
	ld.global.nc.f32 	%f50, [%rd62];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	add.s32 	%r94, %r81, %r8;
	mul.wide.s32 	%rd63, %r94, 4;
	add.s64 	%rd64, %rd2, %rd63;
	st.global.f32 	[%rd64], %f54;
	add.s32 	%r95, %r82, %r1;
	add.s32 	%r96, %r95, %r42;
	mul.wide.s32 	%rd65, %r96, 4;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.nc.f32 	%f55, [%rd66];
	add.s32 	%r97, %r95, %r47;
	mul.wide.s32 	%rd67, %r97, 4;
	add.s64 	%rd68, %rd4, %rd67;
	ld.global.nc.f32 	%f56, [%rd68];
	add.s32 	%r98, %r95, %r48;
	mul.wide.s32 	%rd69, %r98, 4;
	add.s64 	%rd70, %rd4, %rd69;
	ld.global.nc.f32 	%f57, [%rd70];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	add.s32 	%r99, %r86, %r1;
	add.s32 	%r100, %r99, %r42;
	mul.wide.s32 	%rd71, %r100, 4;
	add.s64 	%rd72, %rd4, %rd71;
	ld.global.nc.f32 	%f60, [%rd72];
	add.s32 	%r101, %r99, %r47;
	mul.wide.s32 	%rd73, %r101, 4;
	add.s64 	%rd74, %rd4, %rd73;
	ld.global.nc.f32 	%f61, [%rd74];
	add.s32 	%r102, %r99, %r48;
	mul.wide.s32 	%rd75, %r102, 4;
	add.s64 	%rd76, %rd4, %rd75;
	ld.global.nc.f32 	%f62, [%rd76];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	add.s32 	%r103, %r90, %r1;
	add.s32 	%r104, %r103, %r42;
	mul.wide.s32 	%rd77, %r104, 4;
	add.s64 	%rd78, %rd4, %rd77;
	ld.global.nc.f32 	%f66, [%rd78];
	add.s32 	%r105, %r103, %r47;
	mul.wide.s32 	%rd79, %r105, 4;
	add.s64 	%rd80, %rd4, %rd79;
	ld.global.nc.f32 	%f67, [%rd80];
	add.s32 	%r106, %r103, %r48;
	mul.wide.s32 	%rd81, %r106, 4;
	add.s64 	%rd82, %rd4, %rd81;
	ld.global.nc.f32 	%f68, [%rd82];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	add.s32 	%r107, %r94, %r8;
	mul.wide.s32 	%rd83, %r107, 4;
	add.s64 	%rd84, %rd2, %rd83;
	st.global.f32 	[%rd84], %f72;
	ret;
}
                                        // -- End function
	// .globl	kernel_f5_s0_y_y_o___block_id_y // -- Begin function kernel_f5_s0_y_y_o___block_id_y
.visible .entry kernel_f5_s0_y_y_o___block_id_y(
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f5_s0_y_y_o___block_id_y_param_13,
	.param .u64 kernel_f5_s0_y_y_o___block_id_y_param_14,
	.param .u64 kernel_f5_s0_y_y_o___block_id_y_param_15
)                                       // @kernel_f5_s0_y_y_o___block_id_y
{
	.reg .f32 	%f<73>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<37>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f5_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd1, [kernel_f5_s0_y_y_o___block_id_y_param_15];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f5_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd3, [kernel_f5_s0_y_y_o___block_id_y_param_14];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f5_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r4, [kernel_f5_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r5, %ctaid.y;
	ld.param.u32 	%r6, [kernel_f5_s0_y_y_o___block_id_y_param_4];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.y;
	ld.param.u32 	%r9, [kernel_f5_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r10, [kernel_f5_s0_y_y_o___block_id_y_param_6];
	mov.u32 	%r11, %tid.x;
	shl.b32 	%r12, %r5, 4;
	ld.param.u32 	%r13, [kernel_f5_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r14, %r12, %r9;
	ld.param.u32 	%r15, [kernel_f5_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r16, [kernel_f5_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r17, %r14, %r16;
	ld.param.u32 	%r18, [kernel_f5_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r19, %r7, 4;
	ld.param.u32 	%r20, [kernel_f5_s0_y_y_o___block_id_y_param_11];
	add.s32 	%r21, %r19, %r6;
	ld.param.u32 	%r22, [kernel_f5_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f5_s0_y_y_o___block_id_y_param_13];
	min.s32 	%r24, %r21, %r18;
	add.s32 	%r25, %r17, %r8;
	shl.b32 	%r26, %r25, 1;
	sub.s32 	%r27, %r26, %r4;
	mul.lo.s32 	%r28, %r27, %r20;
	sub.s32 	%r29, %r8, %r15;
	add.s32 	%r30, %r29, %r17;
	add.s32 	%r31, %r24, %r11;
	shl.b32 	%r32, %r31, 1;
	sub.s32 	%r33, %r11, %r13;
	add.s32 	%r34, %r33, %r24;
	mad.lo.s32 	%r35, %r30, %r22, %r34;
	sub.s32 	%r36, %r32, %r3;
	add.s32 	%r37, %r36, %r28;
	sub.s32 	%r38, %r32, %r2;
	add.s32 	%r39, %r38, %r28;
	add.s32 	%r40, %r32, %r23;
	add.s32 	%r41, %r40, %r28;
	mul.wide.s32 	%rd5, %r37, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r39, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r41, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.wide.s32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	add.s32 	%r42, %r32, %r1;
	sub.s32 	%r43, %r42, %r3;
	add.s32 	%r44, %r43, %r28;
	sub.s32 	%r45, %r42, %r2;
	add.s32 	%r46, %r45, %r28;
	add.s32 	%r47, %r42, %r23;
	add.s32 	%r48, %r47, %r28;
	mul.wide.s32 	%rd13, %r44, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f19, [%rd14+4];
	ld.global.nc.f32 	%f20, [%rd14+-4];
	ld.global.nc.f32 	%f21, [%rd14];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	mul.wide.s32 	%rd15, %r46, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f24, [%rd16];
	ld.global.nc.f32 	%f25, [%rd16+-8];
	ld.global.nc.f32 	%f26, [%rd16+-4];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	mul.wide.s32 	%rd17, %r48, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f30, [%rd18+8];
	ld.global.nc.f32 	%f31, [%rd18];
	ld.global.nc.f32 	%f32, [%rd18+4];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s32 	%r49, %r35, %r10;
	mul.wide.s32 	%rd19, %r49, 4;
	add.s64 	%rd20, %rd2, %rd19;
	st.global.f32 	[%rd20], %f36;
	add.s32 	%r50, %r42, %r1;
	sub.s32 	%r51, %r50, %r3;
	add.s32 	%r52, %r51, %r28;
	sub.s32 	%r53, %r50, %r2;
	add.s32 	%r54, %r53, %r28;
	add.s32 	%r55, %r50, %r23;
	add.s32 	%r56, %r55, %r28;
	mul.wide.s32 	%rd21, %r52, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f37, [%rd22+4];
	ld.global.nc.f32 	%f38, [%rd22+-4];
	ld.global.nc.f32 	%f39, [%rd22];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	mul.wide.s32 	%rd23, %r54, 4;
	add.s64 	%rd24, %rd4, %rd23;
	ld.global.nc.f32 	%f42, [%rd24];
	ld.global.nc.f32 	%f43, [%rd24+-8];
	ld.global.nc.f32 	%f44, [%rd24+-4];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	mul.wide.s32 	%rd25, %r56, 4;
	add.s64 	%rd26, %rd4, %rd25;
	ld.global.nc.f32 	%f48, [%rd26+8];
	ld.global.nc.f32 	%f49, [%rd26];
	ld.global.nc.f32 	%f50, [%rd26+4];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	add.s32 	%r57, %r49, %r10;
	mul.wide.s32 	%rd27, %r57, 4;
	add.s64 	%rd28, %rd2, %rd27;
	st.global.f32 	[%rd28], %f54;
	add.s32 	%r58, %r50, %r1;
	sub.s32 	%r59, %r58, %r3;
	add.s32 	%r60, %r59, %r28;
	sub.s32 	%r61, %r58, %r2;
	add.s32 	%r62, %r61, %r28;
	add.s32 	%r63, %r58, %r23;
	add.s32 	%r64, %r63, %r28;
	mul.wide.s32 	%rd29, %r60, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.nc.f32 	%f55, [%rd30+4];
	ld.global.nc.f32 	%f56, [%rd30+-4];
	ld.global.nc.f32 	%f57, [%rd30];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	mul.wide.s32 	%rd31, %r62, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.nc.f32 	%f60, [%rd32];
	ld.global.nc.f32 	%f61, [%rd32+-8];
	ld.global.nc.f32 	%f62, [%rd32+-4];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	mul.wide.s32 	%rd33, %r64, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f66, [%rd34+8];
	ld.global.nc.f32 	%f67, [%rd34];
	ld.global.nc.f32 	%f68, [%rd34+4];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	add.s32 	%r65, %r57, %r10;
	mul.wide.s32 	%rd35, %r65, 4;
	add.s64 	%rd36, %rd2, %rd35;
	st.global.f32 	[%rd36], %f72;
	ret;
}
                                        // -- End function
	// .globl	kernel_f6_s0_y_y_o___block_id_y // -- Begin function kernel_f6_s0_y_y_o___block_id_y
.visible .entry kernel_f6_s0_y_y_o___block_id_y(
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f6_s0_y_y_o___block_id_y_param_13,
	.param .u64 kernel_f6_s0_y_y_o___block_id_y_param_14,
	.param .u64 kernel_f6_s0_y_y_o___block_id_y_param_15
)                                       // @kernel_f6_s0_y_y_o___block_id_y
{
	.reg .f32 	%f<73>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<37>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f6_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd1, [kernel_f6_s0_y_y_o___block_id_y_param_15];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f6_s0_y_y_o___block_id_y_param_1];
	ld.param.u64 	%rd3, [kernel_f6_s0_y_y_o___block_id_y_param_14];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f6_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r4, [kernel_f6_s0_y_y_o___block_id_y_param_3];
	mov.u32 	%r5, %ctaid.y;
	ld.param.u32 	%r6, [kernel_f6_s0_y_y_o___block_id_y_param_4];
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.y;
	ld.param.u32 	%r9, [kernel_f6_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r10, [kernel_f6_s0_y_y_o___block_id_y_param_6];
	mov.u32 	%r11, %tid.x;
	shl.b32 	%r12, %r5, 3;
	ld.param.u32 	%r13, [kernel_f6_s0_y_y_o___block_id_y_param_7];
	add.s32 	%r14, %r12, %r9;
	ld.param.u32 	%r15, [kernel_f6_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r16, [kernel_f6_s0_y_y_o___block_id_y_param_9];
	min.s32 	%r17, %r14, %r16;
	ld.param.u32 	%r18, [kernel_f6_s0_y_y_o___block_id_y_param_10];
	shl.b32 	%r19, %r7, 3;
	ld.param.u32 	%r20, [kernel_f6_s0_y_y_o___block_id_y_param_11];
	add.s32 	%r21, %r19, %r6;
	ld.param.u32 	%r22, [kernel_f6_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f6_s0_y_y_o___block_id_y_param_13];
	min.s32 	%r24, %r21, %r18;
	add.s32 	%r25, %r17, %r8;
	shl.b32 	%r26, %r25, 1;
	sub.s32 	%r27, %r26, %r4;
	mul.lo.s32 	%r28, %r27, %r20;
	sub.s32 	%r29, %r8, %r15;
	add.s32 	%r30, %r29, %r17;
	add.s32 	%r31, %r24, %r11;
	shl.b32 	%r32, %r31, 1;
	sub.s32 	%r33, %r11, %r13;
	add.s32 	%r34, %r33, %r24;
	mad.lo.s32 	%r35, %r30, %r22, %r34;
	sub.s32 	%r36, %r32, %r3;
	add.s32 	%r37, %r36, %r28;
	sub.s32 	%r38, %r32, %r2;
	add.s32 	%r39, %r38, %r28;
	add.s32 	%r40, %r32, %r23;
	add.s32 	%r41, %r40, %r28;
	mul.wide.s32 	%rd5, %r37, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r39, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r41, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.wide.s32 	%rd11, %r35, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	add.s32 	%r42, %r32, %r1;
	sub.s32 	%r43, %r42, %r3;
	add.s32 	%r44, %r43, %r28;
	sub.s32 	%r45, %r42, %r2;
	add.s32 	%r46, %r45, %r28;
	add.s32 	%r47, %r42, %r23;
	add.s32 	%r48, %r47, %r28;
	mul.wide.s32 	%rd13, %r44, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f19, [%rd14+4];
	ld.global.nc.f32 	%f20, [%rd14+-4];
	ld.global.nc.f32 	%f21, [%rd14];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	mul.wide.s32 	%rd15, %r46, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f24, [%rd16];
	ld.global.nc.f32 	%f25, [%rd16+-8];
	ld.global.nc.f32 	%f26, [%rd16+-4];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	mul.wide.s32 	%rd17, %r48, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f30, [%rd18+8];
	ld.global.nc.f32 	%f31, [%rd18];
	ld.global.nc.f32 	%f32, [%rd18+4];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s32 	%r49, %r35, %r10;
	mul.wide.s32 	%rd19, %r49, 4;
	add.s64 	%rd20, %rd2, %rd19;
	st.global.f32 	[%rd20], %f36;
	add.s32 	%r50, %r42, %r1;
	sub.s32 	%r51, %r50, %r3;
	add.s32 	%r52, %r51, %r28;
	sub.s32 	%r53, %r50, %r2;
	add.s32 	%r54, %r53, %r28;
	add.s32 	%r55, %r50, %r23;
	add.s32 	%r56, %r55, %r28;
	mul.wide.s32 	%rd21, %r52, 4;
	add.s64 	%rd22, %rd4, %rd21;
	ld.global.nc.f32 	%f37, [%rd22+4];
	ld.global.nc.f32 	%f38, [%rd22+-4];
	ld.global.nc.f32 	%f39, [%rd22];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	mul.wide.s32 	%rd23, %r54, 4;
	add.s64 	%rd24, %rd4, %rd23;
	ld.global.nc.f32 	%f42, [%rd24];
	ld.global.nc.f32 	%f43, [%rd24+-8];
	ld.global.nc.f32 	%f44, [%rd24+-4];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	mul.wide.s32 	%rd25, %r56, 4;
	add.s64 	%rd26, %rd4, %rd25;
	ld.global.nc.f32 	%f48, [%rd26+8];
	ld.global.nc.f32 	%f49, [%rd26];
	ld.global.nc.f32 	%f50, [%rd26+4];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	add.s32 	%r57, %r49, %r10;
	mul.wide.s32 	%rd27, %r57, 4;
	add.s64 	%rd28, %rd2, %rd27;
	st.global.f32 	[%rd28], %f54;
	add.s32 	%r58, %r50, %r1;
	sub.s32 	%r59, %r58, %r3;
	add.s32 	%r60, %r59, %r28;
	sub.s32 	%r61, %r58, %r2;
	add.s32 	%r62, %r61, %r28;
	add.s32 	%r63, %r58, %r23;
	add.s32 	%r64, %r63, %r28;
	mul.wide.s32 	%rd29, %r60, 4;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.nc.f32 	%f55, [%rd30+4];
	ld.global.nc.f32 	%f56, [%rd30+-4];
	ld.global.nc.f32 	%f57, [%rd30];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	mul.wide.s32 	%rd31, %r62, 4;
	add.s64 	%rd32, %rd4, %rd31;
	ld.global.nc.f32 	%f60, [%rd32];
	ld.global.nc.f32 	%f61, [%rd32+-8];
	ld.global.nc.f32 	%f62, [%rd32+-4];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	mul.wide.s32 	%rd33, %r64, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f66, [%rd34+8];
	ld.global.nc.f32 	%f67, [%rd34];
	ld.global.nc.f32 	%f68, [%rd34+4];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	add.s32 	%r65, %r57, %r10;
	mul.wide.s32 	%rd35, %r65, 4;
	add.s64 	%rd36, %rd2, %rd35;
	st.global.f32 	[%rd36], %f72;
	ret;
}
                                        // -- End function
	// .globl	kernel_f7_s0___outermost_v243___block_id_x // -- Begin function kernel_f7_s0___outermost_v243___block_id_x
.visible .entry kernel_f7_s0___outermost_v243___block_id_x(
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_0,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_1,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_2,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_3,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_4,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_5,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_6,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_7,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_8,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_9,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_10,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_11,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_12,
	.param .u32 kernel_f7_s0___outermost_v243___block_id_x_param_13,
	.param .u64 kernel_f7_s0___outermost_v243___block_id_x_param_14,
	.param .u64 kernel_f7_s0___outermost_v243___block_id_x_param_15
)                                       // @kernel_f7_s0___outermost_v243___block_id_x
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<73>;
	.reg .b32 	%r<152>;
	.reg .b64 	%rd<40>;

// %bb.0:                               // %entry
	ld.param.u32 	%r94, [kernel_f7_s0___outermost_v243___block_id_x_param_9];
	setp.lt.s32 	%p1, %r94, 1;
	@%p1 bra 	LBB6_6;
// %bb.1:                               // %"for f7.s0.y.preheader"
	ld.param.u32 	%r92, [kernel_f7_s0___outermost_v243___block_id_x_param_12];
	setp.lt.s32 	%p2, %r92, 1;
	@%p2 bra 	LBB6_6;
// %bb.2:                               // %"for f7.s0.y.preheader.split.us"
	ld.param.u32 	%r93, [kernel_f7_s0___outermost_v243___block_id_x_param_13];
	ld.param.u32 	%r91, [kernel_f7_s0___outermost_v243___block_id_x_param_11];
	ld.param.u32 	%r90, [kernel_f7_s0___outermost_v243___block_id_x_param_10];
	ld.param.u32 	%r89, [kernel_f7_s0___outermost_v243___block_id_x_param_8];
	ld.param.u32 	%r88, [kernel_f7_s0___outermost_v243___block_id_x_param_7];
	ld.param.u32 	%r87, [kernel_f7_s0___outermost_v243___block_id_x_param_6];
	ld.param.u32 	%r136, [kernel_f7_s0___outermost_v243___block_id_x_param_5];
	ld.param.u32 	%r85, [kernel_f7_s0___outermost_v243___block_id_x_param_4];
	ld.param.u32 	%r84, [kernel_f7_s0___outermost_v243___block_id_x_param_3];
	ld.param.u32 	%r83, [kernel_f7_s0___outermost_v243___block_id_x_param_2];
	ld.param.u32 	%r82, [kernel_f7_s0___outermost_v243___block_id_x_param_1];
	ld.param.u32 	%r81, [kernel_f7_s0___outermost_v243___block_id_x_param_0];
	ld.param.u64 	%rd7, [kernel_f7_s0___outermost_v243___block_id_x_param_15];
	cvta.to.global.u64 	%rd1, %rd7;
	ld.param.u64 	%rd8, [kernel_f7_s0___outermost_v243___block_id_x_param_14];
	cvta.to.global.u64 	%rd2, %rd8;
	add.s32 	%r1, %r94, %r136;
	mul.wide.s32 	%rd3, %r87, 4;
	sub.s32 	%r95, %r136, %r89;
	mad.lo.s32 	%r96, %r91, %r95, %r85;
	sub.s32 	%r135, %r96, %r88;
	shl.b32 	%r97, %r87, 1;
	add.s32 	%r98, %r96, %r97;
	sub.s32 	%r134, %r98, %r88;
	mad.lo.s32 	%r99, %r87, 3, %r96;
	sub.s32 	%r133, %r99, %r88;
	shl.b32 	%r5, %r85, 1;
	shl.b32 	%r100, %r136, 1;
	sub.s32 	%r101, %r100, %r84;
	mul.lo.s32 	%r102, %r90, %r101;
	shl.b32 	%r103, %r81, 1;
	add.s32 	%r104, %r102, %r103;
	sub.s32 	%r132, %r104, %r83;
	shl.b32 	%r7, %r90, 1;
	sub.s32 	%r131, %r104, %r82;
	add.s32 	%r123, %r93, %r102;
	add.s32 	%r130, %r123, %r103;
	mul.lo.s32 	%r105, %r81, 3;
	add.s32 	%r106, %r102, %r105;
	sub.s32 	%r129, %r106, %r83;
	sub.s32 	%r128, %r106, %r82;
	add.s32 	%r127, %r123, %r105;
	add.s32 	%r107, %r93, %r81;
	add.s32 	%r126, %r107, %r102;
	add.s32 	%r108, %r81, %r102;
	sub.s32 	%r125, %r108, %r82;
	sub.s32 	%r124, %r108, %r83;
	sub.s32 	%r122, %r102, %r82;
	sub.s32 	%r121, %r102, %r83;
LBB6_3:                                 // %"for f7.s0.y.us"
                                        // =>This Loop Header: Depth=1
                                        //     Child Loop BB6_4 Depth 2
	mul.wide.s32 	%rd9, %r135, 4;
	add.s64 	%rd39, %rd1, %rd9;
	mov.u32 	%r137, %r121;
	mov.u32 	%r138, %r122;
	mov.u32 	%r139, %r123;
	mov.u32 	%r140, %r124;
	mov.u32 	%r141, %r125;
	mov.u32 	%r142, %r126;
	mov.u32 	%r143, %r127;
	mov.u32 	%r144, %r128;
	mov.u32 	%r145, %r129;
	mov.u32 	%r146, %r130;
	mov.u32 	%r147, %r131;
	mov.u32 	%r148, %r132;
	mov.u32 	%r149, %r133;
	mov.u32 	%r150, %r134;
	mov.u32 	%r151, %r92;
LBB6_4:                                 // %"for f7.s0.x.us"
                                        //   Parent Loop BB6_3 Depth=1
                                        // =>  This Inner Loop Header: Depth=2
	add.s32 	%r109, %r5, %r137;
	mul.wide.s32 	%rd10, %r109, 4;
	add.s64 	%rd11, %rd2, %rd10;
	ld.global.nc.f32 	%f1, [%rd11+4];
	ld.global.nc.f32 	%f2, [%rd11+-4];
	ld.global.nc.f32 	%f3, [%rd11];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	add.s32 	%r110, %r5, %r138;
	mul.wide.s32 	%rd12, %r110, 4;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.nc.f32 	%f6, [%rd13];
	ld.global.nc.f32 	%f7, [%rd13+-8];
	ld.global.nc.f32 	%f8, [%rd13+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	add.s32 	%r111, %r5, %r139;
	mul.wide.s32 	%rd14, %r111, 4;
	add.s64 	%rd15, %rd2, %rd14;
	ld.global.nc.f32 	%f12, [%rd15+8];
	ld.global.nc.f32 	%f13, [%rd15];
	ld.global.nc.f32 	%f14, [%rd15+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	st.global.f32 	[%rd39], %f18;
	add.s32 	%r112, %r5, %r140;
	mul.wide.s32 	%rd16, %r112, 4;
	add.s64 	%rd17, %rd2, %rd16;
	ld.global.nc.f32 	%f19, [%rd17+4];
	ld.global.nc.f32 	%f20, [%rd17+-4];
	ld.global.nc.f32 	%f21, [%rd17];
	fma.rn.ftz.f32 	%f22, %f21, 0f40000000, %f20;
	add.ftz.f32 	%f23, %f19, %f22;
	add.s32 	%r113, %r5, %r141;
	mul.wide.s32 	%rd18, %r113, 4;
	add.s64 	%rd19, %rd2, %rd18;
	ld.global.nc.f32 	%f24, [%rd19];
	ld.global.nc.f32 	%f25, [%rd19+-8];
	ld.global.nc.f32 	%f26, [%rd19+-4];
	fma.rn.ftz.f32 	%f27, %f26, 0f40000000, %f25;
	add.ftz.f32 	%f28, %f24, %f27;
	fma.rn.ftz.f32 	%f29, %f23, 0f40000000, %f28;
	add.s32 	%r114, %r5, %r142;
	mul.wide.s32 	%rd20, %r114, 4;
	add.s64 	%rd21, %rd2, %rd20;
	ld.global.nc.f32 	%f30, [%rd21+8];
	ld.global.nc.f32 	%f31, [%rd21];
	ld.global.nc.f32 	%f32, [%rd21+4];
	fma.rn.ftz.f32 	%f33, %f32, 0f40000000, %f31;
	add.ftz.f32 	%f34, %f30, %f33;
	add.ftz.f32 	%f35, %f29, %f34;
	mul.ftz.f32 	%f36, %f35, 0f3D800000;
	add.s64 	%rd22, %rd39, %rd3;
	st.global.f32 	[%rd22], %f36;
	add.s32 	%r115, %r5, %r148;
	mul.wide.s32 	%rd23, %r115, 4;
	add.s64 	%rd24, %rd2, %rd23;
	ld.global.nc.f32 	%f37, [%rd24+4];
	ld.global.nc.f32 	%f38, [%rd24+-4];
	ld.global.nc.f32 	%f39, [%rd24];
	fma.rn.ftz.f32 	%f40, %f39, 0f40000000, %f38;
	add.ftz.f32 	%f41, %f37, %f40;
	add.s32 	%r116, %r5, %r147;
	mul.wide.s32 	%rd25, %r116, 4;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.nc.f32 	%f42, [%rd26];
	ld.global.nc.f32 	%f43, [%rd26+-8];
	ld.global.nc.f32 	%f44, [%rd26+-4];
	fma.rn.ftz.f32 	%f45, %f44, 0f40000000, %f43;
	add.ftz.f32 	%f46, %f42, %f45;
	fma.rn.ftz.f32 	%f47, %f41, 0f40000000, %f46;
	add.s32 	%r117, %r5, %r146;
	mul.wide.s32 	%rd27, %r117, 4;
	add.s64 	%rd28, %rd2, %rd27;
	ld.global.nc.f32 	%f48, [%rd28+8];
	ld.global.nc.f32 	%f49, [%rd28];
	ld.global.nc.f32 	%f50, [%rd28+4];
	fma.rn.ftz.f32 	%f51, %f50, 0f40000000, %f49;
	add.ftz.f32 	%f52, %f48, %f51;
	add.ftz.f32 	%f53, %f47, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3D800000;
	mul.wide.s32 	%rd29, %r150, 4;
	add.s64 	%rd30, %rd1, %rd29;
	st.global.f32 	[%rd30], %f54;
	add.s32 	%r118, %r5, %r145;
	mul.wide.s32 	%rd31, %r118, 4;
	add.s64 	%rd32, %rd2, %rd31;
	ld.global.nc.f32 	%f55, [%rd32+4];
	ld.global.nc.f32 	%f56, [%rd32+-4];
	ld.global.nc.f32 	%f57, [%rd32];
	fma.rn.ftz.f32 	%f58, %f57, 0f40000000, %f56;
	add.ftz.f32 	%f59, %f55, %f58;
	add.s32 	%r119, %r5, %r144;
	mul.wide.s32 	%rd33, %r119, 4;
	add.s64 	%rd34, %rd2, %rd33;
	ld.global.nc.f32 	%f60, [%rd34];
	ld.global.nc.f32 	%f61, [%rd34+-8];
	ld.global.nc.f32 	%f62, [%rd34+-4];
	fma.rn.ftz.f32 	%f63, %f62, 0f40000000, %f61;
	add.ftz.f32 	%f64, %f60, %f63;
	fma.rn.ftz.f32 	%f65, %f59, 0f40000000, %f64;
	add.s32 	%r120, %r5, %r143;
	mul.wide.s32 	%rd35, %r120, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.nc.f32 	%f66, [%rd36+8];
	ld.global.nc.f32 	%f67, [%rd36];
	ld.global.nc.f32 	%f68, [%rd36+4];
	fma.rn.ftz.f32 	%f69, %f68, 0f40000000, %f67;
	add.ftz.f32 	%f70, %f66, %f69;
	add.ftz.f32 	%f71, %f65, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3D800000;
	mul.wide.s32 	%rd37, %r149, 4;
	add.s64 	%rd38, %rd1, %rd37;
	st.global.f32 	[%rd38], %f72;
	add.s32 	%r151, %r151, -1;
	add.s64 	%rd39, %rd39, 4;
	add.s32 	%r150, %r150, 1;
	add.s32 	%r149, %r149, 1;
	add.s32 	%r148, %r148, 2;
	add.s32 	%r147, %r147, 2;
	add.s32 	%r146, %r146, 2;
	add.s32 	%r145, %r145, 2;
	add.s32 	%r144, %r144, 2;
	add.s32 	%r143, %r143, 2;
	add.s32 	%r142, %r142, 2;
	add.s32 	%r141, %r141, 2;
	add.s32 	%r140, %r140, 2;
	add.s32 	%r139, %r139, 2;
	add.s32 	%r138, %r138, 2;
	add.s32 	%r137, %r137, 2;
	setp.ne.s32 	%p3, %r151, 0;
	@%p3 bra 	LBB6_4;
// %bb.5:                               // %"end for f7.s0.x.loopexit.us"
                                        //   in Loop: Header=BB6_3 Depth=1
	add.s32 	%r136, %r136, 1;
	add.s32 	%r135, %r135, %r91;
	add.s32 	%r134, %r134, %r91;
	add.s32 	%r133, %r133, %r91;
	add.s32 	%r132, %r132, %r7;
	add.s32 	%r131, %r131, %r7;
	add.s32 	%r130, %r130, %r7;
	add.s32 	%r129, %r129, %r7;
	add.s32 	%r128, %r128, %r7;
	add.s32 	%r127, %r127, %r7;
	add.s32 	%r126, %r126, %r7;
	add.s32 	%r125, %r125, %r7;
	add.s32 	%r124, %r124, %r7;
	add.s32 	%r123, %r123, %r7;
	add.s32 	%r122, %r122, %r7;
	add.s32 	%r121, %r121, %r7;
	setp.ne.s32 	%p4, %r136, %r1;
	@%p4 bra 	LBB6_3;
LBB6_6:                                 // %"end for f7.s0.y"
	ret;
}
                                        // -- End function
	// .globl	kernel_f8_s0___outermost_v247___block_id_w // -- Begin function kernel_f8_s0___outermost_v247___block_id_w
.visible .entry kernel_f8_s0___outermost_v247___block_id_w(
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_0,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_1,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_2,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_3,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_4,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_5,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_6,
	.param .u32 kernel_f8_s0___outermost_v247___block_id_w_param_7,
	.param .u64 kernel_f8_s0___outermost_v247___block_id_w_param_8,
	.param .u64 kernel_f8_s0___outermost_v247___block_id_w_param_9
)                                       // @kernel_f8_s0___outermost_v247___block_id_w
{
	.reg .f32 	%f<19>;
	.reg .b32 	%r<29>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f8_s0___outermost_v247___block_id_w_param_0];
	ld.param.u64 	%rd1, [kernel_f8_s0___outermost_v247___block_id_w_param_9];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f8_s0___outermost_v247___block_id_w_param_1];
	ld.param.u64 	%rd3, [kernel_f8_s0___outermost_v247___block_id_w_param_8];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f8_s0___outermost_v247___block_id_w_param_2];
	mov.u32 	%r4, %ctaid.z;
	ld.param.u32 	%r5, [kernel_f8_s0___outermost_v247___block_id_w_param_3];
	ld.param.u32 	%r6, [kernel_f8_s0___outermost_v247___block_id_w_param_4];
	mov.u32 	%r7, %ctaid.y;
	mov.u32 	%r8, %ctaid.x;
	ld.param.u32 	%r9, [kernel_f8_s0___outermost_v247___block_id_w_param_5];
	add.s32 	%r10, %r7, %r9;
	ld.param.u32 	%r11, [kernel_f8_s0___outermost_v247___block_id_w_param_6];
	shl.b32 	%r12, %r10, 1;
	ld.param.u32 	%r13, [kernel_f8_s0___outermost_v247___block_id_w_param_7];
	sub.s32 	%r14, %r12, %r5;
	sub.s32 	%r15, %r2, %r3;
	add.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r8, %r6;
	shl.b32 	%r18, %r17, 1;
	mul.lo.s32 	%r19, %r4, %r1;
	mad.lo.s32 	%r20, %r14, %r16, %r18;
	sub.s32 	%r21, %r20, %r3;
	add.s32 	%r22, %r21, %r19;
	sub.s32 	%r23, %r20, %r2;
	add.s32 	%r24, %r23, %r19;
	add.s32 	%r25, %r22, %r15;
	mul.wide.s32 	%rd5, %r22, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r24, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r25, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.lo.s32 	%r26, %r4, %r11;
	mad.lo.s32 	%r27, %r7, %r13, %r26;
	add.s32 	%r28, %r27, %r8;
	mul.wide.s32 	%rd11, %r28, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	ret;
}
                                        // -- End function
	// .globl	kernel_f9_s0___outermost_v251___block_id_w // -- Begin function kernel_f9_s0___outermost_v251___block_id_w
.visible .entry kernel_f9_s0___outermost_v251___block_id_w(
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_0,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_1,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_2,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_3,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_4,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_5,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_6,
	.param .u32 kernel_f9_s0___outermost_v251___block_id_w_param_7,
	.param .u64 kernel_f9_s0___outermost_v251___block_id_w_param_8,
	.param .u64 kernel_f9_s0___outermost_v251___block_id_w_param_9
)                                       // @kernel_f9_s0___outermost_v251___block_id_w
{
	.reg .f32 	%f<19>;
	.reg .b32 	%r<29>;
	.reg .b64 	%rd<13>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f9_s0___outermost_v251___block_id_w_param_0];
	ld.param.u64 	%rd1, [kernel_f9_s0___outermost_v251___block_id_w_param_9];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f9_s0___outermost_v251___block_id_w_param_1];
	ld.param.u64 	%rd3, [kernel_f9_s0___outermost_v251___block_id_w_param_8];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f9_s0___outermost_v251___block_id_w_param_2];
	ld.param.u32 	%r4, [kernel_f9_s0___outermost_v251___block_id_w_param_3];
	mov.u32 	%r5, %ctaid.z;
	ld.param.u32 	%r6, [kernel_f9_s0___outermost_v251___block_id_w_param_4];
	mov.u32 	%r7, %ctaid.y;
	mov.u32 	%r8, %ctaid.x;
	ld.param.u32 	%r9, [kernel_f9_s0___outermost_v251___block_id_w_param_5];
	add.s32 	%r10, %r7, %r9;
	ld.param.u32 	%r11, [kernel_f9_s0___outermost_v251___block_id_w_param_6];
	shl.b32 	%r12, %r10, 1;
	ld.param.u32 	%r13, [kernel_f9_s0___outermost_v251___block_id_w_param_7];
	sub.s32 	%r14, %r12, %r3;
	sub.s32 	%r15, %r1, %r2;
	add.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r8, %r11;
	shl.b32 	%r18, %r17, 1;
	mul.lo.s32 	%r19, %r5, %r4;
	mad.lo.s32 	%r20, %r14, %r16, %r18;
	sub.s32 	%r21, %r20, %r2;
	add.s32 	%r22, %r21, %r19;
	sub.s32 	%r23, %r20, %r1;
	add.s32 	%r24, %r23, %r19;
	add.s32 	%r25, %r22, %r15;
	mul.wide.s32 	%rd5, %r22, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6+4];
	ld.global.nc.f32 	%f2, [%rd6+-4];
	ld.global.nc.f32 	%f3, [%rd6];
	fma.rn.ftz.f32 	%f4, %f3, 0f40000000, %f2;
	add.ftz.f32 	%f5, %f1, %f4;
	mul.wide.s32 	%rd7, %r24, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f6, [%rd8];
	ld.global.nc.f32 	%f7, [%rd8+-8];
	ld.global.nc.f32 	%f8, [%rd8+-4];
	fma.rn.ftz.f32 	%f9, %f8, 0f40000000, %f7;
	add.ftz.f32 	%f10, %f6, %f9;
	fma.rn.ftz.f32 	%f11, %f5, 0f40000000, %f10;
	mul.wide.s32 	%rd9, %r25, 4;
	add.s64 	%rd10, %rd4, %rd9;
	ld.global.nc.f32 	%f12, [%rd10+8];
	ld.global.nc.f32 	%f13, [%rd10];
	ld.global.nc.f32 	%f14, [%rd10+4];
	fma.rn.ftz.f32 	%f15, %f14, 0f40000000, %f13;
	add.ftz.f32 	%f16, %f12, %f15;
	add.ftz.f32 	%f17, %f11, %f16;
	mul.ftz.f32 	%f18, %f17, 0f3D800000;
	mul.lo.s32 	%r26, %r5, %r6;
	mad.lo.s32 	%r27, %r7, %r13, %r26;
	add.s32 	%r28, %r27, %r8;
	mul.wide.s32 	%rd11, %r28, 4;
	add.s64 	%rd12, %rd2, %rd11;
	st.global.f32 	[%rd12], %f18;
	ret;
}
                                        // -- End function
	// .globl	kernel_f48_s0___outermost_v233___block_id_w // -- Begin function kernel_f48_s0___outermost_v233___block_id_w
.visible .entry kernel_f48_s0___outermost_v233___block_id_w(
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_0,
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_1,
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_2,
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_3,
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_4,
	.param .u32 kernel_f48_s0___outermost_v233___block_id_w_param_5,
	.param .u64 kernel_f48_s0___outermost_v233___block_id_w_param_6,
	.param .u64 kernel_f48_s0___outermost_v233___block_id_w_param_7
)                                       // @kernel_f48_s0___outermost_v233___block_id_w
{
	.reg .f32 	%f<5>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<11>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f48_s0___outermost_v233___block_id_w_param_0];
	ld.param.u64 	%rd1, [kernel_f48_s0___outermost_v233___block_id_w_param_7];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f48_s0___outermost_v233___block_id_w_param_1];
	ld.param.u64 	%rd3, [kernel_f48_s0___outermost_v233___block_id_w_param_6];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f48_s0___outermost_v233___block_id_w_param_2];
	ld.param.u32 	%r4, [kernel_f48_s0___outermost_v233___block_id_w_param_3];
	mov.u32 	%r5, %ctaid.z;
	ld.param.u32 	%r6, [kernel_f48_s0___outermost_v233___block_id_w_param_4];
	mov.u32 	%r7, %ctaid.y;
	ld.param.u32 	%r8, [kernel_f48_s0___outermost_v233___block_id_w_param_5];
	mov.u32 	%r9, %ctaid.x;
	mul.lo.s32 	%r10, %r5, %r2;
	sub.s32 	%r11, %r10, %r3;
	mad.lo.s32 	%r12, %r7, %r4, %r11;
	add.s32 	%r13, %r9, %r8;
	shr.s32 	%r14, %r13, 1;
	add.s32 	%r15, %r14, %r12;
	mul.wide.s32 	%rd5, %r15, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	add.s32 	%r16, %r13, 1;
	shr.s32 	%r17, %r16, 1;
	add.s32 	%r18, %r17, %r12;
	mul.wide.s32 	%rd7, %r18, 4;
	add.s64 	%rd8, %rd2, %rd7;
	ld.global.nc.f32 	%f2, [%rd8];
	add.ftz.f32 	%f3, %f1, %f2;
	mul.ftz.f32 	%f4, %f3, 0f3F000000;
	mul.lo.s32 	%r19, %r5, %r1;
	mad.lo.s32 	%r20, %r7, %r6, %r19;
	add.s32 	%r21, %r20, %r9;
	mul.wide.s32 	%rd9, %r21, 4;
	add.s64 	%rd10, %rd4, %rd9;
	st.global.f32 	[%rd10], %f4;
	ret;
}
                                        // -- End function
	// .globl	kernel_f28_s0___outermost_v219___block_id_w // -- Begin function kernel_f28_s0___outermost_v219___block_id_w
.visible .entry kernel_f28_s0___outermost_v219___block_id_w(
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_0,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_1,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_2,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_3,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_4,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_5,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_6,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_7,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_8,
	.param .u32 kernel_f28_s0___outermost_v219___block_id_w_param_9,
	.param .u64 kernel_f28_s0___outermost_v219___block_id_w_param_10,
	.param .u64 kernel_f28_s0___outermost_v219___block_id_w_param_11,
	.param .u64 kernel_f28_s0___outermost_v219___block_id_w_param_12
)                                       // @kernel_f28_s0___outermost_v219___block_id_w
{
	.reg .f32 	%f<9>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<17>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f28_s0___outermost_v219___block_id_w_param_0];
	ld.param.u64 	%rd1, [kernel_f28_s0___outermost_v219___block_id_w_param_12];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f28_s0___outermost_v219___block_id_w_param_1];
	ld.param.u64 	%rd3, [kernel_f28_s0___outermost_v219___block_id_w_param_11];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f28_s0___outermost_v219___block_id_w_param_2];
	ld.param.u64 	%rd5, [kernel_f28_s0___outermost_v219___block_id_w_param_10];
	cvta.to.global.u64 	%rd6, %rd5;
	ld.param.u32 	%r4, [kernel_f28_s0___outermost_v219___block_id_w_param_3];
	mov.u32 	%r5, %ctaid.z;
	ld.param.u32 	%r6, [kernel_f28_s0___outermost_v219___block_id_w_param_4];
	ld.param.u32 	%r7, [kernel_f28_s0___outermost_v219___block_id_w_param_5];
	mov.u32 	%r8, %ctaid.y;
	ld.param.u32 	%r9, [kernel_f28_s0___outermost_v219___block_id_w_param_6];
	mov.u32 	%r10, %ctaid.x;
	add.s32 	%r11, %r8, %r4;
	ld.param.u32 	%r12, [kernel_f28_s0___outermost_v219___block_id_w_param_7];
	ld.param.u32 	%r13, [kernel_f28_s0___outermost_v219___block_id_w_param_8];
	ld.param.u32 	%r14, [kernel_f28_s0___outermost_v219___block_id_w_param_9];
	mad.lo.s32 	%r15, %r11, %r6, %r10;
	add.s32 	%r16, %r15, %r7;
	mad.lo.s32 	%r17, %r5, %r3, %r16;
	mul.wide.s32 	%rd7, %r17, 4;
	add.s64 	%rd8, %rd2, %rd7;
	ld.global.nc.f32 	%f1, [%rd8];
	add.s32 	%r18, %r15, %r9;
	mul.wide.s32 	%rd9, %r18, 4;
	add.s64 	%rd10, %rd2, %rd9;
	ld.global.nc.f32 	%f2, [%rd10];
	add.s32 	%r19, %r8, %r14;
	shr.s32 	%r20, %r19, 1;
	sub.s32 	%r21, %r20, %r12;
	mad.lo.s32 	%r22, %r5, %r2, %r10;
	mad.lo.s32 	%r23, %r21, %r13, %r22;
	mul.wide.s32 	%rd11, %r23, 4;
	add.s64 	%rd12, %rd4, %rd11;
	ld.global.nc.f32 	%f3, [%rd12];
	add.s32 	%r24, %r19, 1;
	shr.s32 	%r25, %r24, 1;
	sub.s32 	%r26, %r25, %r12;
	mad.lo.s32 	%r27, %r26, %r13, %r22;
	mul.wide.s32 	%rd13, %r27, 4;
	add.s64 	%rd14, %rd4, %rd13;
	ld.global.nc.f32 	%f4, [%rd14];
	add.ftz.f32 	%f5, %f3, %f4;
	neg.ftz.f32 	%f6, %f2;
	fma.rn.ftz.f32 	%f7, %f6, %f5, %f5;
	fma.rn.ftz.f32 	%f8, %f7, 0f3F000000, %f1;
	mul.lo.s32 	%r28, %r5, %r1;
	mad.lo.s32 	%r29, %r8, %r13, %r28;
	add.s32 	%r30, %r29, %r10;
	mul.wide.s32 	%rd15, %r30, 4;
	add.s64 	%rd16, %rd6, %rd15;
	st.global.f32 	[%rd16], %f8;
	ret;
}
                                        // -- End function
	// .globl	kernel_f47_s0___outermost_v229___block_id_w // -- Begin function kernel_f47_s0___outermost_v229___block_id_w
.visible .entry kernel_f47_s0___outermost_v229___block_id_w(
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_0,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_1,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_2,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_3,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_4,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_5,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_6,
	.param .u32 kernel_f47_s0___outermost_v229___block_id_w_param_7,
	.param .u64 kernel_f47_s0___outermost_v229___block_id_w_param_8,
	.param .u64 kernel_f47_s0___outermost_v229___block_id_w_param_9
)                                       // @kernel_f47_s0___outermost_v229___block_id_w
{
	.reg .f32 	%f<5>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<11>;

// %bb.0:                               // %entry
	ld.param.u32 	%r1, [kernel_f47_s0___outermost_v229___block_id_w_param_0];
	ld.param.u64 	%rd1, [kernel_f47_s0___outermost_v229___block_id_w_param_9];
	cvta.to.global.u64 	%rd2, %rd1;
	ld.param.u32 	%r2, [kernel_f47_s0___outermost_v229___block_id_w_param_1];
	ld.param.u64 	%rd3, [kernel_f47_s0___outermost_v229___block_id_w_param_8];
	cvta.to.global.u64 	%rd4, %rd3;
	ld.param.u32 	%r3, [kernel_f47_s0___outermost_v229___block_id_w_param_2];
	ld.param.u32 	%r4, [kernel_f47_s0___outermost_v229___block_id_w_param_3];
	mov.u32 	%r5, %ctaid.z;
	mov.u32 	%r6, %ctaid.y;
	ld.param.u32 	%r7, [kernel_f47_s0___outermost_v229___block_id_w_param_4];
	mov.u32 	%r8, %ctaid.x;
	ld.param.u32 	%r9, [kernel_f47_s0___outermost_v229___block_id_w_param_5];
	ld.param.u32 	%r10, [kernel_f47_s0___outermost_v229___block_id_w_param_6];
	mul.lo.s32 	%r11, %r5, %r1;
	ld.param.u32 	%r12, [kernel_f47_s0___outermost_v229___block_id_w_param_7];
	sub.s32 	%r13, %r11, %r7;
	mad.lo.s32 	%r14, %r6, %r9, %r13;
	add.s32 	%r15, %r8, %r12;
	shr.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r16, %r14;
	mul.wide.s32 	%rd5, %r17, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.f32 	%f1, [%rd6];
	add.s32 	%r18, %r15, 1;
	shr.s32 	%r19, %r18, 1;
	add.s32 	%r20, %r19, %r14;
	mul.wide.s32 	%rd7, %r20, 4;
	add.s64 	%rd8, %rd4, %rd7;
	ld.global.nc.f32 	%f2, [%rd8];
	add.ftz.f32 	%f3, %f1, %f2;
	mul.ftz.f32 	%f4, %f3, 0f3F000000;
	add.s32 	%r21, %r6, %r4;
	mad.lo.s32 	%r22, %r5, %r2, %r3;
	add.s32 	%r23, %r22, %r8;
	mad.lo.s32 	%r24, %r21, %r10, %r23;
	mul.wide.s32 	%rd9, %r24, 4;
	add.s64 	%rd10, %rd2, %rd9;
	st.global.f32 	[%rd10], %f4;
	ret;
}
                                        // -- End function
	// .globl	kernel_f25_s0_y_y_o___block_id_y // -- Begin function kernel_f25_s0_y_y_o___block_id_y
.visible .entry kernel_f25_s0_y_y_o___block_id_y(
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_13,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_14,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_15,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_16,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_17,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_18,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_19,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_20,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_21,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_22,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_23,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_24,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_25,
	.param .u32 kernel_f25_s0_y_y_o___block_id_y_param_26,
	.param .u64 kernel_f25_s0_y_y_o___block_id_y_param_27,
	.param .u64 kernel_f25_s0_y_y_o___block_id_y_param_28,
	.param .u64 kernel_f25_s0_y_y_o___block_id_y_param_29,
	.param .u64 kernel_f25_s0_y_y_o___block_id_y_param_30,
	.param .u64 kernel_f25_s0_y_y_o___block_id_y_param_31
)                                       // @kernel_f25_s0_y_y_o___block_id_y
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<111>;
	.reg .b32 	%r<164>;
	.reg .b64 	%rd<94>;

// %bb.0:                               // %entry
	mov.u32 	%r35, %ctaid.y;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r1, %tid.y;
	mov.u32 	%r2, %tid.x;
	ld.param.u32 	%r37, [kernel_f25_s0_y_y_o___block_id_y_param_14];
	mad.lo.s32 	%r38, %r35, 10, %r37;
	ld.param.u32 	%r39, [kernel_f25_s0_y_y_o___block_id_y_param_25];
	min.s32 	%r3, %r38, %r39;
	ld.param.u32 	%r40, [kernel_f25_s0_y_y_o___block_id_y_param_13];
	shl.b32 	%r41, %r36, 4;
	add.s32 	%r42, %r41, %r40;
	ld.param.u32 	%r43, [kernel_f25_s0_y_y_o___block_id_y_param_26];
	min.s32 	%r4, %r42, %r43;
	setp.gt.u32 	%p1, %r1, 3;
	@%p1 bra 	LBB12_2;
// %bb.1:                               // %true_bb
	and.b32  	%r44, %r4, 3;
	add.s32 	%r45, %r44, 22;
	shr.u32 	%r5, %r45, 2;
	setp.lt.u32 	%p2, %r2, %r5;
	@%p2 bra 	LBB12_9;
	bra.uni 	LBB12_2;
LBB12_9:                                // %true_bb1
	ld.param.u32 	%r34, [kernel_f25_s0_y_y_o___block_id_y_param_24];
	ld.param.u32 	%r33, [kernel_f25_s0_y_y_o___block_id_y_param_23];
	ld.param.u32 	%r32, [kernel_f25_s0_y_y_o___block_id_y_param_22];
	ld.param.u32 	%r24, [kernel_f25_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r23, [kernel_f25_s0_y_y_o___block_id_y_param_11];
	ld.param.u32 	%r22, [kernel_f25_s0_y_y_o___block_id_y_param_10];
	ld.param.u32 	%r21, [kernel_f25_s0_y_y_o___block_id_y_param_9];
	ld.param.u32 	%r20, [kernel_f25_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r12, [kernel_f25_s0_y_y_o___block_id_y_param_0];
	ld.param.u64 	%rd6, [kernel_f25_s0_y_y_o___block_id_y_param_31];
	cvta.to.global.u64 	%rd1, %rd6;
	ld.param.u64 	%rd9, [kernel_f25_s0_y_y_o___block_id_y_param_28];
	cvta.to.global.u64 	%rd4, %rd9;
	shr.s32 	%r46, %r3, 2;
	add.s32 	%r47, %r46, %r1;
	shr.s32 	%r48, %r47, 1;
	sub.s32 	%r49, %r48, %r24;
	add.s32 	%r50, %r47, 1;
	shr.s32 	%r51, %r50, 1;
	sub.s32 	%r52, %r51, %r24;
	sub.s32 	%r53, %r1, %r34;
	add.s32 	%r54, %r53, %r46;
	shr.s32 	%r55, %r4, 2;
	sub.s32 	%r56, %r55, %r21;
	mad.lo.s32 	%r57, %r54, %r22, %r2;
	add.s32 	%r58, %r57, %r20;
	add.s32 	%r59, %r58, %r55;
	sub.s32 	%r60, %r57, %r33;
	add.s32 	%r61, %r60, %r55;
	mul.wide.s32 	%rd11, %r59, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	add.s32 	%r62, %r56, %r2;
	mad.lo.s32 	%r63, %r49, %r23, %r62;
	mad.lo.s32 	%r64, %r52, %r23, %r62;
	mul.wide.s32 	%rd13, %r61, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.nc.f32 	%f2, [%rd14];
	mul.wide.s32 	%rd15, %r63, 4;
	add.s64 	%rd16, %rd4, %rd15;
	ld.global.nc.f32 	%f3, [%rd16];
	mul.wide.s32 	%rd17, %r64, 4;
	add.s64 	%rd18, %rd4, %rd17;
	ld.global.nc.f32 	%f4, [%rd18];
	add.ftz.f32 	%f5, %f3, %f4;
	neg.ftz.f32 	%f6, %f1;
	fma.rn.ftz.f32 	%f7, %f6, %f5, %f5;
	fma.rn.ftz.f32 	%f8, %f7, 0f3F000000, %f2;
	mad.lo.s32 	%r65, %r1, %r5, %r2;
	mul.wide.u32 	%rd19, %r65, 4;
	st.shared.f32 	[%rd19], %f8;
	add.s32 	%r66, %r61, %r32;
	mul.wide.s32 	%rd20, %r66, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.f32 	%f9, [%rd21];
	add.s32 	%r67, %r63, %r12;
	mul.wide.s32 	%rd22, %r67, 4;
	add.s64 	%rd23, %rd4, %rd22;
	ld.global.nc.f32 	%f10, [%rd23];
	add.s32 	%r68, %r64, %r12;
	mul.wide.s32 	%rd24, %r68, 4;
	add.s64 	%rd25, %rd4, %rd24;
	ld.global.nc.f32 	%f11, [%rd25];
	add.ftz.f32 	%f12, %f10, %f11;
	fma.rn.ftz.f32 	%f13, %f6, %f12, %f12;
	fma.rn.ftz.f32 	%f14, %f13, 0f3F000000, %f9;
	shl.b32 	%r69, %r5, 2;
	add.s32 	%r70, %r65, %r69;
	mul.wide.s32 	%rd26, %r69, 4;
	add.s64 	%rd27, %rd19, %rd26;
	st.shared.f32 	[%rd27], %f14;
	add.s32 	%r71, %r66, %r32;
	mul.wide.s32 	%rd28, %r71, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.nc.f32 	%f15, [%rd29];
	add.s32 	%r72, %r67, %r12;
	mul.wide.s32 	%rd30, %r72, 4;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.nc.f32 	%f16, [%rd31];
	add.s32 	%r73, %r68, %r12;
	mul.wide.s32 	%rd32, %r73, 4;
	add.s64 	%rd33, %rd4, %rd32;
	ld.global.nc.f32 	%f17, [%rd33];
	add.ftz.f32 	%f18, %f16, %f17;
	fma.rn.ftz.f32 	%f19, %f6, %f18, %f18;
	fma.rn.ftz.f32 	%f20, %f19, 0f3F000000, %f15;
	add.s32 	%r74, %r70, %r69;
	mul.wide.u32 	%rd34, %r74, 4;
	st.shared.f32 	[%rd34], %f20;
	add.s32 	%r75, %r71, %r32;
	mul.wide.s32 	%rd35, %r75, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.nc.f32 	%f21, [%rd36];
	add.s32 	%r76, %r72, %r12;
	mul.wide.s32 	%rd37, %r76, 4;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.nc.f32 	%f22, [%rd38];
	add.s32 	%r77, %r73, %r12;
	mul.wide.s32 	%rd39, %r77, 4;
	add.s64 	%rd40, %rd4, %rd39;
	ld.global.nc.f32 	%f23, [%rd40];
	add.ftz.f32 	%f24, %f22, %f23;
	fma.rn.ftz.f32 	%f25, %f6, %f24, %f24;
	fma.rn.ftz.f32 	%f26, %f25, 0f3F000000, %f21;
	add.s32 	%r78, %r74, %r69;
	mul.wide.u32 	%rd41, %r78, 4;
	st.shared.f32 	[%rd41], %f26;
LBB12_2:                                // %after_bb
	setp.lt.u32 	%p3, %r1, 4;
	bar.sync 	0;
	setp.lt.u32 	%p4, %r2, 9;
	and.pred  	%p5, %p3, %p4;
	@%p5 bra 	LBB12_10;
	bra.uni 	LBB12_3;
LBB12_10:                               // %true_bb7
	shr.s32 	%r79, %r4, 1;
	add.s32 	%r80, %r79, %r2;
	shr.s32 	%r81, %r80, 1;
	add.s32 	%r82, %r80, 1;
	shr.s32 	%r83, %r82, 1;
	shr.s32 	%r84, %r4, 2;
	and.b32  	%r85, %r4, 3;
	mul.lo.s32 	%r86, %r1, 9;
	add.s32 	%r87, %r85, 22;
	shr.u32 	%r88, %r87, 2;
	and.b32  	%r89, %r87, 28;
	mul.lo.s32 	%r90, %r88, %r1;
	sub.s32 	%r91, %r90, %r84;
	add.s32 	%r92, %r91, %r81;
	add.s32 	%r93, %r91, %r83;
	mul.wide.s32 	%rd42, %r92, 4;
	ld.shared.f32 	%f27, [%rd42];
	mul.wide.s32 	%rd43, %r93, 4;
	ld.shared.f32 	%f28, [%rd43];
	add.ftz.f32 	%f29, %f27, %f28;
	mul.ftz.f32 	%f30, %f29, 0f3F000000;
	cvt.u64.u32 	%rd44, %r86;
	cvt.u64.u32 	%rd45, %r2;
	add.s64 	%rd46, %rd45, %rd44;
	shl.b64 	%rd47, %rd46, 2;
	st.shared.f32 	[%rd47+864], %f30;
	add.s32 	%r94, %r92, %r89;
	mul.wide.u32 	%rd48, %r89, 4;
	add.s64 	%rd49, %rd42, %rd48;
	ld.shared.f32 	%f31, [%rd49];
	add.s32 	%r95, %r93, %r89;
	add.s64 	%rd50, %rd43, %rd48;
	ld.shared.f32 	%f32, [%rd50];
	add.ftz.f32 	%f33, %f31, %f32;
	mul.ftz.f32 	%f34, %f33, 0f3F000000;
	st.shared.f32 	[%rd47+1008], %f34;
	add.s32 	%r96, %r94, %r89;
	mul.wide.s32 	%rd51, %r96, 4;
	ld.shared.f32 	%f35, [%rd51];
	add.s32 	%r97, %r95, %r89;
	mul.wide.s32 	%rd52, %r97, 4;
	ld.shared.f32 	%f36, [%rd52];
	add.ftz.f32 	%f37, %f35, %f36;
	mul.ftz.f32 	%f38, %f37, 0f3F000000;
	st.shared.f32 	[%rd47+1152], %f38;
	add.s32 	%r98, %r96, %r89;
	mul.wide.s32 	%rd53, %r98, 4;
	ld.shared.f32 	%f39, [%rd53];
	add.s32 	%r99, %r97, %r89;
	mul.wide.s32 	%rd54, %r99, 4;
	ld.shared.f32 	%f40, [%rd54];
	add.ftz.f32 	%f41, %f39, %f40;
	mul.ftz.f32 	%f42, %f41, 0f3F000000;
	st.shared.f32 	[%rd47+1296], %f42;
LBB12_3:                                // %after_bb6
	ld.param.u64 	%rd8, [kernel_f25_s0_y_y_o___block_id_y_param_29];
	ld.param.u64 	%rd10, [kernel_f25_s0_y_y_o___block_id_y_param_27];
	bar.sync 	0;
	setp.lt.u32 	%p7, %r1, 6;
	and.pred  	%p8, %p7, %p4;
	@%p8 bra 	LBB12_6;
	bra.uni 	LBB12_4;
LBB12_6:                                // %true_bb13
	ld.param.u64 	%rd7, [kernel_f25_s0_y_y_o___block_id_y_param_30];
	ld.param.u32 	%r31, [kernel_f25_s0_y_y_o___block_id_y_param_21];
	ld.param.u32 	%r30, [kernel_f25_s0_y_y_o___block_id_y_param_20];
	ld.param.u32 	%r29, [kernel_f25_s0_y_y_o___block_id_y_param_19];
	ld.param.u32 	%r19, [kernel_f25_s0_y_y_o___block_id_y_param_7];
	ld.param.u32 	%r18, [kernel_f25_s0_y_y_o___block_id_y_param_6];
	cvta.to.global.u64 	%rd2, %rd7;
	shr.s32 	%r100, %r3, 1;
	sub.s32 	%r101, %r1, %r31;
	add.s32 	%r102, %r101, %r100;
	shr.s32 	%r103, %r4, 1;
	add.s32 	%r104, %r100, %r1;
	shr.s32 	%r105, %r104, 1;
	shr.s32 	%r106, %r3, 2;
	sub.s32 	%r107, %r105, %r106;
	add.s32 	%r108, %r104, 1;
	shr.s32 	%r109, %r108, 1;
	sub.s32 	%r110, %r109, %r106;
	mad.lo.s32 	%r111, %r1, 9, %r2;
	mad.lo.s32 	%r112, %r102, %r19, %r2;
	add.s32 	%r113, %r112, %r18;
	add.s32 	%r114, %r113, %r103;
	sub.s32 	%r115, %r112, %r30;
	add.s32 	%r116, %r115, %r103;
	mul.wide.s32 	%rd55, %r114, 4;
	add.s64 	%rd56, %rd2, %rd55;
	ld.global.nc.f32 	%f43, [%rd56];
	add.s32 	%r117, %r2, 216;
	mad.lo.s32 	%r118, %r107, 9, %r117;
	mad.lo.s32 	%r119, %r110, 9, %r117;
	mul.wide.s32 	%rd57, %r116, 4;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.nc.f32 	%f44, [%rd58];
	mul.wide.s32 	%rd59, %r118, 4;
	ld.shared.f32 	%f45, [%rd59];
	mul.wide.s32 	%rd60, %r119, 4;
	ld.shared.f32 	%f46, [%rd60];
	add.ftz.f32 	%f47, %f45, %f46;
	neg.ftz.f32 	%f48, %f43;
	fma.rn.ftz.f32 	%f49, %f48, %f47, %f47;
	fma.rn.ftz.f32 	%f50, %f49, 0f3F000000, %f44;
	mul.wide.u32 	%rd61, %r111, 4;
	st.shared.f32 	[%rd61], %f50;
	add.s32 	%r120, %r116, %r29;
	mul.wide.s32 	%rd62, %r120, 4;
	add.s64 	%rd63, %rd2, %rd62;
	ld.global.nc.f32 	%f51, [%rd63];
	ld.shared.f32 	%f52, [%rd59+144];
	ld.shared.f32 	%f53, [%rd60+144];
	add.ftz.f32 	%f54, %f52, %f53;
	fma.rn.ftz.f32 	%f55, %f48, %f54, %f54;
	fma.rn.ftz.f32 	%f56, %f55, 0f3F000000, %f51;
	st.shared.f32 	[%rd61+216], %f56;
	add.s32 	%r121, %r120, %r29;
	mul.wide.s32 	%rd64, %r121, 4;
	add.s64 	%rd65, %rd2, %rd64;
	ld.global.nc.f32 	%f57, [%rd65];
	ld.shared.f32 	%f58, [%rd59+288];
	ld.shared.f32 	%f59, [%rd60+288];
	add.ftz.f32 	%f60, %f58, %f59;
	fma.rn.ftz.f32 	%f61, %f48, %f60, %f60;
	fma.rn.ftz.f32 	%f62, %f61, 0f3F000000, %f57;
	st.shared.f32 	[%rd61+432], %f62;
	add.s32 	%r122, %r121, %r29;
	mul.wide.s32 	%rd66, %r122, 4;
	add.s64 	%rd67, %rd2, %rd66;
	ld.global.nc.f32 	%f63, [%rd67];
	ld.shared.f32 	%f64, [%rd59+432];
	ld.shared.f32 	%f65, [%rd60+432];
	add.ftz.f32 	%f66, %f64, %f65;
	fma.rn.ftz.f32 	%f67, %f48, %f66, %f66;
	fma.rn.ftz.f32 	%f68, %f67, 0f3F000000, %f63;
	st.shared.f32 	[%rd61+648], %f68;
LBB12_4:                                // %after_bb12
	ld.param.u32 	%r28, [kernel_f25_s0_y_y_o___block_id_y_param_18];
	ld.param.u32 	%r27, [kernel_f25_s0_y_y_o___block_id_y_param_17];
	ld.param.u32 	%r26, [kernel_f25_s0_y_y_o___block_id_y_param_16];
	ld.param.u32 	%r25, [kernel_f25_s0_y_y_o___block_id_y_param_15];
	ld.param.u32 	%r17, [kernel_f25_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r16, [kernel_f25_s0_y_y_o___block_id_y_param_4];
	ld.param.u32 	%r15, [kernel_f25_s0_y_y_o___block_id_y_param_3];
	ld.param.u32 	%r14, [kernel_f25_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r13, [kernel_f25_s0_y_y_o___block_id_y_param_1];
	cvta.to.global.u64 	%rd3, %rd8;
	cvta.to.global.u64 	%rd5, %rd10;
	bar.sync 	0;
	@%p7 bra 	LBB12_7;
	bra.uni 	LBB12_5;
LBB12_7:                                // %true_bb16
	and.b32  	%r123, %r4, 1;
	add.s32 	%r124, %r123, %r2;
	shr.u32 	%r125, %r124, 1;
	mul.lo.s32 	%r126, %r1, 9;
	add.s32 	%r127, %r125, %r126;
	add.s32 	%r163, %r4, %r2;
	add.s32 	%r128, %r163, 1;
	shr.s32 	%r129, %r128, 1;
	shr.s32 	%r130, %r4, 1;
	sub.s32 	%r131, %r126, %r130;
	add.s32 	%r132, %r131, %r129;
	shl.b32 	%r133, %r1, 4;
	add.s32 	%r162, %r2, 216;
	mul.wide.u32 	%rd68, %r127, 4;
	ld.shared.f32 	%f69, [%rd68];
	mul.wide.s32 	%rd69, %r132, 4;
	ld.shared.f32 	%f70, [%rd69];
	add.ftz.f32 	%f71, %f69, %f70;
	mul.ftz.f32 	%f72, %f71, 0f3F000000;
	cvt.u64.u32 	%rd70, %r133;
	cvt.u64.u32 	%rd71, %r2;
	add.s64 	%rd72, %rd71, %rd70;
	shl.b64 	%rd73, %rd72, 2;
	st.shared.f32 	[%rd73+864], %f72;
	ld.shared.f32 	%f73, [%rd68+216];
	ld.shared.f32 	%f74, [%rd69+216];
	add.ftz.f32 	%f75, %f73, %f74;
	mul.ftz.f32 	%f76, %f75, 0f3F000000;
	st.shared.f32 	[%rd73+1248], %f76;
	ld.shared.f32 	%f77, [%rd68+432];
	ld.shared.f32 	%f78, [%rd69+432];
	add.ftz.f32 	%f79, %f77, %f78;
	mul.ftz.f32 	%f80, %f79, 0f3F000000;
	st.shared.f32 	[%rd73+1632], %f80;
	ld.shared.f32 	%f81, [%rd68+648];
	ld.shared.f32 	%f82, [%rd69+648];
	add.ftz.f32 	%f83, %f81, %f82;
	mul.ftz.f32 	%f84, %f83, 0f3F000000;
	st.shared.f32 	[%rd73+2016], %f84;
	bra.uni 	LBB12_8;
LBB12_5:                                // %after_bb12.after_bb18_crit_edge
	add.s32 	%r163, %r4, %r2;
	add.s32 	%r162, %r2, 216;
LBB12_8:                                // %after_bb18
	bar.sync 	0;
	sub.s32 	%r134, %r1, %r28;
	add.s32 	%r135, %r134, %r3;
	mul.lo.s32 	%r136, %r135, %r17;
	add.s32 	%r137, %r3, %r1;
	add.s32 	%r138, %r137, 1;
	shr.u32 	%r139, %r138, 1;
	shr.s32 	%r140, %r3, 1;
	sub.s32 	%r141, %r139, %r140;
	shr.u32 	%r142, %r137, 1;
	sub.s32 	%r143, %r142, %r140;
	sub.s32 	%r144, %r1, %r15;
	add.s32 	%r145, %r144, %r3;
	shl.b32 	%r146, %r141, 4;
	shl.b32 	%r147, %r143, 4;
	add.s32 	%r148, %r163, %r13;
	add.s32 	%r149, %r148, %r136;
	sub.s32 	%r150, %r163, %r27;
	add.s32 	%r151, %r150, %r136;
	mul.wide.s32 	%rd74, %r149, 4;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.nc.f32 	%f85, [%rd75];
	add.s32 	%r152, %r162, %r147;
	add.s32 	%r153, %r162, %r146;
	sub.s32 	%r154, %r163, %r16;
	mad.lo.s32 	%r155, %r145, %r14, %r154;
	mul.wide.s32 	%rd76, %r151, 4;
	add.s64 	%rd77, %rd3, %rd76;
	ld.global.nc.f32 	%f86, [%rd77];
	mul.wide.s32 	%rd78, %r152, 4;
	ld.shared.f32 	%f87, [%rd78];
	mul.wide.s32 	%rd79, %r153, 4;
	ld.shared.f32 	%f88, [%rd79];
	add.ftz.f32 	%f89, %f87, %f88;
	neg.ftz.f32 	%f90, %f85;
	fma.rn.ftz.f32 	%f91, %f90, %f89, %f89;
	fma.rn.ftz.f32 	%f92, %f91, 0f3F000000, %f86;
	mul.wide.s32 	%rd80, %r155, 4;
	add.s64 	%rd81, %rd5, %rd80;
	st.global.f32 	[%rd81], %f92;
	add.s32 	%r156, %r151, %r26;
	mul.wide.s32 	%rd82, %r156, 4;
	add.s64 	%rd83, %rd3, %rd82;
	ld.global.nc.f32 	%f93, [%rd83];
	ld.shared.f32 	%f94, [%rd78+384];
	ld.shared.f32 	%f95, [%rd79+384];
	add.ftz.f32 	%f96, %f94, %f95;
	fma.rn.ftz.f32 	%f97, %f90, %f96, %f96;
	fma.rn.ftz.f32 	%f98, %f97, 0f3F000000, %f93;
	add.s32 	%r157, %r155, %r25;
	mul.wide.s32 	%rd84, %r157, 4;
	add.s64 	%rd85, %rd5, %rd84;
	st.global.f32 	[%rd85], %f98;
	add.s32 	%r158, %r156, %r26;
	mul.wide.s32 	%rd86, %r158, 4;
	add.s64 	%rd87, %rd3, %rd86;
	ld.global.nc.f32 	%f99, [%rd87];
	ld.shared.f32 	%f100, [%rd78+768];
	ld.shared.f32 	%f101, [%rd79+768];
	add.ftz.f32 	%f102, %f100, %f101;
	fma.rn.ftz.f32 	%f103, %f90, %f102, %f102;
	fma.rn.ftz.f32 	%f104, %f103, 0f3F000000, %f99;
	add.s32 	%r159, %r157, %r25;
	mul.wide.s32 	%rd88, %r159, 4;
	add.s64 	%rd89, %rd5, %rd88;
	st.global.f32 	[%rd89], %f104;
	add.s32 	%r160, %r158, %r26;
	mul.wide.s32 	%rd90, %r160, 4;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.nc.f32 	%f105, [%rd91];
	ld.shared.f32 	%f106, [%rd78+1152];
	ld.shared.f32 	%f107, [%rd79+1152];
	add.ftz.f32 	%f108, %f106, %f107;
	fma.rn.ftz.f32 	%f109, %f90, %f108, %f108;
	fma.rn.ftz.f32 	%f110, %f109, 0f3F000000, %f105;
	add.s32 	%r161, %r159, %r25;
	mul.wide.s32 	%rd92, %r161, 4;
	add.s64 	%rd93, %rd5, %rd92;
	st.global.f32 	[%rd93], %f110;
	ret;
}
                                        // -- End function
	// .globl	kernel_f22_s0_y_y_o___block_id_y // -- Begin function kernel_f22_s0_y_y_o___block_id_y
.visible .entry kernel_f22_s0_y_y_o___block_id_y(
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_13,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_14,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_15,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_16,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_17,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_18,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_19,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_20,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_21,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_22,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_23,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_24,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_25,
	.param .u32 kernel_f22_s0_y_y_o___block_id_y_param_26,
	.param .u64 kernel_f22_s0_y_y_o___block_id_y_param_27,
	.param .u64 kernel_f22_s0_y_y_o___block_id_y_param_28,
	.param .u64 kernel_f22_s0_y_y_o___block_id_y_param_29,
	.param .u64 kernel_f22_s0_y_y_o___block_id_y_param_30,
	.param .u64 kernel_f22_s0_y_y_o___block_id_y_param_31
)                                       // @kernel_f22_s0_y_y_o___block_id_y
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<127>;
	.reg .b32 	%r<203>;
	.reg .b64 	%rd<123>;

// %bb.0:                               // %entry
	mov.u32 	%r36, %ctaid.y;
	mov.u32 	%r37, %ctaid.x;
	mov.u32 	%r1, %tid.y;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r38, %r36, 4;
	ld.param.u32 	%r39, [kernel_f22_s0_y_y_o___block_id_y_param_14];
	add.s32 	%r40, %r38, %r39;
	ld.param.u32 	%r41, [kernel_f22_s0_y_y_o___block_id_y_param_25];
	min.s32 	%r3, %r40, %r41;
	ld.param.u32 	%r42, [kernel_f22_s0_y_y_o___block_id_y_param_13];
	mad.lo.s32 	%r43, %r37, 10, %r42;
	ld.param.u32 	%r44, [kernel_f22_s0_y_y_o___block_id_y_param_26];
	min.s32 	%r4, %r43, %r44;
	and.b32  	%r45, %r3, 3;
	add.s32 	%r5, %r45, 22;
	shr.u32 	%r6, %r5, 2;
	setp.lt.u32 	%p1, %r1, %r6;
	setp.lt.u32 	%p2, %r2, 4;
	and.pred  	%p3, %p2, %p1;
	@%p3 bra 	LBB13_8;
	bra.uni 	LBB13_1;
LBB13_8:                                // %true_bb1
	ld.param.u32 	%r35, [kernel_f22_s0_y_y_o___block_id_y_param_24];
	ld.param.u32 	%r34, [kernel_f22_s0_y_y_o___block_id_y_param_23];
	ld.param.u32 	%r33, [kernel_f22_s0_y_y_o___block_id_y_param_22];
	ld.param.u32 	%r29, [kernel_f22_s0_y_y_o___block_id_y_param_18];
	ld.param.u32 	%r25, [kernel_f22_s0_y_y_o___block_id_y_param_12];
	ld.param.u32 	%r24, [kernel_f22_s0_y_y_o___block_id_y_param_11];
	ld.param.u32 	%r23, [kernel_f22_s0_y_y_o___block_id_y_param_10];
	ld.param.u32 	%r22, [kernel_f22_s0_y_y_o___block_id_y_param_9];
	ld.param.u32 	%r21, [kernel_f22_s0_y_y_o___block_id_y_param_8];
	ld.param.u64 	%rd6, [kernel_f22_s0_y_y_o___block_id_y_param_31];
	cvta.to.global.u64 	%rd1, %rd6;
	ld.param.u64 	%rd8, [kernel_f22_s0_y_y_o___block_id_y_param_29];
	cvta.to.global.u64 	%rd3, %rd8;
	shr.s32 	%r46, %r3, 2;
	sub.s32 	%r47, %r1, %r35;
	add.s32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r25;
	add.s32 	%r50, %r46, %r1;
	shr.s32 	%r51, %r50, 1;
	sub.s32 	%r52, %r51, %r24;
	mul.lo.s32 	%r53, %r52, %r23;
	sub.s32 	%r54, %r53, %r22;
	add.s32 	%r55, %r50, 1;
	shr.s32 	%r56, %r55, 1;
	sub.s32 	%r57, %r56, %r24;
	mul.lo.s32 	%r58, %r57, %r23;
	sub.s32 	%r59, %r58, %r22;
	shr.s32 	%r60, %r4, 2;
	add.s32 	%r61, %r60, %r2;
	add.s32 	%r62, %r61, %r21;
	add.s32 	%r63, %r62, %r49;
	sub.s32 	%r64, %r61, %r34;
	add.s32 	%r65, %r64, %r49;
	mul.wide.s32 	%rd11, %r63, 4;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.nc.f32 	%f1, [%rd12];
	shr.s32 	%r66, %r61, 1;
	add.s32 	%r67, %r61, 1;
	shr.s32 	%r68, %r67, 1;
	mul.wide.s32 	%rd13, %r65, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.nc.f32 	%f2, [%rd14];
	add.s32 	%r69, %r54, %r66;
	mul.wide.s32 	%rd15, %r69, 4;
	add.s64 	%rd16, %rd3, %rd15;
	ld.global.nc.f32 	%f3, [%rd16];
	add.s32 	%r70, %r54, %r68;
	mul.wide.s32 	%rd17, %r70, 4;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.nc.f32 	%f4, [%rd18];
	add.ftz.f32 	%f5, %f3, %f4;
	add.s32 	%r71, %r59, %r66;
	mul.wide.s32 	%rd19, %r71, 4;
	add.s64 	%rd20, %rd3, %rd19;
	ld.global.nc.f32 	%f6, [%rd20];
	add.s32 	%r72, %r59, %r68;
	mul.wide.s32 	%rd21, %r72, 4;
	add.s64 	%rd22, %rd3, %rd21;
	ld.global.nc.f32 	%f7, [%rd22];
	add.ftz.f32 	%f8, %f6, %f7;
	add.ftz.f32 	%f9, %f5, %f8;
	neg.ftz.f32 	%f10, %f1;
	fma.rn.ftz.f32 	%f11, %f10, %f9, %f9;
	fma.rn.ftz.f32 	%f12, %f11, 0f3E800000, %f2;
	shl.b32 	%r73, %r1, 2;
	add.s32 	%r74, %r73, %r2;
	mul.wide.u32 	%rd23, %r74, 4;
	st.shared.f32 	[%rd23], %f12;
	add.s32 	%r75, %r65, %r33;
	mul.wide.s32 	%rd24, %r75, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.nc.f32 	%f13, [%rd25];
	add.s32 	%r76, %r54, %r29;
	add.s32 	%r77, %r76, %r66;
	mul.wide.s32 	%rd26, %r77, 4;
	add.s64 	%rd27, %rd3, %rd26;
	ld.global.nc.f32 	%f14, [%rd27];
	add.s32 	%r78, %r76, %r68;
	mul.wide.s32 	%rd28, %r78, 4;
	add.s64 	%rd29, %rd3, %rd28;
	ld.global.nc.f32 	%f15, [%rd29];
	add.ftz.f32 	%f16, %f14, %f15;
	add.s32 	%r79, %r59, %r29;
	add.s32 	%r80, %r79, %r66;
	mul.wide.s32 	%rd30, %r80, 4;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.nc.f32 	%f17, [%rd31];
	add.s32 	%r81, %r79, %r68;
	mul.wide.s32 	%rd32, %r81, 4;
	add.s64 	%rd33, %rd3, %rd32;
	ld.global.nc.f32 	%f18, [%rd33];
	add.ftz.f32 	%f19, %f17, %f18;
	add.ftz.f32 	%f20, %f16, %f19;
	fma.rn.ftz.f32 	%f21, %f10, %f20, %f20;
	fma.rn.ftz.f32 	%f22, %f21, 0f3E800000, %f13;
	add.s32 	%r82, %r6, %r1;
	shl.b32 	%r83, %r82, 2;
	add.s32 	%r84, %r83, %r2;
	mul.wide.u32 	%rd34, %r84, 4;
	st.shared.f32 	[%rd34], %f22;
	add.s32 	%r85, %r75, %r33;
	mul.wide.s32 	%rd35, %r85, 4;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.nc.f32 	%f23, [%rd36];
	add.s32 	%r86, %r76, %r29;
	add.s32 	%r87, %r86, %r66;
	mul.wide.s32 	%rd37, %r87, 4;
	add.s64 	%rd38, %rd3, %rd37;
	ld.global.nc.f32 	%f24, [%rd38];
	add.s32 	%r88, %r86, %r68;
	mul.wide.s32 	%rd39, %r88, 4;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.nc.f32 	%f25, [%rd40];
	add.ftz.f32 	%f26, %f24, %f25;
	add.s32 	%r89, %r79, %r29;
	add.s32 	%r90, %r89, %r66;
	mul.wide.s32 	%rd41, %r90, 4;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.nc.f32 	%f27, [%rd42];
	add.s32 	%r91, %r89, %r68;
	mul.wide.s32 	%rd43, %r91, 4;
	add.s64 	%rd44, %rd3, %rd43;
	ld.global.nc.f32 	%f28, [%rd44];
	add.ftz.f32 	%f29, %f27, %f28;
	add.ftz.f32 	%f30, %f26, %f29;
	fma.rn.ftz.f32 	%f31, %f10, %f30, %f30;
	fma.rn.ftz.f32 	%f32, %f31, 0f3E800000, %f23;
	add.s32 	%r92, %r82, %r6;
	shl.b32 	%r93, %r92, 2;
	add.s32 	%r94, %r93, %r2;
	mul.wide.u32 	%rd45, %r94, 4;
	st.shared.f32 	[%rd45], %f32;
	add.s32 	%r95, %r85, %r33;
	mul.wide.s32 	%rd46, %r95, 4;
	add.s64 	%rd47, %rd1, %rd46;
	ld.global.nc.f32 	%f33, [%rd47];
	add.s32 	%r96, %r86, %r29;
	add.s32 	%r97, %r96, %r66;
	mul.wide.s32 	%rd48, %r97, 4;
	add.s64 	%rd49, %rd3, %rd48;
	ld.global.nc.f32 	%f34, [%rd49];
	add.s32 	%r98, %r96, %r68;
	mul.wide.s32 	%rd50, %r98, 4;
	add.s64 	%rd51, %rd3, %rd50;
	ld.global.nc.f32 	%f35, [%rd51];
	add.ftz.f32 	%f36, %f34, %f35;
	add.s32 	%r99, %r89, %r29;
	add.s32 	%r100, %r99, %r66;
	mul.wide.s32 	%rd52, %r100, 4;
	add.s64 	%rd53, %rd3, %rd52;
	ld.global.nc.f32 	%f37, [%rd53];
	add.s32 	%r101, %r99, %r68;
	mul.wide.s32 	%rd54, %r101, 4;
	add.s64 	%rd55, %rd3, %rd54;
	ld.global.nc.f32 	%f38, [%rd55];
	add.ftz.f32 	%f39, %f37, %f38;
	add.ftz.f32 	%f40, %f36, %f39;
	fma.rn.ftz.f32 	%f41, %f10, %f40, %f40;
	fma.rn.ftz.f32 	%f42, %f41, 0f3E800000, %f33;
	add.s32 	%r102, %r92, %r6;
	shl.b32 	%r103, %r102, 2;
	add.s32 	%r104, %r103, %r2;
	mul.wide.u32 	%rd56, %r104, 4;
	st.shared.f32 	[%rd56], %f42;
LBB13_1:                                // %after_bb
	bar.sync 	0;
	setp.lt.u32 	%p5, %r2, 6;
	and.pred  	%p6, %p5, %p1;
	@%p6 bra 	LBB13_9;
	bra.uni 	LBB13_2;
LBB13_9:                                // %true_bb7
	shl.b32 	%r105, %r1, 2;
	shr.s32 	%r106, %r4, 2;
	sub.s32 	%r107, %r105, %r106;
	shr.s32 	%r108, %r4, 1;
	add.s32 	%r109, %r108, %r2;
	shr.s32 	%r110, %r109, 1;
	add.s32 	%r111, %r109, 1;
	shr.s32 	%r112, %r111, 1;
	add.s32 	%r113, %r107, %r110;
	mul.wide.s32 	%rd57, %r113, 4;
	ld.shared.f32 	%f43, [%rd57];
	add.s32 	%r114, %r107, %r112;
	mul.wide.s32 	%rd58, %r114, 4;
	ld.shared.f32 	%f44, [%rd58];
	add.ftz.f32 	%f45, %f43, %f44;
	mul.ftz.f32 	%f46, %f45, 0f3F000000;
	mul.lo.s32 	%r115, %r1, 6;
	cvt.u64.u32 	%rd59, %r115;
	cvt.u64.u32 	%rd60, %r2;
	add.s64 	%rd61, %rd60, %rd59;
	shl.b64 	%rd62, %rd61, 2;
	st.shared.f32 	[%rd62+864], %f46;
	and.b32  	%r116, %r5, 28;
	add.s32 	%r117, %r116, %r107;
	add.s32 	%r118, %r117, %r110;
	mul.wide.s32 	%rd63, %r118, 4;
	ld.shared.f32 	%f47, [%rd63];
	add.s32 	%r119, %r117, %r112;
	mul.wide.s32 	%rd64, %r119, 4;
	ld.shared.f32 	%f48, [%rd64];
	add.ftz.f32 	%f49, %f47, %f48;
	mul.ftz.f32 	%f50, %f49, 0f3F000000;
	add.s32 	%r120, %r6, %r1;
	mul.lo.s32 	%r121, %r120, 6;
	cvt.u64.u32 	%rd65, %r121;
	add.s64 	%rd66, %rd60, %rd65;
	shl.b64 	%rd67, %rd66, 2;
	st.shared.f32 	[%rd67+864], %f50;
	shl.b32 	%r122, %r6, 3;
	add.s32 	%r123, %r122, %r107;
	add.s32 	%r124, %r123, %r110;
	mul.wide.s32 	%rd68, %r124, 4;
	ld.shared.f32 	%f51, [%rd68];
	add.s32 	%r125, %r123, %r112;
	mul.wide.s32 	%rd69, %r125, 4;
	ld.shared.f32 	%f52, [%rd69];
	add.ftz.f32 	%f53, %f51, %f52;
	mul.ftz.f32 	%f54, %f53, 0f3F000000;
	add.s32 	%r126, %r120, %r6;
	mul.lo.s32 	%r127, %r126, 6;
	cvt.u64.u32 	%rd70, %r127;
	add.s64 	%rd71, %rd60, %rd70;
	shl.b64 	%rd72, %rd71, 2;
	st.shared.f32 	[%rd72+864], %f54;
	shl.b32 	%r128, %r6, 2;
	add.s32 	%r129, %r123, %r128;
	add.s32 	%r130, %r129, %r110;
	mul.wide.s32 	%rd73, %r130, 4;
	ld.shared.f32 	%f55, [%rd73];
	add.s32 	%r131, %r129, %r112;
	mul.wide.s32 	%rd74, %r131, 4;
	ld.shared.f32 	%f56, [%rd74];
	add.ftz.f32 	%f57, %f55, %f56;
	mul.ftz.f32 	%f58, %f57, 0f3F000000;
	add.s32 	%r132, %r126, %r6;
	mul.lo.s32 	%r133, %r132, 6;
	cvt.u64.u32 	%rd75, %r133;
	add.s64 	%rd76, %rd60, %rd75;
	shl.b64 	%rd77, %rd76, 2;
	st.shared.f32 	[%rd77+864], %f58;
LBB13_2:                                // %after_bb6
	ld.param.u64 	%rd9, [kernel_f22_s0_y_y_o___block_id_y_param_28];
	ld.param.u64 	%rd10, [kernel_f22_s0_y_y_o___block_id_y_param_27];
	bar.sync 	0;
	setp.lt.u32 	%p8, %r1, 9;
	and.pred  	%p9, %p8, %p5;
	@%p9 bra 	LBB13_5;
	bra.uni 	LBB13_3;
LBB13_5:                                // %true_bb13
	ld.param.u64 	%rd7, [kernel_f22_s0_y_y_o___block_id_y_param_30];
	ld.param.u32 	%r32, [kernel_f22_s0_y_y_o___block_id_y_param_21];
	ld.param.u32 	%r31, [kernel_f22_s0_y_y_o___block_id_y_param_20];
	ld.param.u32 	%r30, [kernel_f22_s0_y_y_o___block_id_y_param_19];
	ld.param.u32 	%r20, [kernel_f22_s0_y_y_o___block_id_y_param_7];
	ld.param.u32 	%r19, [kernel_f22_s0_y_y_o___block_id_y_param_6];
	cvta.to.global.u64 	%rd2, %rd7;
	shr.s32 	%r134, %r3, 1;
	sub.s32 	%r135, %r1, %r32;
	add.s32 	%r136, %r135, %r134;
	shr.s32 	%r137, %r4, 1;
	add.s32 	%r138, %r134, %r1;
	shr.s32 	%r139, %r138, 1;
	shr.s32 	%r140, %r3, 2;
	sub.s32 	%r141, %r139, %r140;
	add.s32 	%r142, %r138, 1;
	shr.s32 	%r143, %r142, 1;
	sub.s32 	%r144, %r143, %r140;
	mad.lo.s32 	%r145, %r1, 6, %r2;
	mad.lo.s32 	%r146, %r136, %r20, %r2;
	add.s32 	%r147, %r146, %r19;
	add.s32 	%r148, %r147, %r137;
	sub.s32 	%r149, %r146, %r31;
	add.s32 	%r150, %r149, %r137;
	mul.wide.s32 	%rd78, %r148, 4;
	add.s64 	%rd79, %rd2, %rd78;
	ld.global.nc.f32 	%f59, [%rd79];
	mul.lo.s32 	%r151, %r6, 6;
	add.s32 	%r152, %r2, 216;
	mad.lo.s32 	%r153, %r141, 6, %r152;
	mad.lo.s32 	%r154, %r144, 6, %r152;
	mul.wide.s32 	%rd80, %r150, 4;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.nc.f32 	%f60, [%rd81];
	mul.wide.s32 	%rd82, %r153, 4;
	ld.shared.f32 	%f61, [%rd82];
	mul.wide.s32 	%rd83, %r154, 4;
	ld.shared.f32 	%f62, [%rd83];
	add.ftz.f32 	%f63, %f61, %f62;
	neg.ftz.f32 	%f64, %f59;
	fma.rn.ftz.f32 	%f65, %f64, %f63, %f63;
	fma.rn.ftz.f32 	%f66, %f65, 0f3F000000, %f60;
	mul.wide.u32 	%rd84, %r145, 4;
	st.shared.f32 	[%rd84], %f66;
	add.s32 	%r155, %r150, %r30;
	mul.wide.s32 	%rd85, %r155, 4;
	add.s64 	%rd86, %rd2, %rd85;
	ld.global.nc.f32 	%f67, [%rd86];
	add.s32 	%r156, %r153, %r151;
	mul.wide.s32 	%rd87, %r156, 4;
	ld.shared.f32 	%f68, [%rd87];
	add.s32 	%r157, %r154, %r151;
	mul.wide.s32 	%rd88, %r157, 4;
	ld.shared.f32 	%f69, [%rd88];
	add.ftz.f32 	%f70, %f68, %f69;
	fma.rn.ftz.f32 	%f71, %f64, %f70, %f70;
	fma.rn.ftz.f32 	%f72, %f71, 0f3F000000, %f67;
	st.shared.f32 	[%rd84+216], %f72;
	add.s32 	%r158, %r155, %r30;
	mul.wide.s32 	%rd89, %r158, 4;
	add.s64 	%rd90, %rd2, %rd89;
	ld.global.nc.f32 	%f73, [%rd90];
	add.s32 	%r159, %r156, %r151;
	mul.wide.s32 	%rd91, %r159, 4;
	ld.shared.f32 	%f74, [%rd91];
	add.s32 	%r160, %r157, %r151;
	mul.wide.s32 	%rd92, %r160, 4;
	ld.shared.f32 	%f75, [%rd92];
	add.ftz.f32 	%f76, %f74, %f75;
	fma.rn.ftz.f32 	%f77, %f64, %f76, %f76;
	fma.rn.ftz.f32 	%f78, %f77, 0f3F000000, %f73;
	st.shared.f32 	[%rd84+432], %f78;
	add.s32 	%r161, %r158, %r30;
	mul.wide.s32 	%rd93, %r161, 4;
	add.s64 	%rd94, %rd2, %rd93;
	ld.global.nc.f32 	%f79, [%rd94];
	add.s32 	%r162, %r159, %r151;
	mul.wide.s32 	%rd95, %r162, 4;
	ld.shared.f32 	%f80, [%rd95];
	add.s32 	%r163, %r160, %r151;
	mul.wide.s32 	%rd96, %r163, 4;
	ld.shared.f32 	%f81, [%rd96];
	add.ftz.f32 	%f82, %f80, %f81;
	fma.rn.ftz.f32 	%f83, %f64, %f82, %f82;
	fma.rn.ftz.f32 	%f84, %f83, 0f3F000000, %f79;
	st.shared.f32 	[%rd84+648], %f84;
LBB13_3:                                // %after_bb12
	ld.param.u32 	%r28, [kernel_f22_s0_y_y_o___block_id_y_param_17];
	ld.param.u32 	%r27, [kernel_f22_s0_y_y_o___block_id_y_param_16];
	ld.param.u32 	%r26, [kernel_f22_s0_y_y_o___block_id_y_param_15];
	ld.param.u32 	%r18, [kernel_f22_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r17, [kernel_f22_s0_y_y_o___block_id_y_param_4];
	ld.param.u32 	%r16, [kernel_f22_s0_y_y_o___block_id_y_param_3];
	ld.param.u32 	%r15, [kernel_f22_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r14, [kernel_f22_s0_y_y_o___block_id_y_param_1];
	ld.param.u32 	%r13, [kernel_f22_s0_y_y_o___block_id_y_param_0];
	cvta.to.global.u64 	%rd4, %rd9;
	cvta.to.global.u64 	%rd5, %rd10;
	bar.sync 	0;
	@%p8 bra 	LBB13_6;
	bra.uni 	LBB13_4;
LBB13_6:                                // %true_bb16
	and.b32  	%r164, %r4, 1;
	add.s32 	%r165, %r164, %r2;
	shr.u32 	%r166, %r165, 1;
	mul.lo.s32 	%r167, %r1, 6;
	add.s32 	%r168, %r166, %r167;
	add.s32 	%r202, %r4, %r2;
	add.s32 	%r169, %r202, 1;
	shr.s32 	%r170, %r169, 1;
	shr.s32 	%r171, %r4, 1;
	sub.s32 	%r172, %r167, %r171;
	add.s32 	%r173, %r172, %r170;
	mul.lo.s32 	%r174, %r1, 10;
	add.s32 	%r201, %r2, 216;
	mul.wide.u32 	%rd97, %r168, 4;
	ld.shared.f32 	%f85, [%rd97];
	mul.wide.s32 	%rd98, %r173, 4;
	ld.shared.f32 	%f86, [%rd98];
	add.ftz.f32 	%f87, %f85, %f86;
	mul.ftz.f32 	%f88, %f87, 0f3F000000;
	cvt.u64.u32 	%rd99, %r174;
	cvt.u64.u32 	%rd100, %r2;
	add.s64 	%rd101, %rd100, %rd99;
	shl.b64 	%rd102, %rd101, 2;
	st.shared.f32 	[%rd102+864], %f88;
	ld.shared.f32 	%f89, [%rd97+216];
	ld.shared.f32 	%f90, [%rd98+216];
	add.ftz.f32 	%f91, %f89, %f90;
	mul.ftz.f32 	%f92, %f91, 0f3F000000;
	st.shared.f32 	[%rd102+1224], %f92;
	ld.shared.f32 	%f93, [%rd97+432];
	ld.shared.f32 	%f94, [%rd98+432];
	add.ftz.f32 	%f95, %f93, %f94;
	mul.ftz.f32 	%f96, %f95, 0f3F000000;
	st.shared.f32 	[%rd102+1584], %f96;
	ld.shared.f32 	%f97, [%rd97+648];
	ld.shared.f32 	%f98, [%rd98+648];
	add.ftz.f32 	%f99, %f97, %f98;
	mul.ftz.f32 	%f100, %f99, 0f3F000000;
	st.shared.f32 	[%rd102+1944], %f100;
	bra.uni 	LBB13_7;
LBB13_4:                                // %after_bb12.after_bb18_crit_edge
	add.s32 	%r202, %r4, %r2;
	add.s32 	%r201, %r2, 216;
LBB13_7:                                // %after_bb18
	bar.sync 	0;
	sub.s32 	%r175, %r1, %r27;
	add.s32 	%r176, %r175, %r3;
	mul.lo.s32 	%r177, %r176, %r18;
	add.s32 	%r178, %r3, %r1;
	add.s32 	%r179, %r178, 1;
	shr.s32 	%r180, %r179, 1;
	shr.s32 	%r181, %r3, 1;
	sub.s32 	%r182, %r180, %r181;
	shr.s32 	%r183, %r178, 1;
	sub.s32 	%r184, %r183, %r181;
	sub.s32 	%r185, %r1, %r16;
	add.s32 	%r186, %r185, %r3;
	add.s32 	%r187, %r202, %r14;
	add.s32 	%r188, %r187, %r177;
	sub.s32 	%r189, %r202, %r13;
	add.s32 	%r190, %r189, %r177;
	mul.wide.s32 	%rd103, %r188, 4;
	add.s64 	%rd104, %rd5, %rd103;
	ld.global.nc.f32 	%f101, [%rd104];
	mad.lo.s32 	%r191, %r184, 10, %r201;
	mad.lo.s32 	%r192, %r182, 10, %r201;
	sub.s32 	%r193, %r202, %r17;
	mad.lo.s32 	%r194, %r186, %r15, %r193;
	mul.wide.s32 	%rd105, %r190, 4;
	add.s64 	%rd106, %rd5, %rd105;
	ld.global.nc.f32 	%f102, [%rd106];
	mul.wide.s32 	%rd107, %r191, 4;
	ld.shared.f32 	%f103, [%rd107];
	mul.wide.s32 	%rd108, %r192, 4;
	ld.shared.f32 	%f104, [%rd108];
	add.ftz.f32 	%f105, %f103, %f104;
	neg.ftz.f32 	%f106, %f101;
	fma.rn.ftz.f32 	%f107, %f106, %f105, %f105;
	fma.rn.ftz.f32 	%f108, %f107, 0f3F000000, %f102;
	mul.wide.s32 	%rd109, %r194, 4;
	add.s64 	%rd110, %rd4, %rd109;
	st.global.f32 	[%rd110], %f108;
	add.s32 	%r195, %r190, %r26;
	mul.wide.s32 	%rd111, %r195, 4;
	add.s64 	%rd112, %rd5, %rd111;
	ld.global.nc.f32 	%f109, [%rd112];
	ld.shared.f32 	%f110, [%rd107+360];
	ld.shared.f32 	%f111, [%rd108+360];
	add.ftz.f32 	%f112, %f110, %f111;
	fma.rn.ftz.f32 	%f113, %f106, %f112, %f112;
	fma.rn.ftz.f32 	%f114, %f113, 0f3F000000, %f109;
	add.s32 	%r196, %r194, %r28;
	mul.wide.s32 	%rd113, %r196, 4;
	add.s64 	%rd114, %rd4, %rd113;
	st.global.f32 	[%rd114], %f114;
	add.s32 	%r197, %r195, %r26;
	mul.wide.s32 	%rd115, %r197, 4;
	add.s64 	%rd116, %rd5, %rd115;
	ld.global.nc.f32 	%f115, [%rd116];
	ld.shared.f32 	%f116, [%rd107+720];
	ld.shared.f32 	%f117, [%rd108+720];
	add.ftz.f32 	%f118, %f116, %f117;
	fma.rn.ftz.f32 	%f119, %f106, %f118, %f118;
	fma.rn.ftz.f32 	%f120, %f119, 0f3F000000, %f115;
	add.s32 	%r198, %r196, %r28;
	mul.wide.s32 	%rd117, %r198, 4;
	add.s64 	%rd118, %rd4, %rd117;
	st.global.f32 	[%rd118], %f120;
	add.s32 	%r199, %r197, %r26;
	mul.wide.s32 	%rd119, %r199, 4;
	add.s64 	%rd120, %rd5, %rd119;
	ld.global.nc.f32 	%f121, [%rd120];
	ld.shared.f32 	%f122, [%rd107+1080];
	ld.shared.f32 	%f123, [%rd108+1080];
	add.ftz.f32 	%f124, %f122, %f123;
	fma.rn.ftz.f32 	%f125, %f106, %f124, %f124;
	fma.rn.ftz.f32 	%f126, %f125, 0f3F000000, %f121;
	add.s32 	%r200, %r198, %r28;
	mul.wide.s32 	%rd121, %r200, 4;
	add.s64 	%rd122, %rd4, %rd121;
	st.global.f32 	[%rd122], %f126;
	ret;
}
                                        // -- End function
	// .globl	kernel_normalize_s0_y_y_o___block_id_y // -- Begin function kernel_normalize_s0_y_y_o___block_id_y
.visible .entry kernel_normalize_s0_y_y_o___block_id_y(
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_0,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_1,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_2,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_3,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_4,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_5,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_6,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_7,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_8,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_9,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_10,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_11,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_12,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_13,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_14,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_15,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_16,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_17,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_18,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_19,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_20,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_21,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_22,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_23,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_24,
	.param .u32 kernel_normalize_s0_y_y_o___block_id_y_param_25,
	.param .u64 kernel_normalize_s0_y_y_o___block_id_y_param_26,
	.param .u64 kernel_normalize_s0_y_y_o___block_id_y_param_27,
	.param .u64 kernel_normalize_s0_y_y_o___block_id_y_param_28,
	.param .u64 kernel_normalize_s0_y_y_o___block_id_y_param_29
)                                       // @kernel_normalize_s0_y_y_o___block_id_y
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<90>;
	.reg .b32 	%r<140>;
	.reg .b64 	%rd<59>;

// %bb.0:                               // %entry
	ld.param.u32 	%r24, [kernel_normalize_s0_y_y_o___block_id_y_param_20];
	ld.param.u32 	%r23, [kernel_normalize_s0_y_y_o___block_id_y_param_19];
	mov.u32 	%r29, %ctaid.y;
	mov.u32 	%r30, %ctaid.x;
	mov.u32 	%r1, %tid.y;
	mov.u32 	%r2, %tid.x;
	mul.lo.s32 	%r31, %r29, 10;
	ld.param.u32 	%r32, [kernel_normalize_s0_y_y_o___block_id_y_param_25];
	min.s32 	%r3, %r31, %r32;
	shl.b32 	%r33, %r30, 4;
	ld.param.u32 	%r34, [kernel_normalize_s0_y_y_o___block_id_y_param_12];
	min.s32 	%r4, %r33, %r34;
	setp.lt.u32 	%p1, %r1, 4;
	setp.lt.u32 	%p2, %r2, 9;
	and.pred  	%p3, %p1, %p2;
	@%p3 bra 	LBB14_5;
	bra.uni 	LBB14_1;
LBB14_5:                                // %true_bb1
	ld.param.u32 	%r28, [kernel_normalize_s0_y_y_o___block_id_y_param_24];
	ld.param.u32 	%r27, [kernel_normalize_s0_y_y_o___block_id_y_param_23];
	ld.param.u32 	%r26, [kernel_normalize_s0_y_y_o___block_id_y_param_22];
	ld.param.u32 	%r16, [kernel_normalize_s0_y_y_o___block_id_y_param_11];
	ld.param.u32 	%r15, [kernel_normalize_s0_y_y_o___block_id_y_param_10];
	ld.param.u32 	%r14, [kernel_normalize_s0_y_y_o___block_id_y_param_9];
	ld.param.u64 	%rd7, [kernel_normalize_s0_y_y_o___block_id_y_param_27];
	cvta.to.global.u64 	%rd3, %rd7;
	add.s32 	%r35, %r4, %r23;
	shr.s32 	%r36, %r35, 1;
	add.s32 	%r37, %r36, %r2;
	shr.s32 	%r38, %r37, 1;
	add.s32 	%r39, %r3, %r24;
	shr.s32 	%r40, %r39, 2;
	sub.s32 	%r41, %r1, %r16;
	add.s32 	%r42, %r41, %r40;
	mul.lo.s32 	%r43, %r42, %r15;
	sub.s32 	%r44, %r43, %r14;
	add.s32 	%r45, %r44, %r38;
	mul.wide.s32 	%rd9, %r45, 4;
	add.s64 	%rd10, %rd3, %rd9;
	ld.global.nc.f32 	%f1, [%rd10];
	add.s32 	%r46, %r37, 1;
	shr.s32 	%r47, %r46, 1;
	add.s32 	%r48, %r47, %r44;
	mul.wide.s32 	%rd11, %r48, 4;
	add.s64 	%rd12, %rd3, %rd11;
	ld.global.nc.f32 	%f2, [%rd12];
	add.ftz.f32 	%f3, %f1, %f2;
	mul.ftz.f32 	%f4, %f3, 0f3F000000;
	mad.lo.s32 	%r49, %r1, 9, %r2;
	mul.wide.u32 	%rd13, %r49, 4;
	st.shared.f32 	[%rd13], %f4;
	add.s32 	%r50, %r43, %r26;
	add.s32 	%r51, %r50, %r38;
	mul.wide.s32 	%rd14, %r51, 4;
	add.s64 	%rd15, %rd3, %rd14;
	ld.global.nc.f32 	%f5, [%rd15];
	add.s32 	%r52, %r47, %r50;
	mul.wide.s32 	%rd16, %r52, 4;
	add.s64 	%rd17, %rd3, %rd16;
	ld.global.nc.f32 	%f6, [%rd17];
	add.ftz.f32 	%f7, %f5, %f6;
	mul.ftz.f32 	%f8, %f7, 0f3F000000;
	st.shared.f32 	[%rd13+144], %f8;
	add.s32 	%r53, %r43, %r27;
	add.s32 	%r54, %r53, %r38;
	mul.wide.s32 	%rd18, %r54, 4;
	add.s64 	%rd19, %rd3, %rd18;
	ld.global.nc.f32 	%f9, [%rd19];
	add.s32 	%r55, %r47, %r53;
	mul.wide.s32 	%rd20, %r55, 4;
	add.s64 	%rd21, %rd3, %rd20;
	ld.global.nc.f32 	%f10, [%rd21];
	add.ftz.f32 	%f11, %f9, %f10;
	mul.ftz.f32 	%f12, %f11, 0f3F000000;
	st.shared.f32 	[%rd13+288], %f12;
	add.s32 	%r56, %r43, %r28;
	add.s32 	%r57, %r56, %r38;
	mul.wide.s32 	%rd22, %r57, 4;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.nc.f32 	%f13, [%rd23];
	add.s32 	%r58, %r47, %r56;
	mul.wide.s32 	%rd24, %r58, 4;
	add.s64 	%rd25, %rd3, %rd24;
	ld.global.nc.f32 	%f14, [%rd25];
	add.ftz.f32 	%f15, %f13, %f14;
	mul.ftz.f32 	%f16, %f15, 0f3F000000;
	st.shared.f32 	[%rd13+432], %f16;
LBB14_1:                                // %after_bb
	ld.param.u64 	%rd5, [kernel_normalize_s0_y_y_o___block_id_y_param_29];
	ld.param.u64 	%rd6, [kernel_normalize_s0_y_y_o___block_id_y_param_28];
	bar.sync 	0;
	setp.lt.u32 	%p5, %r1, 6;
	and.pred  	%p6, %p5, %p2;
	@%p6 bra 	LBB14_6;
	bra.uni 	LBB14_2;
LBB14_6:                                // %true_bb7
	ld.param.u64 	%rd8, [kernel_normalize_s0_y_y_o___block_id_y_param_26];
	ld.param.u32 	%r18, [kernel_normalize_s0_y_y_o___block_id_y_param_14];
	ld.param.u32 	%r13, [kernel_normalize_s0_y_y_o___block_id_y_param_8];
	ld.param.u32 	%r12, [kernel_normalize_s0_y_y_o___block_id_y_param_7];
	ld.param.u32 	%r11, [kernel_normalize_s0_y_y_o___block_id_y_param_6];
	ld.param.u32 	%r10, [kernel_normalize_s0_y_y_o___block_id_y_param_5];
	ld.param.u32 	%r5, [kernel_normalize_s0_y_y_o___block_id_y_param_0];
	cvta.to.global.u64 	%rd4, %rd8;
	add.s32 	%r59, %r3, %r24;
	shr.s32 	%r60, %r59, 1;
	sub.s32 	%r61, %r1, %r5;
	add.s32 	%r62, %r61, %r60;
	add.s32 	%r63, %r4, %r23;
	shr.s32 	%r64, %r63, 1;
	mad.lo.s32 	%r65, %r62, %r13, %r2;
	sub.s32 	%r66, %r65, %r18;
	add.s32 	%r67, %r66, %r64;
	mul.wide.s32 	%rd26, %r67, 4;
	add.s64 	%rd27, %rd4, %rd26;
	ld.global.nc.f32 	%f17, [%rd27];
	add.s32 	%r68, %r65, %r12;
	add.s32 	%r69, %r68, %r64;
	mul.wide.s32 	%rd28, %r69, 4;
	add.s64 	%rd29, %rd4, %rd28;
	ld.global.nc.f32 	%f18, [%rd29];
	add.s32 	%r70, %r60, %r1;
	shr.s32 	%r71, %r70, 1;
	shr.s32 	%r72, %r59, 2;
	sub.s32 	%r73, %r71, %r72;
	mad.lo.s32 	%r74, %r73, 9, %r2;
	mul.wide.s32 	%rd30, %r74, 4;
	ld.shared.f32 	%f19, [%rd30];
	add.s32 	%r75, %r70, 1;
	shr.s32 	%r76, %r75, 1;
	sub.s32 	%r77, %r76, %r72;
	mad.lo.s32 	%r78, %r77, 9, %r2;
	mul.wide.s32 	%rd31, %r78, 4;
	ld.shared.f32 	%f20, [%rd31];
	add.ftz.f32 	%f21, %f19, %f20;
	neg.ftz.f32 	%f22, %f18;
	fma.rn.ftz.f32 	%f23, %f22, %f21, %f21;
	fma.rn.ftz.f32 	%f24, %f23, 0f3F000000, %f17;
	mad.lo.s32 	%r79, %r1, 9, %r2;
	mul.wide.u32 	%rd32, %r79, 4;
	st.shared.f32 	[%rd32+1536], %f24;
	add.s32 	%r80, %r65, %r11;
	add.s32 	%r81, %r80, %r64;
	mul.wide.s32 	%rd33, %r81, 4;
	add.s64 	%rd34, %rd4, %rd33;
	ld.global.nc.f32 	%f25, [%rd34];
	ld.shared.f32 	%f26, [%rd30+144];
	ld.shared.f32 	%f27, [%rd31+144];
	add.ftz.f32 	%f28, %f26, %f27;
	fma.rn.ftz.f32 	%f29, %f22, %f28, %f28;
	fma.rn.ftz.f32 	%f30, %f29, 0f3F000000, %f25;
	st.shared.f32 	[%rd32+1752], %f30;
	add.s32 	%r82, %r65, %r10;
	add.s32 	%r83, %r82, %r64;
	mul.wide.s32 	%rd35, %r83, 4;
	add.s64 	%rd36, %rd4, %rd35;
	ld.global.nc.f32 	%f31, [%rd36];
	ld.shared.f32 	%f32, [%rd30+288];
	ld.shared.f32 	%f33, [%rd31+288];
	add.ftz.f32 	%f34, %f32, %f33;
	fma.rn.ftz.f32 	%f35, %f22, %f34, %f34;
	fma.rn.ftz.f32 	%f36, %f35, 0f3F000000, %f31;
	st.shared.f32 	[%rd32+1968], %f36;
	ld.shared.f32 	%f37, [%rd30+432];
	ld.shared.f32 	%f38, [%rd31+432];
	add.ftz.f32 	%f39, %f37, %f38;
	fma.rn.ftz.f32 	%f40, %f22, %f39, %f39;
	fma.rn.ftz.f32 	%f41, %f40, 0f3F000000, %f18;
	st.shared.f32 	[%rd32+2184], %f41;
LBB14_2:                                // %after_bb6
	ld.param.u32 	%r25, [kernel_normalize_s0_y_y_o___block_id_y_param_21];
	ld.param.u32 	%r22, [kernel_normalize_s0_y_y_o___block_id_y_param_18];
	ld.param.u32 	%r21, [kernel_normalize_s0_y_y_o___block_id_y_param_17];
	ld.param.u32 	%r20, [kernel_normalize_s0_y_y_o___block_id_y_param_16];
	ld.param.u32 	%r19, [kernel_normalize_s0_y_y_o___block_id_y_param_15];
	ld.param.u32 	%r17, [kernel_normalize_s0_y_y_o___block_id_y_param_13];
	ld.param.u32 	%r9, [kernel_normalize_s0_y_y_o___block_id_y_param_4];
	ld.param.u32 	%r8, [kernel_normalize_s0_y_y_o___block_id_y_param_3];
	ld.param.u32 	%r7, [kernel_normalize_s0_y_y_o___block_id_y_param_2];
	ld.param.u32 	%r6, [kernel_normalize_s0_y_y_o___block_id_y_param_1];
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd6;
	bar.sync 	0;
	@%p5 bra 	LBB14_3;
	bra.uni 	LBB14_4;
LBB14_3:                                // %true_bb10
	add.s32 	%r84, %r4, %r23;
	and.b32  	%r85, %r84, 1;
	add.s32 	%r86, %r85, %r2;
	shr.u32 	%r87, %r86, 1;
	mul.lo.s32 	%r88, %r1, 9;
	add.s32 	%r89, %r87, %r88;
	mul.wide.u32 	%rd37, %r89, 4;
	ld.shared.f32 	%f42, [%rd37+1536];
	add.s32 	%r90, %r84, %r2;
	add.s32 	%r91, %r90, 769;
	shr.s32 	%r92, %r91, 1;
	shr.s32 	%r93, %r84, 1;
	sub.s32 	%r94, %r88, %r93;
	add.s32 	%r95, %r92, %r94;
	mul.wide.s32 	%rd38, %r95, 4;
	ld.shared.f32 	%f43, [%rd38];
	add.ftz.f32 	%f44, %f42, %f43;
	mul.ftz.f32 	%f45, %f44, 0f3F000000;
	shl.b32 	%r96, %r1, 4;
	add.s32 	%r97, %r96, %r2;
	mul.wide.u32 	%rd39, %r97, 4;
	st.shared.f32 	[%rd39], %f45;
	ld.shared.f32 	%f46, [%rd37+1752];
	add.s32 	%r98, %r90, 877;
	shr.s32 	%r99, %r98, 1;
	add.s32 	%r100, %r99, %r94;
	mul.wide.s32 	%rd40, %r100, 4;
	ld.shared.f32 	%f47, [%rd40];
	add.ftz.f32 	%f48, %f46, %f47;
	mul.ftz.f32 	%f49, %f48, 0f3F000000;
	st.shared.f32 	[%rd39+384], %f49;
	ld.shared.f32 	%f50, [%rd37+1968];
	add.s32 	%r101, %r90, 985;
	shr.s32 	%r102, %r101, 1;
	add.s32 	%r103, %r102, %r94;
	mul.wide.s32 	%rd41, %r103, 4;
	ld.shared.f32 	%f51, [%rd41];
	add.ftz.f32 	%f52, %f50, %f51;
	mul.ftz.f32 	%f53, %f52, 0f3F000000;
	st.shared.f32 	[%rd39+768], %f53;
	ld.shared.f32 	%f54, [%rd37+2184];
	add.s32 	%r104, %r90, 1093;
	shr.s32 	%r105, %r104, 1;
	add.s32 	%r106, %r105, %r94;
	mul.wide.s32 	%rd42, %r106, 4;
	ld.shared.f32 	%f55, [%rd42];
	add.ftz.f32 	%f56, %f54, %f55;
	mul.ftz.f32 	%f57, %f56, 0f3F000000;
	st.shared.f32 	[%rd39+1152], %f57;
LBB14_4:                                // %after_bb12
	bar.sync 	0;
	add.s32 	%r107, %r4, %r2;
	add.s32 	%r108, %r107, %r23;
	min.s32 	%r109, %r108, %r9;
	max.s32 	%r110, %r109, %r19;
	add.s32 	%r111, %r3, %r24;
	add.s32 	%r112, %r111, %r1;
	min.s32 	%r113, %r112, %r8;
	max.s32 	%r114, %r113, %r20;
	neg.s32 	%r115, %r20;
	mad.lo.s32 	%r116, %r114, %r21, %r110;
	sub.s32 	%r117, %r116, %r19;
	mad.lo.s32 	%r118, %r115, %r21, %r117;
	mad.lo.s32 	%r119, %r22, 3, %r118;
	mul.wide.s32 	%rd43, %r119, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f58, [%rd44];
	add.s32 	%r120, %r112, 1;
	shr.u32 	%r121, %r120, 1;
	shr.u32 	%r122, %r111, 1;
	sub.s32 	%r123, %r121, %r122;
	mul.wide.s32 	%rd45, %r118, 4;
	add.s64 	%rd46, %rd2, %rd45;
	ld.global.nc.f32 	%f59, [%rd46];
	and.b32  	%r124, %r111, 1;
	add.s32 	%r125, %r124, %r1;
	shl.b32 	%r126, %r125, 3;
	and.b32  	%r127, %r126, -16;
	add.s32 	%r128, %r127, %r2;
	mul.wide.u32 	%rd47, %r128, 4;
	ld.shared.f32 	%f60, [%rd47];
	shl.b32 	%r129, %r123, 4;
	add.s32 	%r130, %r129, %r2;
	mul.wide.s32 	%rd48, %r130, 4;
	ld.shared.f32 	%f61, [%rd48];
	add.ftz.f32 	%f62, %f60, %f61;
	neg.ftz.f32 	%f63, %f58;
	fma.rn.ftz.f32 	%f64, %f63, %f62, %f62;
	mul.ftz.f32 	%f65, %f64, 0f3F000000;
	fma.rn.ftz.f32 	%f66, %f58, %f59, %f65;
	ld.shared.f32 	%f67, [%rd47+1152];
	ld.shared.f32 	%f68, [%rd48+1152];
	add.ftz.f32 	%f69, %f67, %f68;
	fma.rn.ftz.f32 	%f70, %f63, %f69, %f69;
	fma.rn.ftz.f32 	%f71, %f70, 0f3F000000, %f58;
	rcp.approx.ftz.f32 	%f72, %f71;
	mul.ftz.f32 	%f73, %f66, %f72;
	mul.lo.s32 	%r131, %r112, %r25;
	add.s32 	%r132, %r107, %r17;
	add.s32 	%r133, %r132, %r131;
	mul.wide.s32 	%rd49, %r133, 4;
	add.s64 	%rd50, %rd1, %rd49;
	st.global.f32 	[%rd50], %f73;
	add.s32 	%r134, %r118, %r22;
	mul.wide.s32 	%rd51, %r134, 4;
	add.s64 	%rd52, %rd2, %rd51;
	ld.global.nc.f32 	%f74, [%rd52];
	ld.shared.f32 	%f75, [%rd47+384];
	ld.shared.f32 	%f76, [%rd48+384];
	add.ftz.f32 	%f77, %f75, %f76;
	fma.rn.ftz.f32 	%f78, %f63, %f77, %f77;
	mul.ftz.f32 	%f79, %f78, 0f3F000000;
	fma.rn.ftz.f32 	%f80, %f58, %f74, %f79;
	mul.ftz.f32 	%f81, %f80, %f72;
	add.s32 	%r135, %r107, %r7;
	add.s32 	%r136, %r135, %r131;
	mul.wide.s32 	%rd53, %r136, 4;
	add.s64 	%rd54, %rd1, %rd53;
	st.global.f32 	[%rd54], %f81;
	sub.s32 	%r137, %r119, %r22;
	mul.wide.s32 	%rd55, %r137, 4;
	add.s64 	%rd56, %rd2, %rd55;
	ld.global.nc.f32 	%f82, [%rd56];
	ld.shared.f32 	%f83, [%rd47+768];
	ld.shared.f32 	%f84, [%rd48+768];
	add.ftz.f32 	%f85, %f83, %f84;
	fma.rn.ftz.f32 	%f86, %f63, %f85, %f85;
	mul.ftz.f32 	%f87, %f86, 0f3F000000;
	fma.rn.ftz.f32 	%f88, %f58, %f82, %f87;
	mul.ftz.f32 	%f89, %f88, %f72;
	add.s32 	%r138, %r107, %r6;
	add.s32 	%r139, %r138, %r131;
	mul.wide.s32 	%rd57, %r139, 4;
	add.s64 	%rd58, %rd1, %rd57;
	st.global.f32 	[%rd58], %f89;
	ret;
}
                                        // -- End function


add_temp_object_file: /tmp/jbMrCL/interpolate_auto_schedule.a.o
Module.compile(): temporary object_name /tmp/jbMrCL/interpolate_auto_schedule.a.o
emit_file.Compiling to native code...
Module.compile(): static_library_name ./bin/interpolate_auto_schedule.a
file_unlink: /tmp/jbMrCL/interpolate_auto_schedule.a.o
dir_rmdir: /tmp/jbMrCL
Module.compile(): c_header_name ./bin/interpolate_auto_schedule.h
Module.compile(): registration_name ./bin/interpolate_auto_schedule.registration.cpp
